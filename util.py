import csv
import string
from typing import Callable, List, Tuple

import gensim.models
import matplotlib.pyplot as plt
import numpy as np
from gensim.models.keyedvectors import KeyedVectors


def generate_2d_xor_dataset(d: float = 4, seed: int = 1) -> Tuple[np.ndarray,
                                                                  np.ndarray]:
    """
    Generates a 2D dataset with the following properties:
    Two classes, indicated by labels 0 and 1.
    The examples come from 4 clusters:
        1. A 2D normal distribution centered at (-d, d) with unit variances.
        2. A 2D normal distribution centered at (d, d) with unit variances.
        3. A 2D normal distribution centered at (-d, 3d) with unit variances.
        4. A 2D normal distribution centered at (d, 3d) with unit variances.
    Points from clusters 1 and 2 have label 1, and points from clusters 3 and 4
    have label 0.
    Args:
        d (float): Parameter determining the positions of the cluster centers.
        seed (int): The seed to use to set the randomness for np.random.
    Returns:
        Tuple[np.ndarray, np.ndarray]: The first output is an array containing
                                        all of the data points/examples, with
                                        shape (num_examples, 2).
                                        The second output is an array containing
                                        the corresponding labels (0 or 1),
                                        with shape
                                        (num_examples, 1).
    """
    np.random.seed(seed)

    cluster_means_to_label = {(-d, d):     0,
                              (d, d):      1,
                              (-d, 3 * d): 1,
                              (d, 3 * d):  0}
    covariance = np.array([[1, 0],
                           [0, 1]])

    points_per_cluster = 100

    clusters_x = []
    clusters_y = []

    for mean, label in cluster_means_to_label.items():
        clusters_x.append(np.random.multivariate_normal(mean, covariance,
                                                        points_per_cluster))
        clusters_y.append(np.full((points_per_cluster,), label))

    X = np.concatenate(clusters_x, axis=0)
    y = np.expand_dims(np.concatenate(clusters_y, axis=0), axis=1)

    return X, y


def plot_2d_dataset_points(X: np.ndarray, y: np.ndarray) -> None:
    """
    Plots the 2D toy dataset with labels.
    Args:
        X (np.ndarray): Array of the examples/data points of shape
                        (num_examples, 2). Generated by
                        generate_2d_xor_dataset().
        y (np.ndarray): Array of the corresponding labels of shape
                        (num_examples, 1). Generated by
                        generate_2d_xor_dataset().
    """
    # Get points in class 1 and class 0 separately
    X_c1 = X[y[:, 0] == 1]
    X_c0 = X[y[:, 0] == 0]

    # Plot them as colored points
    plt.scatter(X_c1[:, 0], X_c1[:, 1], c="Red", label="Positive true sentiment (y=1)")
    plt.scatter(X_c0[:, 0], X_c0[:, 1], c="Blue", label="Negative true sentiment (y=0)")
    # Add axes labels and legend
    plt.xlabel("Feature 1: Average Sentiment of Words in Sentence")
    plt.ylabel("Feature 2: Sarcasm level in Sentence")
    plt.legend()
    return plt 

def plot_points_with_classifier_predictions(
        X: np.ndarray,
        y: np.ndarray,
        classifier,
        h: float = 0.02,
        alpha: float = 0.3) -> None:
    """
    Plots the data points X, labeling based on their true labels y.
    Then, overlays the prediction of the provided classifier over the data,
    showing the regions predicted as each class with shaded colors.
    Args:
        X (np.ndarray): Array of the examples/data points of shape
                        (num_examples, 2). Generated by
                        generate_2d_xor_dataset().
        y (np.ndarray): Array of the corresponding labels of shape
                        (num_examples, 1). Generated by
                        generate_2d_xor_dataset().
        classifier: An object which implements the method predict(X), which
                    takes in the array of inputs of shape (num_examples,
                    input_size) and outputs an array of predictions of
                    shape (num_examples,).
        h (float): Parameter controlling the density of sampling used to
                    produce the colored classifier prediction regions.
        alpha (float): Parameter controlling the opacity of the colored
                        classifier prediction regions.
    Credit to the excellent plotting example from Scikit-Learn here:
    http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html
    """

    # Plot the points in class 1 and class 0 as colored dots
    X_c1 = X[y[:, 0] == 1]
    X_c0 = X[y[:, 0] == 0]

    # Plot them as colored points
    plt.scatter(X_c1[:, 0], X_c1[:, 1], c="Red", label="Positive true sentiment (y=1)")
    plt.scatter(X_c0[:, 0], X_c0[:, 1], c="Blue", label="Negative true sentiment (y=0)")
    # Add axes labels and legend
    plt.xlabel("Feature 1: Average Sentiment of Words in Sentence")
    plt.ylabel("Feature 2: Sarcasm level in Sentence")

    # Shade the plot based on the model's predictions
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=alpha)

    plt.legend()
    return plt 

def load_embeddings(embedding_filename: str) -> gensim.models.KeyedVectors:
    """
    Load the GloVe word embeddings from a file and add an "unknown"
    word embedding.
    Args:
        embedding_filename (str): The text file containing the embedding data,
                                    must be in the Word2Vec format (see
                                    Gensim documentation).
    Returns:
        gensim.models.KeyedVectors: A Gensim embeddings object.
    """
    embeddings = KeyedVectors.load_word2vec_format(
        embedding_filename, binary=False)

    # Create the "<unk>" token for unknown words and set it equal to the average
    # of all the other word embeddings.
    embeddings["<unk>"] = np.mean(embeddings.vectors, axis=0)
    return embeddings


def load_dataset(filename: str) -> Tuple[List[List[str]], List[int]]:
    """
    Load in a Yelp review dataset (pre-processed) from a custom-formatted
    CSV file.
    Args:
        filename (str): The text file containing the Yelp review data. Formatted
                        as a pipe ("|")-delimited CSV with a header row and two
                        columns ("Review", and "Label").
    Returns:
        Tuple[List[List[str]], List[int]]: The first output is a list of
        examples, where each example is a list of words and each word is a
        string. The second output is a list of labels for the corresponding
        examples, where each label is either 0 or 1. Both lists are of the
        same length (the number of examples).
    """
    examples = []
    labels = []
    with open(filename, "r") as f:
        reader = csv.DictReader(f, delimiter='|', quotechar='"')
        for row in reader:
            if not row["Review"].split():
                continue
            examples.append(row["Review"].split())
            labels.append(int(row["Label"]))

    return examples, labels

def load_vocab2idx(): 
    embeddings = KeyedVectors.load_word2vec_format("./data/embeddings/glove50_4k.txt", binary=False)
    vocab2indx = dict(embeddings.key_to_index)
    new_oov_entry = len(embeddings)
    vocab2indx["<OOV>"] = new_oov_entry
    return vocab2indx

def diagnostics_plot(loss_history, train_acc_history, dev_acc_history):
    plt.subplot(2, 1, 1)
    plt.plot(loss_history, 'o')
    plt.xlabel('checkpoint no.')
    plt.ylabel('loss')

    plt.subplot(2, 1, 2)
    plt.plot(train_acc_history, '-o')
    plt.plot(dev_acc_history, '-o')
    plt.ylim(0, 1.0)
    plt.legend(['train', 'val'], loc='upper left')
    plt.xlabel('checkpoint no.')
    plt.ylabel('accuracy')
    plt.tight_layout();
