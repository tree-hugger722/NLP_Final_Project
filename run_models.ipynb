{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e263e0b1",
   "metadata": {},
   "source": [
    "### Run Distilled DAN, Non-distilled DAN, and Logistic Regression (GloVE-embedded input) Models\n",
    "Run all of the following cells, in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4a2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "import torch\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5ee47",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c784db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    \"\"\"\n",
    "    Load training and dev sets\n",
    "    \"\"\"\n",
    "\n",
    "    train = pd.read_csv(\"./data/train_preprocessed.csv\")\n",
    "    dev = pd.read_csv(\"./data/val_preprocessed.csv\")\n",
    "    \n",
    "    return train, dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce5576",
   "metadata": {},
   "source": [
    "Tokenize Input Text and Add to Train and Dev Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa2742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text: str):\n",
    "    '''\n",
    "    NLTK Tweet Tokenizer -- removes handles\n",
    "\n",
    "    @param text        string tweet\n",
    "    @ret tokens        list of tokens\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    tokenizer = nltk.tokenize.TweetTokenizer(strip_handles=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df731f",
   "metadata": {},
   "source": [
    "Embed Input Text Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ad0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Loads embeddings from embedding file and creates \n",
    "    1) dictionary of embedding words to indices\n",
    "    2) list of embedding indices to words\n",
    "    3) dense word embedding matrix\n",
    "    \"\"\"\n",
    "    embeddings = KeyedVectors.load_word2vec_format(filename, binary=False, no_header=True)\n",
    "    vocab2indx = dict(embeddings.key_to_index)\n",
    "    idx2vocab = list(embeddings.index_to_key)\n",
    "    embed_array = embeddings.vectors # matrix of dense word embeddings \n",
    "                                     # rows: a word \n",
    "                                     # columns: dimensions (50) of the dense embeddings\n",
    "    return vocab2indx, idx2vocab, embed_array\n",
    "\n",
    "\n",
    "def add_the_embedding(embed_array, vocab2indx): \n",
    "    \"\"\"\n",
    "    Adds \"the\" embedding to the embed_array matrix\n",
    "    \"\"\"\n",
    "    the_embedding = embed_array[vocab2indx[\"the\"]]\n",
    "    out = np.vstack((embed_array, the_embedding))\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_oov(idx2vocab, vocab2indx, embed_array):\n",
    "    \"\"\"\n",
    "    Adds <OOV> token to embedded vocabulary\n",
    "    \"\"\"\n",
    "    print(\"len embed array: \", len(embed_array))\n",
    "    new_oov_entry = len(embed_array)\n",
    "    idx2vocab += [\"<OOV>\"]\n",
    "    vocab2indx[\"<OOV>\"] = new_oov_entry\n",
    "    embed_array_w_oov = add_the_embedding(embed_array, vocab2indx)\n",
    "\n",
    "    return idx2vocab, vocab2indx, embed_array_w_oov\n",
    "\n",
    "\n",
    "def add_pad(idx2vocab, vocab2indx, embed_array):\n",
    "    \"\"\"\n",
    "    Adds <PAD> token to embedded vocabulary\n",
    "    \"\"\"\n",
    "    print(\"len embed array: \", len(embed_array))\n",
    "    new_pad_entry = len(embed_array)\n",
    "    idx2vocab += [\"<PAD>\"]\n",
    "    vocab2indx[\"<PAD>\"] = new_pad_entry\n",
    "    embed_array_w_pad = add_the_embedding(embed_array, vocab2indx)\n",
    "    \n",
    "    return idx2vocab, vocab2indx, embed_array_w_pad\n",
    "\n",
    "\n",
    "def truncate(original_indices_list: list, maximum_length=128) -> list: \n",
    "    \"\"\"\n",
    "    Truncates the original_indices_list to the maximum_length\n",
    "    \"\"\"\n",
    "    return original_indices_list[0:maximum_length]\n",
    "\n",
    "\n",
    "def pad(original_indices_list: list, pad_index: int, maximum_length=128) -> list: \n",
    "    \"\"\"\n",
    "    Given original_indices_list, concatenates the pad_index enough times \n",
    "    to make the list to maximum_length. \n",
    "    \"\"\"\n",
    "    while len(original_indices_list) < maximum_length:\n",
    "        original_indices_list.append(pad_index)\n",
    "        \n",
    "    return original_indices_list\n",
    "\n",
    "\n",
    "def get_padded_oov_embeddings():\n",
    "    \"\"\"\n",
    "    Get embedding array which includes the <PAD> and <OOV> tokens\n",
    "    \"\"\"\n",
    "    vocab2indx, idx2vocab, embed_array = load_embeddings(\"glove.twitter.27B.50d.txt\")\n",
    "    idx2vocab, vocab2indx, embed_array_w_oov = add_oov(idx2vocab, vocab2indx, embed_array)\n",
    "    idx2vocab, vocab2indx, embed_array_w_oov_pad = add_pad(idx2vocab, vocab2indx, embed_array_w_oov)\n",
    "    \n",
    "    return embed_array_w_oov_pad, vocab2indx, idx2vocab\n",
    "\n",
    "def create_word_indices(tokens, vocab2indx): \n",
    "    \"\"\"\n",
    "    For each example, translate each token into its corresponding index from vocab2indx\n",
    "    \n",
    "    Replace words not in the vocabulary with the symbol \"<OOV>\" \n",
    "        which stands for 'out of vocabulary'\n",
    "        \n",
    "    Arguments: \n",
    "       - tokens (List[str]): list of strings of tokens \n",
    "       - vocab2indx (dict): each vocabulary word as strings and its corresponding int index \n",
    "                           for the embeddings \n",
    "                           \n",
    "    Returns: \n",
    "        - (List[int]): list of integers\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    num_oov = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in vocab2indx:\n",
    "            token = \"<OOV>\"\n",
    "            num_oov += 1\n",
    "        indices.append(vocab2indx[token])\n",
    "    \n",
    "    return indices, num_oov, len(tokens)\n",
    "\n",
    "\n",
    "def convert_X(Xmat, embeddings, vocab2indx, idx2vocab):\n",
    "    MAXIMUM_LENGTH = 128\n",
    "    \n",
    "    X_list_embedded = []\n",
    "    num_total_tokens = 0\n",
    "    num_oov = 0\n",
    "    \n",
    "    for one_example in Xmat:\n",
    "        one_example = str(one_example)\n",
    "        one_example_tokenized = tokenizer(one_example)\n",
    "        example_indices, num_oov_in_example, num_tokens_in_example = create_word_indices(one_example_tokenized, vocab2indx)\n",
    "        example_indices = truncate(example_indices, maximum_length=MAXIMUM_LENGTH)\n",
    "        example_indices = pad(example_indices, len(vocab2indx)-1, maximum_length=MAXIMUM_LENGTH)\n",
    "        \n",
    "        example_embeddings = [] # A list of token embeddings\n",
    "        \n",
    "        for index in example_indices:\n",
    "            example_embeddings.append(embeddings[index])\n",
    "        \n",
    "        X_list_embedded.append(example_embeddings)\n",
    "        \n",
    "        num_total_tokens += num_tokens_in_example\n",
    "        num_oov += num_oov_in_example\n",
    "        percent_oov = (num_oov/num_total_tokens)\n",
    "        \n",
    "    return torch.FloatTensor(X_list_embedded), percent_oov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03910a2f",
   "metadata": {},
   "source": [
    "Get embedded input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa085621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train, dev = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0073b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len embed array:  1193514\n",
      "len embed array:  1193515\n"
     ]
    }
   ],
   "source": [
    "# Get GloVE embeddings\n",
    "embeddings, vocab2indx, idx2vocab = get_padded_oov_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7403464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_22011/498052130.py:132: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_2a19nf9hj1/croot/pytorch_1675190251927/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  return torch.FloatTensor(X_list_embedded), percent_oov\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of train tokens out-of-vocabulary:  0.08425232669426272\n",
      "Percentage of dev tokens out-of-vocabulary:  0.08289588312819711\n"
     ]
    }
   ],
   "source": [
    "# Convert train and dev sets to GloVE embeddings\n",
    "# X_train shape: (num_examples_test, 64, 50)\n",
    "# X_dev shape: (num_examples_test, 64, 50)\n",
    "Xmat_train, percent_train_oov = convert_X(train[\"text\"], embeddings, vocab2indx, idx2vocab)\n",
    "Xmat_dev, percent_dev_oov = convert_X(dev[\"text\"], embeddings, vocab2indx, idx2vocab)\n",
    "\n",
    "print(\"Percentage of train tokens out-of-vocabulary: \", percent_train_oov)\n",
    "print(\"Percentage of dev tokens out-of-vocabulary: \", percent_dev_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c09a0b",
   "metadata": {},
   "source": [
    "Run Logistic Regression Baseline Model with GloVE-Embedded Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc462a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_embedding(df):\n",
    "    \"\"\"\n",
    "    Convert a tensor of shape (batch_size, num_sentences, embedding_size) to\n",
    "    (batch_size, embedding_size) by averaging the embeddings along the second dimension.\n",
    "\n",
    "    :param df: Input tensor with shape (batch_size, num_sentences, embedding_size)\n",
    "    :type df: torch.Tensor\n",
    "    :return: Averaged tensor with shape (batch_size, embedding_size)\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    # Check if the input is a PyTorch tensor\n",
    "    if not isinstance(df, torch.Tensor):\n",
    "        raise TypeError(\"Input must be a PyTorch tensor.\")\n",
    "\n",
    "    # Check if the input tensor has the correct shape\n",
    "    if len(df.shape) != 3:\n",
    "        raise ValueError(\"Input tensor must have 3 dimensions (batch_size, num_sentences, embedding_size).\")\n",
    "\n",
    "    # Compute the average along the second dimension (num_sentences)\n",
    "    averaged_embeddings = df.mean(dim=1)\n",
    "\n",
    "    return averaged_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef00693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train accuracy: 0.6146443056012276\n",
      "Baseline dev accuracy: 0.612\n"
     ]
    }
   ],
   "source": [
    "# Average the word embeddings for each example into a sentence embedding\n",
    "X_train_avg = average_sentence_embedding(Xmat_train) # shape: (num_examples_test, 50)\n",
    "X_dev_avg = average_sentence_embedding(Xmat_dev) # shape: (num_examples_test, 50)\n",
    "\n",
    "# Get Y\n",
    "Y_train = train[\"label\"]\n",
    "Y_dev = dev[\"label\"]\n",
    "\n",
    "# Train a Logistic Regression model using the averaged embeddings\n",
    "baseline_embed = LogisticRegression(max_iter=10000, multi_class='auto', solver='lbfgs')\n",
    "baseline_embed.fit(X_train_avg, Y_train)\n",
    "\n",
    "# Prediction & Evaluation\n",
    "Y_pred_train = baseline_embed.predict(X_train_avg)\n",
    "Y_pred_dev = baseline_embed.predict(X_dev_avg)\n",
    "\n",
    "train_accuracy = accuracy_score(Y_train, Y_pred_train)\n",
    "dev_accuracy = accuracy_score(Y_dev, Y_pred_dev)\n",
    "\n",
    "print(f\"Baseline train accuracy: {train_accuracy}\")\n",
    "print(f\"Baseline dev accuracy: {dev_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722165b",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "988e8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./new_dataset/test_preprocessed.csv\")\n",
    "\n",
    "Xmat_test = test[\"text\"]\n",
    "Y_test = test[\"label\"]\n",
    "\n",
    "Xmat_test, percent_test_oov = convert_X(test[\"text\"], embeddings, vocab2indx, idx2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a4f35aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_avg = average_sentence_embedding(Xmat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f5c06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.6101432758059264\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = baseline_embed.predict(X_test_avg)\n",
    "\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "print(f\"Baseline test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fbd431ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_baseline_embedding = [0, 0, 0]\n",
    "wrong_baseline_embedding = [0, 0, 0]\n",
    "for y, y_pred in zip(Y_test, Y_pred_test):\n",
    "    total_baseline_embedding[y] += 1\n",
    "    if y != y_pred:\n",
    "        # if the prediction is wrong\n",
    "        wrong_baseline_embedding[y] += 1\n",
    "\n",
    "percent_error_baseline_embedding = []\n",
    "\n",
    "for i in range(len(total_baseline_embedding)):\n",
    "    percent_error_baseline_embedding.append(wrong_baseline_embedding[i]/total_baseline_embedding[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "018c1c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3972, 5937, 2375]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_baseline_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "23a94912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2473, 1228, 1088]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_baseline_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7ab5ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6226082578046325, 0.20683847060805122, 0.45810526315789474]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_error_baseline_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc5a71",
   "metadata": {},
   "source": [
    "### Distilled Deep Averaging Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb05359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499f85a",
   "metadata": {},
   "source": [
    "Helper function to convert an array of log probabilities to a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f9e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_to_label(proba_batch):\n",
    "    '''\n",
    "    Given a proba_batch, an array of probabilities over each sentiment class (0, 1, 2), returns\n",
    "    a single label corresponding to the maximum probability\n",
    "    '''\n",
    "    \n",
    "    # Detach the tensor and convert it to a NumPy array\n",
    "    proba_batch_np = proba_batch.detach().numpy()\n",
    "\n",
    "    # Find the index of the largest value in each sub-array\n",
    "    max_indices = np.argmax(proba_batch_np, axis=1)\n",
    "\n",
    "#     # Create a new array of the same shape filled with 0s\n",
    "#     binary_array = np.zeros_like(proba_batch_np)\n",
    "\n",
    "#     # Set the largest value positions to 1\n",
    "#     for i, max_index in enumerate(max_indices):\n",
    "#         binary_array[i, max_index] = 1\n",
    "\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158edc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soft labels\n",
    "Y_soft_train = train[\"Y_soft\"]\n",
    "Y_soft_train = np.array([literal_eval(row) for row in Y_soft_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c8ae3",
   "metadata": {},
   "source": [
    "Architecture: Distilled DAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b2da3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilledDAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation for Deep Averaging Network for sentiment analysis\n",
    "    Uses Hinton et al.'s 'distillation loss' which compares soft labels from a teacher model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes,\n",
    "                       embedding_dim: int, \n",
    "                       hidden_dim1: int, \n",
    "                       hidden_dim2: int, \n",
    "                       hidden_dim3: int, \n",
    "                       leaky_relu_negative_slope: float, \n",
    "                       dropout_probability: float,\n",
    "                       has_third_hidden_layer: bool,\n",
    "                       has_dropout_on_input: bool\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Create the network architecture. \n",
    "        In our sentiment analysis, we have three classes: 0, 1, 2\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.hidden_dim3 = hidden_dim3\n",
    "        self.leaky_relu_negative_slope = leaky_relu_negative_slope\n",
    "        self.dropout_probability = dropout_probability\n",
    "        \n",
    "        self.hidden1 = nn.Linear(self.embedding_dim, self.hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(self.hidden_dim1,self.hidden_dim2)\n",
    "        self.theta = nn.Linear(self.hidden_dim2, self.num_classes)\n",
    "\n",
    "        # Check if hidden3 set to True and adjust theta dimensions accordingly\n",
    "        if has_third_hidden_layer:\n",
    "            self.hidden3 = nn.Linear(self.hidden_dim2,self.hidden_dim3)\n",
    "            self.theta = nn.Linear(self.hidden_dim3, self.num_classes)\n",
    "        \n",
    "        self.log_softmax = nn.Softmax(dim=1) # A dimension along which LogSoftmax will be computed.\n",
    "        self.apply_dropout = nn.Dropout(self.dropout_probability)\n",
    "        self.has_dropout_on_input = has_dropout_on_input\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor containing embedded word vectors.\n",
    "                              Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Log probability of each class. Shape: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Average the input word embeddings\n",
    "        if self.has_dropout_on_input:\n",
    "            x = self.apply_dropout(x)\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Pass through the shared layers\n",
    "        x = self.hidden1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=self.leaky_relu_negative_slope)\n",
    "        x = self.apply_dropout(x)\n",
    "\n",
    "        x = self.hidden2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=self.leaky_relu_negative_slope)\n",
    "        x = self.apply_dropout(x)\n",
    "\n",
    "        # Pass through final layer\n",
    "        x = self.theta(x)\n",
    "\n",
    "        # Apply the LogSoftmax activation function\n",
    "        x = self.log_softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def train_model(self,\n",
    "                    X_train,\n",
    "                    Y_train,\n",
    "                    X_dev,\n",
    "                    Y_dev,\n",
    "                    soft_labels,\n",
    "                    optimizer,\n",
    "                    num_iterations,\n",
    "                    soft_label_weight=0.5,\n",
    "                    loss_fn=nn.CrossEntropyLoss(),\n",
    "                    batch_size=1000,\n",
    "                    check_every=10,\n",
    "                    verbose=False):\n",
    "        \"\"\"\n",
    "        Method to train the model. \n",
    "\n",
    "        soft_labels are only available for the training set. \n",
    "        \"\"\"\n",
    "\n",
    "        # Let the model know that we're in training mode, which is important for dropout\n",
    "        self.train()\n",
    "\n",
    "        loss_history = []\n",
    "        train_accuracy = []\n",
    "        dev_accuracy = []\n",
    "\n",
    "        for t in range(num_iterations):\n",
    "            if batch_size >= X_train.shape[0]: \n",
    "                X_batch = X_train\n",
    "                Y_batch = Y_train\n",
    "                soft_labels_batch = soft_labels\n",
    "            else:\n",
    "                batch_indices = np.random.randint(X_train.shape[0], size=batch_size)\n",
    "                X_batch = X_train[batch_indices]\n",
    "                Y_batch = Y_train[batch_indices]\n",
    "                soft_labels_batch = soft_labels[batch_indices]\n",
    "\n",
    "            # Forward pass \n",
    "            log_probs_batch = self.forward(X_batch)\n",
    "\n",
    "            # Distillation loss (cross entropy loss with hard labels + cross entropy loss with soft labels)\n",
    "            # weighted with soft and hard label\n",
    "            loss = (1 - soft_label_weight) * loss_fn(log_probs_batch, Y_batch) + \\\n",
    "                    soft_label_weight * loss_fn(log_probs_batch, soft_labels_batch)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % check_every == 0:\n",
    "                loss_value = loss.item()\n",
    "                loss_history.append(loss_value)\n",
    "\n",
    "                # Check train accuracy (entire set, not just batch) \n",
    "                train_y_pred = self.predict(X_train)\n",
    "                train_acc = self.accuracy(train_y_pred, Y_train.detach().numpy()) \n",
    "                train_accuracy.append(train_acc)\n",
    "\n",
    "                # Check dev accuracy (entire set, not just batch) \n",
    "                dev_y_pred = self.predict(X_dev)\n",
    "                dev_acc = self.accuracy(dev_y_pred, Y_dev.detach().numpy())\n",
    "                dev_accuracy.append(dev_acc)\n",
    "\n",
    "                if verbose: print(f\"Iteration={t}, Loss={loss_value}\")\n",
    "\n",
    "        return loss_history, train_accuracy, dev_accuracy\n",
    "\n",
    "    \n",
    "    def predict(self, X, proba_mode=False):\n",
    "        \"\"\"\n",
    "        Method to make predictions given a trained model. \n",
    "        \n",
    "        No need to modify this method. \n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        log_probs_batch = self.forward(X)\n",
    "\n",
    "        if proba_mode:\n",
    "            return log_probs_batch\n",
    "        else:\n",
    "            # Convert log probabilities to labels\n",
    "            label_batch = proba_to_label(log_probs_batch)\n",
    "            return label_batch\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_pred: np.ndarray, y_true: np.ndarray) -> float: \n",
    "        \"\"\"\n",
    "        Calculates accuracy. \n",
    "        \"\"\"\n",
    "        return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638daadd",
   "metadata": {},
   "source": [
    "### Grid Search to Tune Hyperparameters\n",
    "Parameters to tune:\n",
    "\n",
    "- learning rate\n",
    "- dropout probability\n",
    "- soft label weight\n",
    "- hidden layer dimensionality\n",
    "- training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9e6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch random seed\n",
    "torch.manual_seed(4)\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419e09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_22011/2578902843.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(Xmat_train, dtype=torch.float32)\n",
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_22011/2578902843.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_22011/2578902843.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_dev = torch.tensor(Xmat_dev, dtype=torch.float32)\n",
      "/var/folders/2m/s6xvfp8x29j9m9pl6w7jn8hh0000gn/T/ipykernel_22011/2578902843.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_dev = torch.tensor(Y_dev, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Load and pre-process data\n",
    "X_train = torch.tensor(Xmat_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "X_dev = torch.tensor(Xmat_dev, dtype=torch.float32)\n",
    "Y_dev = torch.tensor(Y_dev, dtype=torch.long)\n",
    "soft_labels = torch.tensor(Y_soft_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110df412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_student(hidden3=False):\n",
    "    '''\n",
    "    Performs a grid search to pick the combination of hyperparameters for the student\n",
    "    Distilled Deep Averaging Network with the best accuracy on the task of sentiment analysis\n",
    "    \n",
    "    Fixed parameters:\n",
    "    - input embedding (pre-trained GloVE embeddings, 50d, vocab of 1.2M)\n",
    "    - loss function\n",
    "    - number of iterations of gradient descent\n",
    "    \n",
    "    Hyper parameters:\n",
    "    - learning rate [1e-5, 1e-4, 1e-3, 1e-2] \n",
    "    - dropout probability [0.0, 0.2, 0.4, 0.6, 0.8] \n",
    "    - soft label weight [0.0, 0.2, 0.5, 0.4, 0.6, 0.8]\n",
    "    - hidden layer dimensionality\n",
    "    - training batch size\n",
    "\n",
    "    Potential Future Step:\n",
    "    - test performance with dropout on input embeddings\n",
    "    - test performance with more hidden layers\n",
    "    \n",
    "    Returns \n",
    "        1) array of dictionaries containing 'train accuracies', 'dev accuracies', 'best iteration' \n",
    "        (containing the index of the dev accuracies array with the highest value), 'loss history'\n",
    "        2) dictionary containing the combination of hyperparameters with the highest dev accuracy\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    best = {}\n",
    "    overall_best_dev_accuracy = 0\n",
    "    \n",
    "    # Hyperparameters\n",
    "    learning_rates = [.0001, .001, .01]\n",
    "    dropout_probs = [0.0,0.25]\n",
    "    soft_label_weights = [0.0, 0.2, 0.5, 0.8]\n",
    "    dropout_input = [False]\n",
    "    batch_sizes = [500, 1000]\n",
    "    hidden_dims1 = [64, 128]\n",
    "    hidden_dims2 = [32, 64]\n",
    "    \n",
    "    # Fixed parameters, model architecture\n",
    "    num_classes = 3\n",
    "    embedding_dim = 50\n",
    "    leaky_relu_negative_slope = 0.1\n",
    "    \n",
    "    # Fixed parameters, model training\n",
    "    num_iterations = 10000\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    check_every = 10\n",
    "    verbose = False\n",
    "    \n",
    "    # Grid Search\n",
    "    for learning_rate in learning_rates:\n",
    "        for dropout_prob in dropout_probs:\n",
    "            for soft_label_weight in soft_label_weights:\n",
    "                for is_dropout_input in dropout_input:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        for hidden_dim1 in hidden_dims1:\n",
    "                            for hidden_dim2 in hidden_dims2:\n",
    "\n",
    "                                # Create model\n",
    "                                model = DistilledDAN(num_classes, embedding_dim, hidden_dim1, hidden_dim2, 0,\n",
    "                                                     leaky_relu_negative_slope, dropout_prob, hidden3, is_dropout_input)\n",
    "\n",
    "                                # Step 3: Train the model using the `train_model` method\n",
    "                                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                                loss_history, train_accuracy, dev_accuracy = model.train_model(X_train, Y_train, X_dev, Y_dev, soft_labels, optimizer, num_iterations, soft_label_weight, loss_fn, batch_size, check_every, verbose)\n",
    "\n",
    "                                best_dev_iteration = np.argmax(dev_accuracy)\n",
    "\n",
    "                                hyperparameters = {'learning rate': learning_rate,\n",
    "                                                   'dropout prob': dropout_prob, \n",
    "                                                   'soft label weight': soft_label_weight,\n",
    "                                                   'is_dropout_input': is_dropout_input,\n",
    "                                                   'batch size': batch_size,\n",
    "                                                   'hidden_dim1': hidden_dim1,\n",
    "                                                   'hidden_dim2': hidden_dim2}\n",
    "\n",
    "                                result = {'hyperparameters': hyperparameters,\n",
    "                                          'train accuracy at best dev iter': train_accuracy[best_dev_iteration], \n",
    "                                          'best dev accuracy': dev_accuracy[best_dev_iteration], \n",
    "                                          'best dev iteration': best_dev_iteration}\n",
    "\n",
    "                                # Update best overall dev accuracy to get the best model hyperparameters\n",
    "                                # at end of grid search\n",
    "                                if dev_accuracy[best_dev_iteration] > overall_best_dev_accuracy:\n",
    "                                    overall_best_dev_accuracy = dev_accuracy[best_dev_iteration]\n",
    "                                    best = result\n",
    "                                \n",
    "                                print(result)\n",
    "                                results.append(result)\n",
    "    \n",
    "    return results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5c6b459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5773977858160693, 'best dev accuracy': 0.5655, 'best dev iteration': 943}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5837114984106105, 'best dev accuracy': 0.5655, 'best dev iteration': 989}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5865833607365998, 'best dev accuracy': 0.5715, 'best dev iteration': 963}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5854214622382988, 'best dev accuracy': 0.572, 'best dev iteration': 867}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5862325989257919, 'best dev accuracy': 0.5755, 'best dev iteration': 919}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5916255617669626, 'best dev accuracy': 0.5805, 'best dev iteration': 987}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5909678833716979, 'best dev accuracy': 0.5805, 'best dev iteration': 988}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.591779020059191, 'best dev accuracy': 0.5815, 'best dev iteration': 973}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5832072783075742, 'best dev accuracy': 0.5665, 'best dev iteration': 968}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5846541707771566, 'best dev accuracy': 0.574, 'best dev iteration': 867}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.58726296174504, 'best dev accuracy': 0.573, 'best dev iteration': 984}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5892579195440096, 'best dev accuracy': 0.5775, 'best dev iteration': 991}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5899813657788008, 'best dev accuracy': 0.573, 'best dev iteration': 997}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5906171215608901, 'best dev accuracy': 0.5755, 'best dev iteration': 995}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5918228652855421, 'best dev accuracy': 0.58, 'best dev iteration': 933}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5937959004713362, 'best dev accuracy': 0.581, 'best dev iteration': 986}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5840841828345938, 'best dev accuracy': 0.5715, 'best dev iteration': 909}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5904198180423107, 'best dev accuracy': 0.5775, 'best dev iteration': 969}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5889729255727283, 'best dev accuracy': 0.5795, 'best dev iteration': 983}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5928532281047901, 'best dev accuracy': 0.581, 'best dev iteration': 939}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5895648361284666, 'best dev accuracy': 0.573, 'best dev iteration': 982}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5916694069933136, 'best dev accuracy': 0.5815, 'best dev iteration': 962}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5924805436808067, 'best dev accuracy': 0.581, 'best dev iteration': 989}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5928970733311411, 'best dev accuracy': 0.582, 'best dev iteration': 924}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5885125506960429, 'best dev accuracy': 0.569, 'best dev iteration': 999}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5902005919105557, 'best dev accuracy': 0.5735, 'best dev iteration': 969}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5912309547298038, 'best dev accuracy': 0.579, 'best dev iteration': 993}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5931601446892469, 'best dev accuracy': 0.5815, 'best dev iteration': 980}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5915378713142606, 'best dev accuracy': 0.576, 'best dev iteration': 933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5935985969527567, 'best dev accuracy': 0.5785, 'best dev iteration': 932}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5949358763564617, 'best dev accuracy': 0.5815, 'best dev iteration': 963}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5946947276115313, 'best dev accuracy': 0.5835, 'best dev iteration': 864}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.578011618984983, 'best dev accuracy': 0.567, 'best dev iteration': 934}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5819138441302203, 'best dev accuracy': 0.566, 'best dev iteration': 965}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5867806642551792, 'best dev accuracy': 0.573, 'best dev iteration': 952}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5867368190288282, 'best dev accuracy': 0.575, 'best dev iteration': 933}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5846322481639812, 'best dev accuracy': 0.5695, 'best dev iteration': 920}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5885783185355694, 'best dev accuracy': 0.5775, 'best dev iteration': 974}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5855749205305273, 'best dev accuracy': 0.5755, 'best dev iteration': 944}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5921297818699989, 'best dev accuracy': 0.582, 'best dev iteration': 998}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.586101063246739, 'best dev accuracy': 0.5685, 'best dev iteration': 995}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5857503014359312, 'best dev accuracy': 0.57, 'best dev iteration': 968}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5846541707771566, 'best dev accuracy': 0.569, 'best dev iteration': 944}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5829880521758194, 'best dev accuracy': 0.5735, 'best dev iteration': 937}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.588468705469692, 'best dev accuracy': 0.573, 'best dev iteration': 968}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5921297818699989, 'best dev accuracy': 0.5795, 'best dev iteration': 934}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5915817165406116, 'best dev accuracy': 0.58, 'best dev iteration': 968}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5933574482078263, 'best dev accuracy': 0.5845, 'best dev iteration': 919}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5846322481639812, 'best dev accuracy': 0.569, 'best dev iteration': 888}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.585969527567686, 'best dev accuracy': 0.5725, 'best dev iteration': 903}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5876794913953743, 'best dev accuracy': 0.5725, 'best dev iteration': 932}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.591866710511893, 'best dev accuracy': 0.5805, 'best dev iteration': 876}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5912528773429793, 'best dev accuracy': 0.5785, 'best dev iteration': 981}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5938616683108626, 'best dev accuracy': 0.5825, 'best dev iteration': 972}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5935766743395813, 'best dev accuracy': 0.5795, 'best dev iteration': 979}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5957470130439548, 'best dev accuracy': 0.584, 'best dev iteration': 988}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5890606160254303, 'best dev accuracy': 0.573, 'best dev iteration': 964}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5897182944206949, 'best dev accuracy': 0.579, 'best dev iteration': 904}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5903759728159597, 'best dev accuracy': 0.578, 'best dev iteration': 977}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.593203989915598, 'best dev accuracy': 0.5815, 'best dev iteration': 943}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5929409185574921, 'best dev accuracy': 0.581, 'best dev iteration': 993}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5931382220760715, 'best dev accuracy': 0.5785, 'best dev iteration': 959}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5938835909240382, 'best dev accuracy': 0.5815, 'best dev iteration': 944}\n",
      "{'hyperparameters': {'learning rate': 0.0001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5939274361503891, 'best dev accuracy': 0.582, 'best dev iteration': 900}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5978515839088019, 'best dev accuracy': 0.595, 'best dev iteration': 844}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5985750301435931, 'best dev accuracy': 0.591, 'best dev iteration': 991}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5988161788885236, 'best dev accuracy': 0.5925, 'best dev iteration': 798}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5998026964814206, 'best dev accuracy': 0.593, 'best dev iteration': 960}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6001973035185794, 'best dev accuracy': 0.5945, 'best dev iteration': 962}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5985531075304176, 'best dev accuracy': 0.5935, 'best dev iteration': 839}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5983119587854873, 'best dev accuracy': 0.595, 'best dev iteration': 819}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5990792502466294, 'best dev accuracy': 0.594, 'best dev iteration': 932}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5976104351638716, 'best dev accuracy': 0.59, 'best dev iteration': 885}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5967554532500274, 'best dev accuracy': 0.5925, 'best dev iteration': 716}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5998026964814206, 'best dev accuracy': 0.5935, 'best dev iteration': 907}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5980708100405568, 'best dev accuracy': 0.5945, 'best dev iteration': 912}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6003946070371589, 'best dev accuracy': 0.5935, 'best dev iteration': 965}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5992107859256823, 'best dev accuracy': 0.5935, 'best dev iteration': 826}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6018195768935657, 'best dev accuracy': 0.594, 'best dev iteration': 834}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6019511125726187, 'best dev accuracy': 0.5965, 'best dev iteration': 972}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5995834703496656, 'best dev accuracy': 0.592, 'best dev iteration': 953}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5997588512550696, 'best dev accuracy': 0.5945, 'best dev iteration': 997}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5987284884358216, 'best dev accuracy': 0.5915, 'best dev iteration': 760}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6106105447769374, 'best dev accuracy': 0.6155, 'best dev iteration': 973}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6007892140743176, 'best dev accuracy': 0.5945, 'best dev iteration': 961}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5997150060287186, 'best dev accuracy': 0.5945, 'best dev iteration': 911}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6009645949797215, 'best dev accuracy': 0.593, 'best dev iteration': 935}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6026307135810589, 'best dev accuracy': 0.597, 'best dev iteration': 977}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6005919105557382, 'best dev accuracy': 0.593, 'best dev iteration': 962}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5991669406993314, 'best dev accuracy': 0.5895, 'best dev iteration': 926}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.608133289488107, 'best dev accuracy': 0.612, 'best dev iteration': 964}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6039679929847638, 'best dev accuracy': 0.603, 'best dev iteration': 997}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5997369286418941, 'best dev accuracy': 0.592, 'best dev iteration': 802}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6004822974898608, 'best dev accuracy': 0.596, 'best dev iteration': 967}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5997807738682451, 'best dev accuracy': 0.5945, 'best dev iteration': 822}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6045379809273266, 'best dev accuracy': 0.5985, 'best dev iteration': 960}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5982900361723117, 'best dev accuracy': 0.592, 'best dev iteration': 869}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5990573276334539, 'best dev accuracy': 0.5915, 'best dev iteration': 995}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5985750301435931, 'best dev accuracy': 0.592, 'best dev iteration': 787}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5984215718513647, 'best dev accuracy': 0.5935, 'best dev iteration': 893}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6003507618108078, 'best dev accuracy': 0.5915, 'best dev iteration': 987}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5972815959662392, 'best dev accuracy': 0.592, 'best dev iteration': 620}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.596426614052395, 'best dev accuracy': 0.5955, 'best dev iteration': 740}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6009865175928971, 'best dev accuracy': 0.599, 'best dev iteration': 996}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5961196974679381, 'best dev accuracy': 0.589, 'best dev iteration': 747}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6002630713581059, 'best dev accuracy': 0.5925, 'best dev iteration': 972}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5989038693412255, 'best dev accuracy': 0.592, 'best dev iteration': 891}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.601030362819248, 'best dev accuracy': 0.594, 'best dev iteration': 992}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5992765537652088, 'best dev accuracy': 0.5945, 'best dev iteration': 809}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6020168804121451, 'best dev accuracy': 0.596, 'best dev iteration': 978}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6015565055354598, 'best dev accuracy': 0.5945, 'best dev iteration': 992}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6014030472432313, 'best dev accuracy': 0.5965, 'best dev iteration': 936}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5993861668310863, 'best dev accuracy': 0.5895, 'best dev iteration': 871}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5998465417077715, 'best dev accuracy': 0.5915, 'best dev iteration': 976}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.599912309547298, 'best dev accuracy': 0.593, 'best dev iteration': 717}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6012715115641785, 'best dev accuracy': 0.5965, 'best dev iteration': 897}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.599956154773649, 'best dev accuracy': 0.595, 'best dev iteration': 979}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5998026964814206, 'best dev accuracy': 0.5965, 'best dev iteration': 900}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6020168804121451, 'best dev accuracy': 0.596, 'best dev iteration': 969}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6027622492601118, 'best dev accuracy': 0.601, 'best dev iteration': 946}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5997588512550696, 'best dev accuracy': 0.5945, 'best dev iteration': 913}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.5981146552669078, 'best dev accuracy': 0.5955, 'best dev iteration': 915}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5996930834155432, 'best dev accuracy': 0.594, 'best dev iteration': 882}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6006357557820893, 'best dev accuracy': 0.594, 'best dev iteration': 904}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5998026964814206, 'best dev accuracy': 0.5925, 'best dev iteration': 933}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.599013482407103, 'best dev accuracy': 0.5945, 'best dev iteration': 845}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.5985750301435931, 'best dev accuracy': 0.5965, 'best dev iteration': 999}\n",
      "{'hyperparameters': {'learning rate': 0.001, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6008769045270196, 'best dev accuracy': 0.5995, 'best dev iteration': 974}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6205414885454346, 'best dev accuracy': 0.618, 'best dev iteration': 923}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6155869779677737, 'best dev accuracy': 0.6175, 'best dev iteration': 603}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6201030362819248, 'best dev accuracy': 0.6195, 'best dev iteration': 975}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6224487558917023, 'best dev accuracy': 0.6175, 'best dev iteration': 994}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6243998684643209, 'best dev accuracy': 0.6215, 'best dev iteration': 845}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6229748986079141, 'best dev accuracy': 0.62, 'best dev iteration': 647}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6220541488545435, 'best dev accuracy': 0.6195, 'best dev iteration': 697}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6277321056669956, 'best dev accuracy': 0.6175, 'best dev iteration': 885}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6186780664255179, 'best dev accuracy': 0.619, 'best dev iteration': 718}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6228652855420366, 'best dev accuracy': 0.618, 'best dev iteration': 877}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6222514523731228, 'best dev accuracy': 0.62, 'best dev iteration': 813}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6185465307464649, 'best dev accuracy': 0.619, 'best dev iteration': 743}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.626548284555519, 'best dev accuracy': 0.621, 'best dev iteration': 922}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6220760714677189, 'best dev accuracy': 0.6235, 'best dev iteration': 713}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6284993971281376, 'best dev accuracy': 0.6235, 'best dev iteration': 920}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6190945960758523, 'best dev accuracy': 0.6185, 'best dev iteration': 420}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.62323796996602, 'best dev accuracy': 0.62, 'best dev iteration': 939}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.621944535788666, 'best dev accuracy': 0.6205, 'best dev iteration': 987}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6189630603967993, 'best dev accuracy': 0.62, 'best dev iteration': 732}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6222952975994739, 'best dev accuracy': 0.617, 'best dev iteration': 949}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.627754028280171, 'best dev accuracy': 0.6235, 'best dev iteration': 897}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6285213197413132, 'best dev accuracy': 0.6215, 'best dev iteration': 976}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6276882604406445, 'best dev accuracy': 0.6235, 'best dev iteration': 970}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6295078373342102, 'best dev accuracy': 0.6195, 'best dev iteration': 905}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6211991669406993, 'best dev accuracy': 0.6185, 'best dev iteration': 657}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6210457086484709, 'best dev accuracy': 0.6195, 'best dev iteration': 764}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.624268332785268, 'best dev accuracy': 0.619, 'best dev iteration': 956}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6188315247177464, 'best dev accuracy': 0.6185, 'best dev iteration': 883}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6212868573934013, 'best dev accuracy': 0.626, 'best dev iteration': 680}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6269648142058534, 'best dev accuracy': 0.625, 'best dev iteration': 801}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.628740545873068, 'best dev accuracy': 0.626, 'best dev iteration': 971}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.0, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6201249588951003, 'best dev accuracy': 0.6205, 'best dev iteration': 389}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6183053820015346, 'best dev accuracy': 0.618, 'best dev iteration': 833}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6162446563630385, 'best dev accuracy': 0.6185, 'best dev iteration': 566}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6179326975775512, 'best dev accuracy': 0.6175, 'best dev iteration': 886}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6177573166721473, 'best dev accuracy': 0.6175, 'best dev iteration': 941}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6224268332785268, 'best dev accuracy': 0.619, 'best dev iteration': 729}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6250137016332347, 'best dev accuracy': 0.618, 'best dev iteration': 917}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6170777156637071, 'best dev accuracy': 0.618, 'best dev iteration': 960}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6253644634440425, 'best dev accuracy': 0.621, 'best dev iteration': 906}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6183492272278855, 'best dev accuracy': 0.6205, 'best dev iteration': 787}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6196426614052395, 'best dev accuracy': 0.6255, 'best dev iteration': 850}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6201688041214513, 'best dev accuracy': 0.6215, 'best dev iteration': 960}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6203222624136797, 'best dev accuracy': 0.6195, 'best dev iteration': 699}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6204757207059082, 'best dev accuracy': 0.6235, 'best dev iteration': 840}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.625430231283569, 'best dev accuracy': 0.621, 'best dev iteration': 869}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6217691548832621, 'best dev accuracy': 0.621, 'best dev iteration': 497}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6267017428477475, 'best dev accuracy': 0.619, 'best dev iteration': 888}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6167488764660748, 'best dev accuracy': 0.618, 'best dev iteration': 533}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6208922503562425, 'best dev accuracy': 0.622, 'best dev iteration': 993}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6193357448207827, 'best dev accuracy': 0.6195, 'best dev iteration': 828}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6171434835032336, 'best dev accuracy': 0.618, 'best dev iteration': 447}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6253206182176916, 'best dev accuracy': 0.621, 'best dev iteration': 774}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6278197961196975, 'best dev accuracy': 0.62, 'best dev iteration': 920}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6255617669626219, 'best dev accuracy': 0.6195, 'best dev iteration': 777}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6239614162008111, 'best dev accuracy': 0.6215, 'best dev iteration': 712}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6215718513646826, 'best dev accuracy': 0.617, 'best dev iteration': 924}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6221637619204209, 'best dev accuracy': 0.619, 'best dev iteration': 912}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6192699769812562, 'best dev accuracy': 0.6205, 'best dev iteration': 797}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 500, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6179765428039022, 'best dev accuracy': 0.6205, 'best dev iteration': 606}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.620738792064014, 'best dev accuracy': 0.6245, 'best dev iteration': 766}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 64, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6301874383426505, 'best dev accuracy': 0.624, 'best dev iteration': 980}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 32}, 'train accuracy at best dev iter': 0.6262632905842377, 'best dev accuracy': 0.6225, 'best dev iteration': 967}\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.625517921736271, 'best dev accuracy': 0.627, 'best dev iteration': 984}\n",
      "Total time:  9827.310186862946\n"
     ]
    }
   ],
   "source": [
    "# result is a dictionary containing the following keys:\n",
    "# 'hyperparameters': \n",
    "#     {'learning rate'\n",
    "#     'dropout prob'\n",
    "#     'soft label weight'\n",
    "#     'is_dropout_input'\n",
    "#     'batch size'\n",
    "#     'hidden_dim1'\n",
    "#     'hidden_dim2'}\n",
    "# 'train accuracy at best dev iter'\n",
    "# 'best dev accuracy'\n",
    "# 'best dev iteration'\n",
    "\n",
    "start = time.time()\n",
    "results, best = grid_search_student()\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "print(\"Total time: \", total_time)\n",
    "\n",
    "\n",
    "with open('grid_search_results/grid_search_results_10000.txt', 'w') as results_file:\n",
    "    for elem in results:\n",
    "        results_file.write('%s\\n' % elem)\n",
    "\n",
    "with open('grid_search_results/best_result_10000.txt', 'w') as f:\n",
    "    f.write('BEST: %s\\n' % best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42570a0b",
   "metadata": {},
   "source": [
    "# Results and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "451922ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def read_dictionaries_from_file(file_path):\n",
    "    dictionaries = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            dictionary = ast.literal_eval(line)\n",
    "            dictionaries.append(dictionary)\n",
    "    return dictionaries\n",
    "\n",
    "results = read_dictionaries_from_file(\"grid_search_results_10000.txt\")\n",
    "\n",
    "sorted_results = sorted(results, key=lambda d: d['best dev accuracy'], reverse=True)\n",
    "\n",
    "with open('grid_search_results/grid_search_results_sorted_10000.txt', 'w') as f:\n",
    "    for elem in sorted_results:\n",
    "        f.write('%s\\n' % elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c11dfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hyperparameters': {'learning rate': 0.01,\n",
       "   'dropout prob': 0.25,\n",
       "   'soft label weight': 0.8,\n",
       "   'is_dropout_input': False,\n",
       "   'batch size': 1000,\n",
       "   'hidden_dim1': 128,\n",
       "   'hidden_dim2': 64},\n",
       "  'train accuracy at best dev iter': 0.625517921736271,\n",
       "  'best dev accuracy': 0.627,\n",
       "  'best dev iteration': 984},\n",
       " {'hyperparameters': {'learning rate': 0.01,\n",
       "   'dropout prob': 0.0,\n",
       "   'soft label weight': 0.8,\n",
       "   'is_dropout_input': False,\n",
       "   'batch size': 1000,\n",
       "   'hidden_dim1': 64,\n",
       "   'hidden_dim2': 32},\n",
       "  'train accuracy at best dev iter': 0.6212868573934013,\n",
       "  'best dev accuracy': 0.626,\n",
       "  'best dev iteration': 680},\n",
       " {'hyperparameters': {'learning rate': 0.01,\n",
       "   'dropout prob': 0.0,\n",
       "   'soft label weight': 0.8,\n",
       "   'is_dropout_input': False,\n",
       "   'batch size': 1000,\n",
       "   'hidden_dim1': 128,\n",
       "   'hidden_dim2': 32},\n",
       "  'train accuracy at best dev iter': 0.628740545873068,\n",
       "  'best dev accuracy': 0.626,\n",
       "  'best dev iteration': 971},\n",
       " {'hyperparameters': {'learning rate': 0.01,\n",
       "   'dropout prob': 0.25,\n",
       "   'soft label weight': 0.2,\n",
       "   'is_dropout_input': False,\n",
       "   'batch size': 500,\n",
       "   'hidden_dim1': 64,\n",
       "   'hidden_dim2': 64},\n",
       "  'train accuracy at best dev iter': 0.6196426614052395,\n",
       "  'best dev accuracy': 0.6255,\n",
       "  'best dev iteration': 850},\n",
       " {'hyperparameters': {'learning rate': 0.01,\n",
       "   'dropout prob': 0.0,\n",
       "   'soft label weight': 0.8,\n",
       "   'is_dropout_input': False,\n",
       "   'batch size': 1000,\n",
       "   'hidden_dim1': 64,\n",
       "   'hidden_dim2': 64},\n",
       "  'train accuracy at best dev iter': 0.6269648142058534,\n",
       "  'best dev accuracy': 0.625,\n",
       "  'best dev iteration': 801}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dafe6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search goes through all the soft label weights while keeping the rest of the hyperparameters constant \n",
    "# (as the set of hyperparameters identified by the grid search)\n",
    "\n",
    "def grid_search_student_2(hidden3=False):\n",
    "    '''\n",
    "    Performs a grid search to pick the combination of hyperparameters for the student\n",
    "    Distilled Deep Averaging Network with the best accuracy on the task of sentiment analysis\n",
    "    \n",
    "    Fixed parameters:\n",
    "    - input embedding (pre-trained GloVE embeddings, 50d, vocab of 1.2M)\n",
    "    - loss function\n",
    "    - number of iterations of gradient descent\n",
    "    \n",
    "    Hyper parameters:\n",
    "    - learning rate [1e-5, 1e-4, 1e-3, 1e-2] \n",
    "    - dropout probability [0.0, 0.2, 0.4, 0.6, 0.8] \n",
    "    - soft label weight [0.0, 0.2, 0.5, 0.4, 0.6, 0.8]\n",
    "    - # of layers (2 or 3)\n",
    "\n",
    "    Potential Future Step:\n",
    "    - test performance with dropout on input embeddings\n",
    "    \n",
    "    Returns \n",
    "        1) array of dictionaries containing 'train accuracies', 'dev accuracies', 'best iteration' \n",
    "        (containing the index of the dev accuracies array with the highest value), 'loss history'\n",
    "        2) dictionary containing the combination of hyperparameters with the highest dev accuracy\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    best = {}\n",
    "    overall_best_dev_accuracy = 0\n",
    "    \n",
    "    # Hyperparameters\n",
    "    learning_rates = [.01]\n",
    "    dropout_probs = [0.25]\n",
    "    soft_label_weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    dropout_input = [False]\n",
    "    batch_sizes = [1000]\n",
    "    hidden_dims1 = [128]\n",
    "    hidden_dims2 = [64]\n",
    "    \n",
    "    # Fixed parameters, model architecture\n",
    "    num_classes = 3\n",
    "    embedding_dim = 50\n",
    "    leaky_relu_negative_slope = 0.1\n",
    "    \n",
    "    # Fixed parameters, model training\n",
    "    num_iterations = 10000\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    check_every = 10\n",
    "    verbose = False\n",
    "    \n",
    "    # Grid Search\n",
    "    for learning_rate in learning_rates:\n",
    "        for dropout_prob in dropout_probs:\n",
    "            for soft_label_weight in soft_label_weights:\n",
    "                for is_dropout_input in dropout_input:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        for hidden_dim1 in hidden_dims1:\n",
    "                            for hidden_dim2 in hidden_dims2:\n",
    "                                \n",
    "                                print(learning_rate)\n",
    "\n",
    "                                # Create model\n",
    "                                model = DistilledDAN(num_classes, embedding_dim, hidden_dim1, hidden_dim2, 0,\n",
    "                                                     leaky_relu_negative_slope, dropout_prob, hidden3, is_dropout_input)\n",
    "\n",
    "                                # Step 3: Train the model using the `train_model` method\n",
    "                                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                                loss_history, train_accuracy, dev_accuracy = model.train_model(X_train, Y_train, X_dev, Y_dev, soft_labels, optimizer, num_iterations, soft_label_weight, loss_fn, batch_size, check_every, verbose)\n",
    "\n",
    "                                best_dev_iteration = np.argmax(dev_accuracy)\n",
    "\n",
    "                                hyperparameters = {'learning rate': learning_rate,\n",
    "                                                   'dropout prob': dropout_prob, \n",
    "                                                   'soft label weight': soft_label_weight,\n",
    "                                                   'is_dropout_input': is_dropout_input,\n",
    "                                                   'batch size': batch_size,\n",
    "                                                   'hidden_dim1': hidden_dim1,\n",
    "                                                   'hidden_dim2': hidden_dim2}\n",
    "\n",
    "                                result = {'hyperparameters': hyperparameters,\n",
    "                                          'train accuracy at best dev iter': train_accuracy[best_dev_iteration], \n",
    "                                          'best dev accuracy': dev_accuracy[best_dev_iteration], \n",
    "                                          'best dev iteration': best_dev_iteration}\n",
    "\n",
    "                                # Update best overall dev accuracy to get the best model hyperparameters\n",
    "                                # at end of grid search\n",
    "                                if dev_accuracy[best_dev_iteration] > overall_best_dev_accuracy:\n",
    "                                    overall_best_dev_accuracy = dev_accuracy[best_dev_iteration]\n",
    "                                    best = result\n",
    "                                \n",
    "                                print(result)\n",
    "                                results.append(result)\n",
    "    \n",
    "    return results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17a704d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.618590375972816, 'best dev accuracy': 0.619, 'best dev iteration': 843}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.1, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6217033870437356, 'best dev accuracy': 0.625, 'best dev iteration': 965}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.2, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6269428915926778, 'best dev accuracy': 0.62, 'best dev iteration': 938}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.3, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6178669297380248, 'best dev accuracy': 0.619, 'best dev iteration': 408}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.4, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6274032664693632, 'best dev accuracy': 0.6215, 'best dev iteration': 805}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.5, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.625342540830867, 'best dev accuracy': 0.623, 'best dev iteration': 999}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.6, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6226022141839307, 'best dev accuracy': 0.6215, 'best dev iteration': 763}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.6, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6239175709744601, 'best dev accuracy': 0.622, 'best dev iteration': 709}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.8, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6270744272717308, 'best dev accuracy': 0.623, 'best dev iteration': 893}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 0.9, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6269428915926778, 'best dev accuracy': 0.6225, 'best dev iteration': 949}\n",
      "0.01\n",
      "{'hyperparameters': {'learning rate': 0.01, 'dropout prob': 0.25, 'soft label weight': 1.0, 'is_dropout_input': False, 'batch size': 1000, 'hidden_dim1': 128, 'hidden_dim2': 64}, 'train accuracy at best dev iter': 0.6203880302532062, 'best dev accuracy': 0.6235, 'best dev iteration': 573}\n",
      "Total time:  2403.712137937546\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results, best = grid_search_student_2()\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "print(\"Total time: \", total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7e3bb",
   "metadata": {},
   "source": [
    "### Output of results:\n",
    "\n",
    "```\n",
    "[{'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.0,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.618590375972816,\n",
    "  'best dev accuracy': 0.619,\n",
    "  'best dev iteration': 843},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.1,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6217033870437356,\n",
    "  'best dev accuracy': 0.625,\n",
    "  'best dev iteration': 965},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.2,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6269428915926778,\n",
    "  'best dev accuracy': 0.62,\n",
    "  'best dev iteration': 938},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.3,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6178669297380248,\n",
    "  'best dev accuracy': 0.619,\n",
    "  'best dev iteration': 408},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.4,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6274032664693632,\n",
    "  'best dev accuracy': 0.6215,\n",
    "  'best dev iteration': 805},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.5,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.625342540830867,\n",
    "  'best dev accuracy': 0.623,\n",
    "  'best dev iteration': 999},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.6,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6226022141839307,\n",
    "  'best dev accuracy': 0.6215,\n",
    "  'best dev iteration': 763},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.7,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6239175709744601,\n",
    "  'best dev accuracy': 0.6225,\n",
    "  'best dev iteration': 709},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.8,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6270744272717308,\n",
    "  'best dev accuracy': 0.623,\n",
    "  'best dev iteration': 893},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 0.9,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6269428915926778,\n",
    "  'best dev accuracy': 0.6225,\n",
    "  'best dev iteration': 949},\n",
    " {'hyperparameters': {'learning rate': 0.01,\n",
    "   'dropout prob': 0.25,\n",
    "   'soft label weight': 1.0,\n",
    "   'is_dropout_input': False,\n",
    "   'batch size': 1000,\n",
    "   'hidden_dim1': 128,\n",
    "   'hidden_dim2': 64},\n",
    "  'train accuracy at best dev iter': 0.6203880302532062,\n",
    "  'best dev accuracy': 0.6235,\n",
    "  'best dev iteration': 573}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2bfea9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e46adbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your data\n",
    "data = results\n",
    "\n",
    "# Extract the necessary information\n",
    "soft_label_weights = [entry['hyperparameters']['soft label weight'] for entry in data]\n",
    "train_accuracies = [entry['train accuracy at best dev iter'] for entry in data]\n",
    "dev_accuracies = [entry['best dev accuracy'] for entry in data]\n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.plot(soft_label_weights, train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(soft_label_weights, dev_accuracies, marker='o', label='Dev Accuracy')\n",
    "\n",
    "# Set the y-axis range\n",
    "plt.ylim(0.6, 0.65)\n",
    "\n",
    "plt.xlabel('Soft Label Weight')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Soft Label Weight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb9042",
   "metadata": {},
   "source": [
    "### Run the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a90bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=0, Loss=1.0959248542785645\n",
      "Iteration=10, Loss=1.0477992296218872\n",
      "Iteration=20, Loss=1.0328383445739746\n",
      "Iteration=30, Loss=1.0257521867752075\n",
      "Iteration=40, Loss=1.005302906036377\n",
      "Iteration=50, Loss=1.0012120008468628\n",
      "Iteration=60, Loss=0.9961627125740051\n",
      "Iteration=70, Loss=0.9779399633407593\n",
      "Iteration=80, Loss=0.9838843941688538\n",
      "Iteration=90, Loss=0.9838460683822632\n",
      "Iteration=100, Loss=0.9989803433418274\n",
      "Iteration=110, Loss=0.9955161809921265\n",
      "Iteration=120, Loss=0.9812686443328857\n",
      "Iteration=130, Loss=0.9635843634605408\n",
      "Iteration=140, Loss=0.9664087891578674\n",
      "Iteration=150, Loss=0.9661003351211548\n",
      "Iteration=160, Loss=0.9593077898025513\n",
      "Iteration=170, Loss=0.9712860584259033\n",
      "Iteration=180, Loss=0.9717569947242737\n",
      "Iteration=190, Loss=0.9860913753509521\n",
      "Iteration=200, Loss=0.9817032814025879\n",
      "Iteration=210, Loss=1.0061264038085938\n",
      "Iteration=220, Loss=0.9782307744026184\n",
      "Iteration=230, Loss=0.9613000154495239\n",
      "Iteration=240, Loss=0.9687857031822205\n",
      "Iteration=250, Loss=0.960879921913147\n",
      "Iteration=260, Loss=0.9702922701835632\n",
      "Iteration=270, Loss=0.9476991891860962\n",
      "Iteration=280, Loss=0.9568573236465454\n",
      "Iteration=290, Loss=0.9642884731292725\n",
      "Iteration=300, Loss=0.9561734795570374\n",
      "Iteration=310, Loss=0.9561623930931091\n",
      "Iteration=320, Loss=0.9574843645095825\n",
      "Iteration=330, Loss=0.9445342421531677\n",
      "Iteration=340, Loss=0.9463008642196655\n",
      "Iteration=350, Loss=0.956986665725708\n",
      "Iteration=360, Loss=1.0055416822433472\n",
      "Iteration=370, Loss=1.0021545886993408\n",
      "Iteration=380, Loss=0.9651000499725342\n",
      "Iteration=390, Loss=0.9769139289855957\n",
      "Iteration=400, Loss=0.9455133676528931\n",
      "Iteration=410, Loss=0.9487830400466919\n",
      "Iteration=420, Loss=0.9644749164581299\n",
      "Iteration=430, Loss=0.9662858843803406\n",
      "Iteration=440, Loss=0.9776620864868164\n",
      "Iteration=450, Loss=0.9522857069969177\n",
      "Iteration=460, Loss=0.9571776986122131\n",
      "Iteration=470, Loss=0.9638724327087402\n",
      "Iteration=480, Loss=0.9417664408683777\n",
      "Iteration=490, Loss=0.9681196808815002\n",
      "Iteration=500, Loss=0.9658325910568237\n",
      "Iteration=510, Loss=0.9614757299423218\n",
      "Iteration=520, Loss=0.9327964782714844\n",
      "Iteration=530, Loss=0.9526219367980957\n",
      "Iteration=540, Loss=0.9689290523529053\n",
      "Iteration=550, Loss=0.96205735206604\n",
      "Iteration=560, Loss=0.9513213634490967\n",
      "Iteration=570, Loss=0.9717405438423157\n",
      "Iteration=580, Loss=0.9608873128890991\n",
      "Iteration=590, Loss=0.9540671110153198\n",
      "Iteration=600, Loss=0.9643213152885437\n",
      "Iteration=610, Loss=0.959567129611969\n",
      "Iteration=620, Loss=0.9760806560516357\n",
      "Iteration=630, Loss=0.9582885503768921\n",
      "Iteration=640, Loss=0.9431304931640625\n",
      "Iteration=650, Loss=0.9485070705413818\n",
      "Iteration=660, Loss=0.9560520648956299\n",
      "Iteration=670, Loss=0.9483250975608826\n",
      "Iteration=680, Loss=0.9452086091041565\n",
      "Iteration=690, Loss=0.942887544631958\n",
      "Iteration=700, Loss=0.937208890914917\n",
      "Iteration=710, Loss=0.9433831572532654\n",
      "Iteration=720, Loss=0.9398936033248901\n",
      "Iteration=730, Loss=0.9520266056060791\n",
      "Iteration=740, Loss=0.9344978332519531\n",
      "Iteration=750, Loss=0.9439789056777954\n",
      "Iteration=760, Loss=0.9636377692222595\n",
      "Iteration=770, Loss=0.9640738368034363\n",
      "Iteration=780, Loss=0.9563239812850952\n",
      "Iteration=790, Loss=0.9499918818473816\n",
      "Iteration=800, Loss=0.9793176054954529\n",
      "Iteration=810, Loss=0.9560162425041199\n",
      "Iteration=820, Loss=0.9574814438819885\n",
      "Iteration=830, Loss=0.9697242975234985\n",
      "Iteration=840, Loss=0.9492838382720947\n",
      "Iteration=850, Loss=0.9475957155227661\n",
      "Iteration=860, Loss=0.9790596961975098\n",
      "Iteration=870, Loss=0.9670270681381226\n",
      "Iteration=880, Loss=0.9491783380508423\n",
      "Iteration=890, Loss=0.9483938217163086\n",
      "Iteration=900, Loss=0.9478280544281006\n",
      "Iteration=910, Loss=0.9464686512947083\n",
      "Iteration=920, Loss=0.939807116985321\n",
      "Iteration=930, Loss=0.9451754093170166\n",
      "Iteration=940, Loss=0.9448519945144653\n",
      "Iteration=950, Loss=0.9453960657119751\n",
      "Iteration=960, Loss=0.9411532878875732\n",
      "Iteration=970, Loss=0.9344980716705322\n",
      "Iteration=980, Loss=0.9593902826309204\n",
      "Iteration=990, Loss=0.9410045742988586\n",
      "Iteration=1000, Loss=0.9330306649208069\n",
      "Iteration=1010, Loss=0.9646898508071899\n",
      "Iteration=1020, Loss=0.9262723922729492\n",
      "Iteration=1030, Loss=0.936663031578064\n",
      "Iteration=1040, Loss=0.9422390460968018\n",
      "Iteration=1050, Loss=0.9542638063430786\n",
      "Iteration=1060, Loss=0.9596200585365295\n",
      "Iteration=1070, Loss=0.9381752014160156\n",
      "Iteration=1080, Loss=0.9566906690597534\n",
      "Iteration=1090, Loss=0.956942617893219\n",
      "Iteration=1100, Loss=0.9519458413124084\n",
      "Iteration=1110, Loss=0.9538840055465698\n",
      "Iteration=1120, Loss=0.9582362174987793\n",
      "Iteration=1130, Loss=0.9495784044265747\n",
      "Iteration=1140, Loss=0.9533112049102783\n",
      "Iteration=1150, Loss=0.957933247089386\n",
      "Iteration=1160, Loss=0.9613091945648193\n",
      "Iteration=1170, Loss=0.9482700228691101\n",
      "Iteration=1180, Loss=0.9658110737800598\n",
      "Iteration=1190, Loss=0.9453011155128479\n",
      "Iteration=1200, Loss=0.9624918699264526\n",
      "Iteration=1210, Loss=0.9531060457229614\n",
      "Iteration=1220, Loss=0.9593385457992554\n",
      "Iteration=1230, Loss=0.9573794603347778\n",
      "Iteration=1240, Loss=0.9431726336479187\n",
      "Iteration=1250, Loss=0.9526926279067993\n",
      "Iteration=1260, Loss=0.9503970146179199\n",
      "Iteration=1270, Loss=0.9499732255935669\n",
      "Iteration=1280, Loss=0.9810253977775574\n",
      "Iteration=1290, Loss=0.9748215079307556\n",
      "Iteration=1300, Loss=0.967009961605072\n",
      "Iteration=1310, Loss=0.9579904079437256\n",
      "Iteration=1320, Loss=0.942672610282898\n",
      "Iteration=1330, Loss=0.9552059173583984\n",
      "Iteration=1340, Loss=0.9646469950675964\n",
      "Iteration=1350, Loss=0.9407757520675659\n",
      "Iteration=1360, Loss=0.9494476318359375\n",
      "Iteration=1370, Loss=0.9604787230491638\n",
      "Iteration=1380, Loss=0.9451291561126709\n",
      "Iteration=1390, Loss=0.9579613208770752\n",
      "Iteration=1400, Loss=0.9662687182426453\n",
      "Iteration=1410, Loss=0.9530367255210876\n",
      "Iteration=1420, Loss=0.9574925899505615\n",
      "Iteration=1430, Loss=0.9707353115081787\n",
      "Iteration=1440, Loss=0.9620887637138367\n",
      "Iteration=1450, Loss=0.93792724609375\n",
      "Iteration=1460, Loss=0.9365841150283813\n",
      "Iteration=1470, Loss=0.938264012336731\n",
      "Iteration=1480, Loss=0.9409593939781189\n",
      "Iteration=1490, Loss=0.9352099895477295\n",
      "Iteration=1500, Loss=0.91449373960495\n",
      "Iteration=1510, Loss=0.9265884160995483\n",
      "Iteration=1520, Loss=0.9354320168495178\n",
      "Iteration=1530, Loss=0.9250503182411194\n",
      "Iteration=1540, Loss=0.9359601736068726\n",
      "Iteration=1550, Loss=0.9487817287445068\n",
      "Iteration=1560, Loss=0.9352204203605652\n",
      "Iteration=1570, Loss=0.9396229982376099\n",
      "Iteration=1580, Loss=0.9339460134506226\n",
      "Iteration=1590, Loss=0.9313927888870239\n",
      "Iteration=1600, Loss=0.9263864755630493\n",
      "Iteration=1610, Loss=0.9342139959335327\n",
      "Iteration=1620, Loss=0.9120843410491943\n",
      "Iteration=1630, Loss=0.940281867980957\n",
      "Iteration=1640, Loss=0.9229176044464111\n",
      "Iteration=1650, Loss=0.9206887483596802\n",
      "Iteration=1660, Loss=0.9435418248176575\n",
      "Iteration=1670, Loss=0.942474901676178\n",
      "Iteration=1680, Loss=0.9505524635314941\n",
      "Iteration=1690, Loss=0.9163290858268738\n",
      "Iteration=1700, Loss=0.9317983984947205\n",
      "Iteration=1710, Loss=0.9135106205940247\n",
      "Iteration=1720, Loss=0.9225513935089111\n",
      "Iteration=1730, Loss=0.932365357875824\n",
      "Iteration=1740, Loss=0.9410749077796936\n",
      "Iteration=1750, Loss=0.933087170124054\n",
      "Iteration=1760, Loss=0.9478136897087097\n",
      "Iteration=1770, Loss=0.9306411743164062\n",
      "Iteration=1780, Loss=0.93044513463974\n",
      "Iteration=1790, Loss=0.9245859980583191\n",
      "Iteration=1800, Loss=0.9382506608963013\n",
      "Iteration=1810, Loss=0.9233396649360657\n",
      "Iteration=1820, Loss=0.9311935305595398\n",
      "Iteration=1830, Loss=0.9329600930213928\n",
      "Iteration=1840, Loss=0.9307594299316406\n",
      "Iteration=1850, Loss=0.9530352354049683\n",
      "Iteration=1860, Loss=0.9588250517845154\n",
      "Iteration=1870, Loss=0.9727835059165955\n",
      "Iteration=1880, Loss=0.9409329891204834\n",
      "Iteration=1890, Loss=0.9488918781280518\n",
      "Iteration=1900, Loss=0.9570207595825195\n",
      "Iteration=1910, Loss=0.9684064984321594\n",
      "Iteration=1920, Loss=0.9614437818527222\n",
      "Iteration=1930, Loss=0.9676176309585571\n",
      "Iteration=1940, Loss=0.9522658586502075\n",
      "Iteration=1950, Loss=0.9645900726318359\n",
      "Iteration=1960, Loss=0.9435074329376221\n",
      "Iteration=1970, Loss=0.9486969113349915\n",
      "Iteration=1980, Loss=0.9525103569030762\n",
      "Iteration=1990, Loss=0.9461456537246704\n",
      "Iteration=2000, Loss=0.9559629559516907\n",
      "Iteration=2010, Loss=0.9311313629150391\n",
      "Iteration=2020, Loss=0.946394681930542\n",
      "Iteration=2030, Loss=0.9385456442832947\n",
      "Iteration=2040, Loss=0.9581244587898254\n",
      "Iteration=2050, Loss=0.9527039527893066\n",
      "Iteration=2060, Loss=0.9501228332519531\n",
      "Iteration=2070, Loss=0.9753942489624023\n",
      "Iteration=2080, Loss=0.9552856087684631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2090, Loss=0.9611610770225525\n",
      "Iteration=2100, Loss=0.9555106163024902\n",
      "Iteration=2110, Loss=0.9742133617401123\n",
      "Iteration=2120, Loss=0.9442141652107239\n",
      "Iteration=2130, Loss=0.9572709202766418\n",
      "Iteration=2140, Loss=0.9433547854423523\n",
      "Iteration=2150, Loss=0.9402509927749634\n",
      "Iteration=2160, Loss=0.948486328125\n",
      "Iteration=2170, Loss=0.9433640241622925\n",
      "Iteration=2180, Loss=0.9653905034065247\n",
      "Iteration=2190, Loss=0.9505018591880798\n",
      "Iteration=2200, Loss=0.9491292238235474\n",
      "Iteration=2210, Loss=0.9553259015083313\n",
      "Iteration=2220, Loss=0.9428950548171997\n",
      "Iteration=2230, Loss=0.9769880771636963\n",
      "Iteration=2240, Loss=0.9422096014022827\n",
      "Iteration=2250, Loss=0.9419606924057007\n",
      "Iteration=2260, Loss=0.9611989855766296\n",
      "Iteration=2270, Loss=0.9545393586158752\n",
      "Iteration=2280, Loss=0.941720187664032\n",
      "Iteration=2290, Loss=0.9613977074623108\n",
      "Iteration=2300, Loss=0.9411066174507141\n",
      "Iteration=2310, Loss=0.9604606628417969\n",
      "Iteration=2320, Loss=0.958000123500824\n",
      "Iteration=2330, Loss=0.9299813508987427\n",
      "Iteration=2340, Loss=0.9496307373046875\n",
      "Iteration=2350, Loss=0.9350154995918274\n",
      "Iteration=2360, Loss=0.9335705041885376\n",
      "Iteration=2370, Loss=0.9249476194381714\n",
      "Iteration=2380, Loss=0.9080648422241211\n",
      "Iteration=2390, Loss=0.9327924251556396\n",
      "Iteration=2400, Loss=0.9553113579750061\n",
      "Iteration=2410, Loss=0.9986737370491028\n",
      "Iteration=2420, Loss=0.9398675560951233\n",
      "Iteration=2430, Loss=0.936060905456543\n",
      "Iteration=2440, Loss=0.9179090261459351\n",
      "Iteration=2450, Loss=0.9309811592102051\n",
      "Iteration=2460, Loss=0.9239408373832703\n",
      "Iteration=2470, Loss=0.9355483055114746\n",
      "Iteration=2480, Loss=0.9453016519546509\n",
      "Iteration=2490, Loss=0.9175518751144409\n",
      "Iteration=2500, Loss=0.9235000014305115\n",
      "Iteration=2510, Loss=0.9257999062538147\n",
      "Iteration=2520, Loss=0.9298694133758545\n",
      "Iteration=2530, Loss=0.9182369112968445\n",
      "Iteration=2540, Loss=0.9237962365150452\n",
      "Iteration=2550, Loss=0.9316737651824951\n",
      "Iteration=2560, Loss=0.9279117584228516\n",
      "Iteration=2570, Loss=0.9261430501937866\n",
      "Iteration=2580, Loss=0.9303188323974609\n",
      "Iteration=2590, Loss=0.9187437891960144\n",
      "Iteration=2600, Loss=0.9348229765892029\n",
      "Iteration=2610, Loss=0.9381361603736877\n",
      "Iteration=2620, Loss=0.9272922277450562\n",
      "Iteration=2630, Loss=0.9203590154647827\n",
      "Iteration=2640, Loss=0.9312229156494141\n",
      "Iteration=2650, Loss=0.9510747790336609\n",
      "Iteration=2660, Loss=0.9234157204627991\n",
      "Iteration=2670, Loss=0.9179352521896362\n",
      "Iteration=2680, Loss=0.9316405653953552\n",
      "Iteration=2690, Loss=0.9236125946044922\n",
      "Iteration=2700, Loss=0.9230242967605591\n",
      "Iteration=2710, Loss=0.9360077977180481\n",
      "Iteration=2720, Loss=0.9157154560089111\n",
      "Iteration=2730, Loss=0.9256818890571594\n",
      "Iteration=2740, Loss=0.9149027466773987\n",
      "Iteration=2750, Loss=0.9330376386642456\n",
      "Iteration=2760, Loss=0.9072887301445007\n",
      "Iteration=2770, Loss=0.9558703899383545\n",
      "Iteration=2780, Loss=0.9276587963104248\n",
      "Iteration=2790, Loss=0.9398621320724487\n",
      "Iteration=2800, Loss=0.9616035223007202\n",
      "Iteration=2810, Loss=0.9582552313804626\n",
      "Iteration=2820, Loss=0.9411485195159912\n",
      "Iteration=2830, Loss=0.9425715804100037\n",
      "Iteration=2840, Loss=0.9456304907798767\n",
      "Iteration=2850, Loss=0.9572413563728333\n",
      "Iteration=2860, Loss=0.9610379934310913\n",
      "Iteration=2870, Loss=0.961958646774292\n",
      "Iteration=2880, Loss=0.9550350308418274\n",
      "Iteration=2890, Loss=0.9694446325302124\n",
      "Iteration=2900, Loss=0.945469319820404\n",
      "Iteration=2910, Loss=0.9536153078079224\n",
      "Iteration=2920, Loss=0.9538362622261047\n",
      "Iteration=2930, Loss=0.9486560821533203\n",
      "Iteration=2940, Loss=0.9263132810592651\n",
      "Iteration=2950, Loss=0.9053299427032471\n",
      "Iteration=2960, Loss=0.9243565201759338\n",
      "Iteration=2970, Loss=0.933090090751648\n",
      "Iteration=2980, Loss=0.9364273548126221\n",
      "Iteration=2990, Loss=0.9301621913909912\n",
      "Iteration=3000, Loss=0.9041557908058167\n",
      "Iteration=3010, Loss=0.9272971749305725\n",
      "Iteration=3020, Loss=0.9267022013664246\n",
      "Iteration=3030, Loss=0.9163572788238525\n",
      "Iteration=3040, Loss=0.9318339824676514\n",
      "Iteration=3050, Loss=0.9290318489074707\n",
      "Iteration=3060, Loss=0.9160376191139221\n",
      "Iteration=3070, Loss=0.9252452254295349\n",
      "Iteration=3080, Loss=0.923724889755249\n",
      "Iteration=3090, Loss=0.9128736853599548\n",
      "Iteration=3100, Loss=0.9202449321746826\n",
      "Iteration=3110, Loss=0.932335376739502\n",
      "Iteration=3120, Loss=0.9403667449951172\n",
      "Iteration=3130, Loss=0.9259926080703735\n",
      "Iteration=3140, Loss=0.9121297597885132\n",
      "Iteration=3150, Loss=0.9112927913665771\n",
      "Iteration=3160, Loss=0.9402389526367188\n",
      "Iteration=3170, Loss=0.93929523229599\n",
      "Iteration=3180, Loss=0.9292042255401611\n",
      "Iteration=3190, Loss=0.9400306940078735\n",
      "Iteration=3200, Loss=0.9255574941635132\n",
      "Iteration=3210, Loss=0.9151552319526672\n",
      "Iteration=3220, Loss=0.9214526414871216\n",
      "Iteration=3230, Loss=0.918738067150116\n",
      "Iteration=3240, Loss=0.916064977645874\n",
      "Iteration=3250, Loss=0.9325659275054932\n",
      "Iteration=3260, Loss=0.9222326278686523\n",
      "Iteration=3270, Loss=0.9147480726242065\n",
      "Iteration=3280, Loss=0.9294208884239197\n",
      "Iteration=3290, Loss=0.9145092964172363\n",
      "Iteration=3300, Loss=0.9246305227279663\n",
      "Iteration=3310, Loss=0.9261897206306458\n",
      "Iteration=3320, Loss=0.9292429685592651\n",
      "Iteration=3330, Loss=0.9229898452758789\n",
      "Iteration=3340, Loss=0.9165371060371399\n",
      "Iteration=3350, Loss=0.8955739736557007\n",
      "Iteration=3360, Loss=0.9144911766052246\n",
      "Iteration=3370, Loss=0.9161393642425537\n",
      "Iteration=3380, Loss=0.9148430824279785\n",
      "Iteration=3390, Loss=0.9114187955856323\n",
      "Iteration=3400, Loss=0.9443285465240479\n",
      "Iteration=3410, Loss=0.94533371925354\n",
      "Iteration=3420, Loss=0.9370635747909546\n",
      "Iteration=3430, Loss=0.9364553689956665\n",
      "Iteration=3440, Loss=0.9356791377067566\n",
      "Iteration=3450, Loss=0.9262540936470032\n",
      "Iteration=3460, Loss=0.9153873324394226\n",
      "Iteration=3470, Loss=0.9296386241912842\n",
      "Iteration=3480, Loss=0.9262233972549438\n",
      "Iteration=3490, Loss=0.9310367107391357\n",
      "Iteration=3500, Loss=0.9419237375259399\n",
      "Iteration=3510, Loss=0.9150760769844055\n",
      "Iteration=3520, Loss=0.9181729555130005\n",
      "Iteration=3530, Loss=0.9452340006828308\n",
      "Iteration=3540, Loss=0.9193147420883179\n",
      "Iteration=3550, Loss=0.9120492935180664\n",
      "Iteration=3560, Loss=0.9327552318572998\n",
      "Iteration=3570, Loss=0.9163188338279724\n",
      "Iteration=3580, Loss=0.9196001291275024\n",
      "Iteration=3590, Loss=0.9350587129592896\n",
      "Iteration=3600, Loss=0.9152181148529053\n",
      "Iteration=3610, Loss=0.9245729446411133\n",
      "Iteration=3620, Loss=0.9266008138656616\n",
      "Iteration=3630, Loss=0.9160087704658508\n",
      "Iteration=3640, Loss=0.9278978109359741\n",
      "Iteration=3650, Loss=0.9363232851028442\n",
      "Iteration=3660, Loss=0.9333536028862\n",
      "Iteration=3670, Loss=0.9441753625869751\n",
      "Iteration=3680, Loss=0.925338089466095\n",
      "Iteration=3690, Loss=0.9170230031013489\n",
      "Iteration=3700, Loss=0.9185134768486023\n",
      "Iteration=3710, Loss=0.9197070598602295\n",
      "Iteration=3720, Loss=0.9158008098602295\n",
      "Iteration=3730, Loss=0.9123870134353638\n",
      "Iteration=3740, Loss=0.9284669160842896\n",
      "Iteration=3750, Loss=0.9399125576019287\n",
      "Iteration=3760, Loss=0.9132123589515686\n",
      "Iteration=3770, Loss=0.9331153035163879\n",
      "Iteration=3780, Loss=0.9180636405944824\n",
      "Iteration=3790, Loss=0.9365626573562622\n",
      "Iteration=3800, Loss=0.9124614596366882\n",
      "Iteration=3810, Loss=0.9264051914215088\n",
      "Iteration=3820, Loss=0.9116348624229431\n",
      "Iteration=3830, Loss=0.9313638806343079\n",
      "Iteration=3840, Loss=0.9227728843688965\n",
      "Iteration=3850, Loss=0.9112573862075806\n",
      "Iteration=3860, Loss=0.9180291891098022\n",
      "Iteration=3870, Loss=0.9130975008010864\n",
      "Iteration=3880, Loss=0.9231200218200684\n",
      "Iteration=3890, Loss=0.9131785035133362\n",
      "Iteration=3900, Loss=0.923090934753418\n",
      "Iteration=3910, Loss=0.9098030924797058\n",
      "Iteration=3920, Loss=0.9315897822380066\n",
      "Iteration=3930, Loss=0.9135581254959106\n",
      "Iteration=3940, Loss=0.9007030129432678\n",
      "Iteration=3950, Loss=0.9187667369842529\n",
      "Iteration=3960, Loss=0.9138885140419006\n",
      "Iteration=3970, Loss=0.9057143330574036\n",
      "Iteration=3980, Loss=0.9321720600128174\n",
      "Iteration=3990, Loss=0.918197751045227\n",
      "Iteration=4000, Loss=0.930964469909668\n",
      "Iteration=4010, Loss=0.9057081341743469\n",
      "Iteration=4020, Loss=0.9167646169662476\n",
      "Iteration=4030, Loss=0.9191874265670776\n",
      "Iteration=4040, Loss=0.9324437379837036\n",
      "Iteration=4050, Loss=0.9213413000106812\n",
      "Iteration=4060, Loss=0.9176697134971619\n",
      "Iteration=4070, Loss=0.9133342504501343\n",
      "Iteration=4080, Loss=0.9200127720832825\n",
      "Iteration=4090, Loss=0.9281089901924133\n",
      "Iteration=4100, Loss=0.9254770874977112\n",
      "Iteration=4110, Loss=0.922938346862793\n",
      "Iteration=4120, Loss=0.9308393597602844\n",
      "Iteration=4130, Loss=0.9255936741828918\n",
      "Iteration=4140, Loss=0.9227473735809326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=4150, Loss=0.9281035661697388\n",
      "Iteration=4160, Loss=0.9331568479537964\n",
      "Iteration=4170, Loss=0.9086167216300964\n",
      "Iteration=4180, Loss=0.927671492099762\n",
      "Iteration=4190, Loss=0.9057058095932007\n",
      "Iteration=4200, Loss=0.9150662422180176\n",
      "Iteration=4210, Loss=0.9163451790809631\n",
      "Iteration=4220, Loss=0.9179790019989014\n",
      "Iteration=4230, Loss=0.9186672568321228\n",
      "Iteration=4240, Loss=0.9078176021575928\n",
      "Iteration=4250, Loss=0.9378233551979065\n",
      "Iteration=4260, Loss=0.9198360443115234\n",
      "Iteration=4270, Loss=0.9091097712516785\n",
      "Iteration=4280, Loss=0.9252204298973083\n",
      "Iteration=4290, Loss=0.916934609413147\n",
      "Iteration=4300, Loss=0.9273425340652466\n",
      "Iteration=4310, Loss=0.9128394722938538\n",
      "Iteration=4320, Loss=0.9097222089767456\n",
      "Iteration=4330, Loss=0.9274541735649109\n",
      "Iteration=4340, Loss=0.9066203236579895\n",
      "Iteration=4350, Loss=0.9160443544387817\n",
      "Iteration=4360, Loss=0.9239962100982666\n",
      "Iteration=4370, Loss=0.9065301418304443\n",
      "Iteration=4380, Loss=0.9241147041320801\n",
      "Iteration=4390, Loss=0.923827052116394\n",
      "Iteration=4400, Loss=0.9264919757843018\n",
      "Iteration=4410, Loss=0.9195370674133301\n",
      "Iteration=4420, Loss=0.9212237000465393\n",
      "Iteration=4430, Loss=0.917137622833252\n",
      "Iteration=4440, Loss=0.9176775217056274\n",
      "Iteration=4450, Loss=0.9210852384567261\n",
      "Iteration=4460, Loss=0.9109563231468201\n",
      "Iteration=4470, Loss=0.9158710241317749\n",
      "Iteration=4480, Loss=0.926717221736908\n",
      "Iteration=4490, Loss=0.9213076829910278\n",
      "Iteration=4500, Loss=0.9126622676849365\n",
      "Iteration=4510, Loss=0.9109295606613159\n",
      "Iteration=4520, Loss=0.916117787361145\n",
      "Iteration=4530, Loss=0.9119638204574585\n",
      "Iteration=4540, Loss=0.9196334481239319\n",
      "Iteration=4550, Loss=0.9230136275291443\n",
      "Iteration=4560, Loss=0.915617823600769\n",
      "Iteration=4570, Loss=0.9108549952507019\n",
      "Iteration=4580, Loss=0.9110583066940308\n",
      "Iteration=4590, Loss=0.9254524111747742\n",
      "Iteration=4600, Loss=0.9187906980514526\n",
      "Iteration=4610, Loss=0.9175739884376526\n",
      "Iteration=4620, Loss=0.909136950969696\n",
      "Iteration=4630, Loss=0.9165607690811157\n",
      "Iteration=4640, Loss=0.9279413223266602\n",
      "Iteration=4650, Loss=0.912178635597229\n",
      "Iteration=4660, Loss=0.9229888916015625\n",
      "Iteration=4670, Loss=0.9168304204940796\n",
      "Iteration=4680, Loss=0.9150844812393188\n",
      "Iteration=4690, Loss=0.9298915863037109\n",
      "Iteration=4700, Loss=0.915092408657074\n",
      "Iteration=4710, Loss=0.9122796058654785\n",
      "Iteration=4720, Loss=0.9119477868080139\n",
      "Iteration=4730, Loss=0.9243924617767334\n",
      "Iteration=4740, Loss=0.917161226272583\n",
      "Iteration=4750, Loss=0.9121353030204773\n",
      "Iteration=4760, Loss=0.9236972332000732\n",
      "Iteration=4770, Loss=0.9191247224807739\n",
      "Iteration=4780, Loss=0.9154908061027527\n",
      "Iteration=4790, Loss=0.9215213060379028\n",
      "Iteration=4800, Loss=0.9108657836914062\n",
      "Iteration=4810, Loss=0.9371209740638733\n",
      "Iteration=4820, Loss=0.9351024627685547\n",
      "Iteration=4830, Loss=0.9134599566459656\n",
      "Iteration=4840, Loss=0.9125865697860718\n",
      "Iteration=4850, Loss=0.9262418150901794\n",
      "Iteration=4860, Loss=0.9170215129852295\n",
      "Iteration=4870, Loss=0.9254254698753357\n",
      "Iteration=4880, Loss=0.919204592704773\n",
      "Iteration=4890, Loss=0.9306265115737915\n",
      "Iteration=4900, Loss=0.9193931818008423\n",
      "Iteration=4910, Loss=0.9198554754257202\n",
      "Iteration=4920, Loss=0.9274801015853882\n",
      "Iteration=4930, Loss=0.9097540378570557\n",
      "Iteration=4940, Loss=0.9190879464149475\n",
      "Iteration=4950, Loss=0.8992738127708435\n",
      "Iteration=4960, Loss=0.9123967289924622\n",
      "Iteration=4970, Loss=0.9099434018135071\n",
      "Iteration=4980, Loss=0.9196813106536865\n",
      "Iteration=4990, Loss=0.9072322845458984\n",
      "Iteration=5000, Loss=0.9043811559677124\n",
      "Iteration=5010, Loss=0.9250585436820984\n",
      "Iteration=5020, Loss=0.9263400435447693\n",
      "Iteration=5030, Loss=0.9165374040603638\n",
      "Iteration=5040, Loss=0.9298059940338135\n",
      "Iteration=5050, Loss=0.9255580902099609\n",
      "Iteration=5060, Loss=0.9167744517326355\n",
      "Iteration=5070, Loss=0.9357984066009521\n",
      "Iteration=5080, Loss=0.9300987124443054\n",
      "Iteration=5090, Loss=0.9032562971115112\n",
      "Iteration=5100, Loss=0.9228090047836304\n",
      "Iteration=5110, Loss=0.9074156880378723\n",
      "Iteration=5120, Loss=0.9364750385284424\n",
      "Iteration=5130, Loss=0.9111611843109131\n",
      "Iteration=5140, Loss=0.9284555912017822\n",
      "Iteration=5150, Loss=0.915181040763855\n",
      "Iteration=5160, Loss=0.9201223254203796\n",
      "Iteration=5170, Loss=0.9268196225166321\n",
      "Iteration=5180, Loss=0.9047621488571167\n",
      "Iteration=5190, Loss=0.9221470952033997\n",
      "Iteration=5200, Loss=0.9139958024024963\n",
      "Iteration=5210, Loss=0.9150128364562988\n",
      "Iteration=5220, Loss=0.9146977066993713\n",
      "Iteration=5230, Loss=0.9250348210334778\n",
      "Iteration=5240, Loss=0.9218275547027588\n",
      "Iteration=5250, Loss=0.9016300439834595\n",
      "Iteration=5260, Loss=0.9158248901367188\n",
      "Iteration=5270, Loss=0.9324495792388916\n",
      "Iteration=5280, Loss=0.915782630443573\n",
      "Iteration=5290, Loss=0.917121410369873\n",
      "Iteration=5300, Loss=0.9254416823387146\n",
      "Iteration=5310, Loss=0.9190260767936707\n",
      "Iteration=5320, Loss=0.9143632650375366\n",
      "Iteration=5330, Loss=0.9419628977775574\n",
      "Iteration=5340, Loss=0.9142757058143616\n",
      "Iteration=5350, Loss=0.9215266108512878\n",
      "Iteration=5360, Loss=0.9173953533172607\n",
      "Iteration=5370, Loss=0.9176802039146423\n",
      "Iteration=5380, Loss=0.9110134243965149\n",
      "Iteration=5390, Loss=0.9054978489875793\n",
      "Iteration=5400, Loss=0.9199434518814087\n",
      "Iteration=5410, Loss=0.8985036015510559\n",
      "Iteration=5420, Loss=0.9005540609359741\n",
      "Iteration=5430, Loss=0.9326672554016113\n",
      "Iteration=5440, Loss=0.9247438311576843\n",
      "Iteration=5450, Loss=0.9046279191970825\n",
      "Iteration=5460, Loss=0.9090195894241333\n",
      "Iteration=5470, Loss=0.9228827357292175\n",
      "Iteration=5480, Loss=0.9098044037818909\n",
      "Iteration=5490, Loss=0.9037328958511353\n",
      "Iteration=5500, Loss=0.9168399572372437\n",
      "Iteration=5510, Loss=0.9168561100959778\n",
      "Iteration=5520, Loss=0.9071884155273438\n",
      "Iteration=5530, Loss=0.9171116352081299\n",
      "Iteration=5540, Loss=0.9132285118103027\n",
      "Iteration=5550, Loss=0.9092827439308167\n",
      "Iteration=5560, Loss=0.9255982637405396\n",
      "Iteration=5570, Loss=0.9078280925750732\n",
      "Iteration=5580, Loss=0.9038203954696655\n",
      "Iteration=5590, Loss=0.9262518882751465\n",
      "Iteration=5600, Loss=0.9019305109977722\n",
      "Iteration=5610, Loss=0.920028805732727\n",
      "Iteration=5620, Loss=0.9115487933158875\n",
      "Iteration=5630, Loss=0.9230740666389465\n",
      "Iteration=5640, Loss=0.9019615650177002\n",
      "Iteration=5650, Loss=0.908922553062439\n",
      "Iteration=5660, Loss=0.915946900844574\n",
      "Iteration=5670, Loss=0.9108618497848511\n",
      "Iteration=5680, Loss=0.9075258374214172\n",
      "Iteration=5690, Loss=0.9215100407600403\n",
      "Iteration=5700, Loss=0.9132599234580994\n",
      "Iteration=5710, Loss=0.9352813959121704\n",
      "Iteration=5720, Loss=0.9399069547653198\n",
      "Iteration=5730, Loss=0.899006187915802\n",
      "Iteration=5740, Loss=0.8980209231376648\n",
      "Iteration=5750, Loss=0.9232592582702637\n",
      "Iteration=5760, Loss=0.911017656326294\n",
      "Iteration=5770, Loss=0.9178994297981262\n",
      "Iteration=5780, Loss=0.9208433032035828\n",
      "Iteration=5790, Loss=0.9236289858818054\n",
      "Iteration=5800, Loss=0.9063715934753418\n",
      "Iteration=5810, Loss=0.9173639416694641\n",
      "Iteration=5820, Loss=0.9154106974601746\n",
      "Iteration=5830, Loss=0.922126054763794\n",
      "Iteration=5840, Loss=0.9262922406196594\n",
      "Iteration=5850, Loss=0.9185682535171509\n",
      "Iteration=5860, Loss=0.9165952205657959\n",
      "Iteration=5870, Loss=0.9297770261764526\n",
      "Iteration=5880, Loss=0.9130346775054932\n",
      "Iteration=5890, Loss=0.9251003265380859\n",
      "Iteration=5900, Loss=0.9089779853820801\n",
      "Iteration=5910, Loss=0.9069767594337463\n",
      "Iteration=5920, Loss=0.9252644777297974\n",
      "Iteration=5930, Loss=0.9392423033714294\n",
      "Iteration=5940, Loss=0.9211359620094299\n",
      "Iteration=5950, Loss=0.9200248122215271\n",
      "Iteration=5960, Loss=0.9205194711685181\n",
      "Iteration=5970, Loss=0.9288726449012756\n",
      "Iteration=5980, Loss=0.919764518737793\n",
      "Iteration=5990, Loss=0.9117087125778198\n",
      "Iteration=6000, Loss=0.9113302826881409\n",
      "Iteration=6010, Loss=0.9142401218414307\n",
      "Iteration=6020, Loss=0.9262351989746094\n",
      "Iteration=6030, Loss=0.9238054752349854\n",
      "Iteration=6040, Loss=0.915151059627533\n",
      "Iteration=6050, Loss=0.9243564605712891\n",
      "Iteration=6060, Loss=0.9039112329483032\n",
      "Iteration=6070, Loss=0.9132704734802246\n",
      "Iteration=6080, Loss=0.9280272722244263\n",
      "Iteration=6090, Loss=0.9149588346481323\n",
      "Iteration=6100, Loss=0.9159412384033203\n",
      "Iteration=6110, Loss=0.9167340397834778\n",
      "Iteration=6120, Loss=0.9060992002487183\n",
      "Iteration=6130, Loss=0.9182431697845459\n",
      "Iteration=6140, Loss=0.9127163887023926\n",
      "Iteration=6150, Loss=0.9273766279220581\n",
      "Iteration=6160, Loss=0.9065223932266235\n",
      "Iteration=6170, Loss=0.9223693013191223\n",
      "Iteration=6180, Loss=0.9166089296340942\n",
      "Iteration=6190, Loss=0.9128014445304871\n",
      "Iteration=6200, Loss=0.9241324067115784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=6210, Loss=0.9188258647918701\n",
      "Iteration=6220, Loss=0.9201184511184692\n",
      "Iteration=6230, Loss=0.9158250689506531\n",
      "Iteration=6240, Loss=0.9060255289077759\n",
      "Iteration=6250, Loss=0.9222550392150879\n",
      "Iteration=6260, Loss=0.9221047759056091\n",
      "Iteration=6270, Loss=0.9109188318252563\n",
      "Iteration=6280, Loss=0.915240466594696\n",
      "Iteration=6290, Loss=0.9156370759010315\n",
      "Iteration=6300, Loss=0.9012485146522522\n",
      "Iteration=6310, Loss=0.9052140116691589\n",
      "Iteration=6320, Loss=0.9182788729667664\n",
      "Iteration=6330, Loss=0.9130785465240479\n",
      "Iteration=6340, Loss=0.9267116785049438\n",
      "Iteration=6350, Loss=0.9107481241226196\n",
      "Iteration=6360, Loss=0.9184488654136658\n",
      "Iteration=6370, Loss=0.9132473468780518\n",
      "Iteration=6380, Loss=0.9197090864181519\n",
      "Iteration=6390, Loss=0.927671492099762\n",
      "Iteration=6400, Loss=0.9067857265472412\n",
      "Iteration=6410, Loss=0.9133834838867188\n",
      "Iteration=6420, Loss=0.9133964776992798\n",
      "Iteration=6430, Loss=0.912344217300415\n",
      "Iteration=6440, Loss=0.9242773056030273\n",
      "Iteration=6450, Loss=0.9117549061775208\n",
      "Iteration=6460, Loss=0.9165220856666565\n",
      "Iteration=6470, Loss=0.9099352359771729\n",
      "Iteration=6480, Loss=0.9173792600631714\n",
      "Iteration=6490, Loss=0.909165620803833\n",
      "Iteration=6500, Loss=0.922484815120697\n",
      "Iteration=6510, Loss=0.9120792746543884\n",
      "Iteration=6520, Loss=0.9122251272201538\n",
      "Iteration=6530, Loss=0.9201277494430542\n",
      "Iteration=6540, Loss=0.9181035757064819\n",
      "Iteration=6550, Loss=0.9205420613288879\n",
      "Iteration=6560, Loss=0.9178311228752136\n",
      "Iteration=6570, Loss=0.9147256016731262\n",
      "Iteration=6580, Loss=0.909423828125\n",
      "Iteration=6590, Loss=0.9221286177635193\n",
      "Iteration=6600, Loss=0.9341917037963867\n",
      "Iteration=6610, Loss=0.9285040497779846\n",
      "Iteration=6620, Loss=0.912664532661438\n",
      "Iteration=6630, Loss=0.9102841019630432\n",
      "Iteration=6640, Loss=0.9099705815315247\n",
      "Iteration=6650, Loss=0.8980981707572937\n",
      "Iteration=6660, Loss=0.9196824431419373\n",
      "Iteration=6670, Loss=0.9051934480667114\n",
      "Iteration=6680, Loss=0.9077743291854858\n",
      "Iteration=6690, Loss=0.9124789237976074\n",
      "Iteration=6700, Loss=0.9231846332550049\n",
      "Iteration=6710, Loss=0.9436435103416443\n",
      "Iteration=6720, Loss=0.9011063575744629\n",
      "Iteration=6730, Loss=0.920861542224884\n",
      "Iteration=6740, Loss=0.9224493503570557\n",
      "Iteration=6750, Loss=0.9286120533943176\n",
      "Iteration=6760, Loss=0.9316480159759521\n",
      "Iteration=6770, Loss=0.9091196656227112\n",
      "Iteration=6780, Loss=0.9047514200210571\n",
      "Iteration=6790, Loss=0.926369845867157\n",
      "Iteration=6800, Loss=0.9227089881896973\n",
      "Iteration=6810, Loss=0.9252956509590149\n",
      "Iteration=6820, Loss=0.9102104306221008\n",
      "Iteration=6830, Loss=0.912039041519165\n",
      "Iteration=6840, Loss=0.9340920448303223\n",
      "Iteration=6850, Loss=0.904231607913971\n",
      "Iteration=6860, Loss=0.9016901254653931\n",
      "Iteration=6870, Loss=0.8999097347259521\n",
      "Iteration=6880, Loss=0.9167607426643372\n",
      "Iteration=6890, Loss=0.8996122479438782\n",
      "Iteration=6900, Loss=0.9088147282600403\n",
      "Iteration=6910, Loss=0.8925955891609192\n",
      "Iteration=6920, Loss=0.9213567972183228\n",
      "Iteration=6930, Loss=0.9039566516876221\n",
      "Iteration=6940, Loss=0.9139896631240845\n",
      "Iteration=6950, Loss=0.9167356491088867\n",
      "Iteration=6960, Loss=0.9144070744514465\n",
      "Iteration=6970, Loss=0.9293167591094971\n",
      "Iteration=6980, Loss=0.9246882200241089\n",
      "Iteration=6990, Loss=0.9110617637634277\n",
      "Iteration=7000, Loss=0.9158876538276672\n",
      "Iteration=7010, Loss=0.9113979935646057\n",
      "Iteration=7020, Loss=0.9233219623565674\n",
      "Iteration=7030, Loss=0.9232935905456543\n",
      "Iteration=7040, Loss=0.9042122960090637\n",
      "Iteration=7050, Loss=0.9223799109458923\n",
      "Iteration=7060, Loss=0.8982663750648499\n",
      "Iteration=7070, Loss=0.9223626852035522\n",
      "Iteration=7080, Loss=0.9157072305679321\n",
      "Iteration=7090, Loss=0.9152697324752808\n",
      "Iteration=7100, Loss=0.9252899289131165\n",
      "Iteration=7110, Loss=0.9151166677474976\n",
      "Iteration=7120, Loss=0.9157494902610779\n",
      "Iteration=7130, Loss=0.9125876426696777\n",
      "Iteration=7140, Loss=0.9157721996307373\n",
      "Iteration=7150, Loss=0.9101494550704956\n",
      "Iteration=7160, Loss=0.9153409004211426\n",
      "Iteration=7170, Loss=0.9108108282089233\n",
      "Iteration=7180, Loss=0.9048280119895935\n",
      "Iteration=7190, Loss=0.9220618009567261\n",
      "Iteration=7200, Loss=0.917558491230011\n",
      "Iteration=7210, Loss=0.9203365445137024\n",
      "Iteration=7220, Loss=0.921709418296814\n",
      "Iteration=7230, Loss=0.9287883639335632\n",
      "Iteration=7240, Loss=0.9264628887176514\n",
      "Iteration=7250, Loss=0.9116505980491638\n",
      "Iteration=7260, Loss=0.9013340473175049\n",
      "Iteration=7270, Loss=0.907341480255127\n",
      "Iteration=7280, Loss=0.9211190342903137\n",
      "Iteration=7290, Loss=0.9186933040618896\n",
      "Iteration=7300, Loss=0.9112841486930847\n",
      "Iteration=7310, Loss=0.9232560396194458\n",
      "Iteration=7320, Loss=0.9079607725143433\n",
      "Iteration=7330, Loss=0.9257784485816956\n",
      "Iteration=7340, Loss=0.9134916067123413\n",
      "Iteration=7350, Loss=0.9114205241203308\n",
      "Iteration=7360, Loss=0.9076159000396729\n",
      "Iteration=7370, Loss=0.911495566368103\n",
      "Iteration=7380, Loss=0.9077548980712891\n",
      "Iteration=7390, Loss=0.9072957038879395\n",
      "Iteration=7400, Loss=0.9363305568695068\n",
      "Iteration=7410, Loss=0.9184985160827637\n",
      "Iteration=7420, Loss=0.9108490943908691\n",
      "Iteration=7430, Loss=0.9114612340927124\n",
      "Iteration=7440, Loss=0.9244480133056641\n",
      "Iteration=7450, Loss=0.8950400948524475\n",
      "Iteration=7460, Loss=0.909318208694458\n",
      "Iteration=7470, Loss=0.914697527885437\n",
      "Iteration=7480, Loss=0.9185170531272888\n",
      "Iteration=7490, Loss=0.9188449382781982\n",
      "Iteration=7500, Loss=0.9244185090065002\n",
      "Iteration=7510, Loss=0.9204199314117432\n",
      "Iteration=7520, Loss=0.9148626327514648\n",
      "Iteration=7530, Loss=0.9183180928230286\n",
      "Iteration=7540, Loss=0.9066637754440308\n",
      "Iteration=7550, Loss=0.8994030952453613\n",
      "Iteration=7560, Loss=0.9088877439498901\n",
      "Iteration=7570, Loss=0.926072895526886\n",
      "Iteration=7580, Loss=0.914208710193634\n",
      "Iteration=7590, Loss=0.9178119897842407\n",
      "Iteration=7600, Loss=0.9172573089599609\n",
      "Iteration=7610, Loss=0.9184293150901794\n",
      "Iteration=7620, Loss=0.9164876341819763\n",
      "Iteration=7630, Loss=0.9128841757774353\n",
      "Iteration=7640, Loss=0.901598334312439\n",
      "Iteration=7650, Loss=0.9430147409439087\n",
      "Iteration=7660, Loss=0.8982401490211487\n",
      "Iteration=7670, Loss=0.9291916489601135\n",
      "Iteration=7680, Loss=0.9390236139297485\n",
      "Iteration=7690, Loss=0.9099833965301514\n",
      "Iteration=7700, Loss=0.9253026247024536\n",
      "Iteration=7710, Loss=0.8989169597625732\n",
      "Iteration=7720, Loss=0.9089652299880981\n",
      "Iteration=7730, Loss=0.9223645329475403\n",
      "Iteration=7740, Loss=0.9227844476699829\n",
      "Iteration=7750, Loss=0.9077539443969727\n",
      "Iteration=7760, Loss=0.8972364068031311\n",
      "Iteration=7770, Loss=0.8991897106170654\n",
      "Iteration=7780, Loss=0.9133151769638062\n",
      "Iteration=7790, Loss=0.9007712602615356\n",
      "Iteration=7800, Loss=0.9096714854240417\n",
      "Iteration=7810, Loss=0.9166107177734375\n",
      "Iteration=7820, Loss=0.914863109588623\n",
      "Iteration=7830, Loss=0.9088152647018433\n",
      "Iteration=7840, Loss=0.9230202436447144\n",
      "Iteration=7850, Loss=0.9059810042381287\n",
      "Iteration=7860, Loss=0.918742299079895\n",
      "Iteration=7870, Loss=0.922008752822876\n",
      "Iteration=7880, Loss=0.903113842010498\n",
      "Iteration=7890, Loss=0.9146279096603394\n",
      "Iteration=7900, Loss=0.9189960956573486\n",
      "Iteration=7910, Loss=0.9027462005615234\n",
      "Iteration=7920, Loss=0.9209615588188171\n",
      "Iteration=7930, Loss=0.9136696457862854\n",
      "Iteration=7940, Loss=0.9113112092018127\n",
      "Iteration=7950, Loss=0.913277268409729\n",
      "Iteration=7960, Loss=0.9057497978210449\n",
      "Iteration=7970, Loss=0.931390106678009\n",
      "Iteration=7980, Loss=0.9381208419799805\n",
      "Iteration=7990, Loss=0.9287035465240479\n",
      "Iteration=8000, Loss=0.9213001728057861\n",
      "Iteration=8010, Loss=0.9101490378379822\n",
      "Iteration=8020, Loss=0.9158844947814941\n",
      "Iteration=8030, Loss=0.9105638265609741\n",
      "Iteration=8040, Loss=0.9058366417884827\n",
      "Iteration=8050, Loss=0.9128679037094116\n",
      "Iteration=8060, Loss=0.9147613048553467\n",
      "Iteration=8070, Loss=0.9084764122962952\n",
      "Iteration=8080, Loss=0.9240949153900146\n",
      "Iteration=8090, Loss=0.927825927734375\n",
      "Iteration=8100, Loss=0.9168215394020081\n",
      "Iteration=8110, Loss=0.9022462368011475\n",
      "Iteration=8120, Loss=0.9112370610237122\n",
      "Iteration=8130, Loss=0.929287314414978\n",
      "Iteration=8140, Loss=0.9167162775993347\n",
      "Iteration=8150, Loss=0.9036608338356018\n",
      "Iteration=8160, Loss=0.9053893685340881\n",
      "Iteration=8170, Loss=0.9118444323539734\n",
      "Iteration=8180, Loss=0.9266088008880615\n",
      "Iteration=8190, Loss=0.9137807488441467\n",
      "Iteration=8200, Loss=0.9134467244148254\n",
      "Iteration=8210, Loss=0.9137237668037415\n",
      "Iteration=8220, Loss=0.9129629135131836\n",
      "Iteration=8230, Loss=0.9245938062667847\n",
      "Iteration=8240, Loss=0.9076627492904663\n",
      "Iteration=8250, Loss=0.9222854375839233\n",
      "Iteration=8260, Loss=0.9049268960952759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=8270, Loss=0.9100489020347595\n",
      "Iteration=8280, Loss=0.9139161109924316\n",
      "Iteration=8290, Loss=0.9263388514518738\n",
      "Iteration=8300, Loss=0.910101592540741\n",
      "Iteration=8310, Loss=0.9222068786621094\n",
      "Iteration=8320, Loss=0.9024880528450012\n",
      "Iteration=8330, Loss=0.9115491509437561\n",
      "Iteration=8340, Loss=0.926374077796936\n",
      "Iteration=8350, Loss=0.9065876007080078\n",
      "Iteration=8360, Loss=0.9181941747665405\n",
      "Iteration=8370, Loss=0.9188646078109741\n",
      "Iteration=8380, Loss=0.9262548089027405\n",
      "Iteration=8390, Loss=0.9286625981330872\n",
      "Iteration=8400, Loss=0.9340265989303589\n",
      "Iteration=8410, Loss=0.9143909215927124\n",
      "Iteration=8420, Loss=0.9114135503768921\n",
      "Iteration=8430, Loss=0.916234016418457\n",
      "Iteration=8440, Loss=0.9067190885543823\n",
      "Iteration=8450, Loss=0.9180394411087036\n",
      "Iteration=8460, Loss=0.922411322593689\n",
      "Iteration=8470, Loss=0.9125728011131287\n",
      "Iteration=8480, Loss=0.9164543151855469\n",
      "Iteration=8490, Loss=0.8990302085876465\n",
      "Iteration=8500, Loss=0.9141735434532166\n",
      "Iteration=8510, Loss=0.9206587076187134\n",
      "Iteration=8520, Loss=0.9311245679855347\n",
      "Iteration=8530, Loss=0.9303106069564819\n",
      "Iteration=8540, Loss=0.907555341720581\n",
      "Iteration=8550, Loss=0.8992143273353577\n",
      "Iteration=8560, Loss=0.911333441734314\n",
      "Iteration=8570, Loss=0.9156070947647095\n",
      "Iteration=8580, Loss=0.917973518371582\n",
      "Iteration=8590, Loss=0.9194051027297974\n",
      "Iteration=8600, Loss=0.9173519611358643\n",
      "Iteration=8610, Loss=0.9184136986732483\n",
      "Iteration=8620, Loss=0.9170324802398682\n",
      "Iteration=8630, Loss=0.9204899072647095\n",
      "Iteration=8640, Loss=0.9050005674362183\n",
      "Iteration=8650, Loss=0.913140594959259\n",
      "Iteration=8660, Loss=0.9151749014854431\n",
      "Iteration=8670, Loss=0.9009019732475281\n",
      "Iteration=8680, Loss=0.9166598916053772\n",
      "Iteration=8690, Loss=0.9161203503608704\n",
      "Iteration=8700, Loss=0.9155516624450684\n",
      "Iteration=8710, Loss=0.9124964475631714\n",
      "Iteration=8720, Loss=0.9192063212394714\n",
      "Iteration=8730, Loss=0.919471263885498\n",
      "Iteration=8740, Loss=0.9322537183761597\n",
      "Iteration=8750, Loss=0.9113762974739075\n",
      "Iteration=8760, Loss=0.9331613183021545\n",
      "Iteration=8770, Loss=0.9177849292755127\n",
      "Iteration=8780, Loss=0.9143431186676025\n",
      "Iteration=8790, Loss=0.9109617471694946\n",
      "Iteration=8800, Loss=0.9181368350982666\n",
      "Iteration=8810, Loss=0.9175329804420471\n",
      "Iteration=8820, Loss=0.9071453809738159\n",
      "Iteration=8830, Loss=0.902129054069519\n",
      "Iteration=8840, Loss=0.924770176410675\n",
      "Iteration=8850, Loss=0.921380341053009\n",
      "Iteration=8860, Loss=0.9059324264526367\n",
      "Iteration=8870, Loss=0.9167085886001587\n",
      "Iteration=8880, Loss=0.9325729608535767\n",
      "Iteration=8890, Loss=0.9101563692092896\n",
      "Iteration=8900, Loss=0.9080075025558472\n",
      "Iteration=8910, Loss=0.9092482328414917\n",
      "Iteration=8920, Loss=0.917210042476654\n",
      "Iteration=8930, Loss=0.9120522737503052\n",
      "Iteration=8940, Loss=0.9294646978378296\n",
      "Iteration=8950, Loss=0.9227796196937561\n",
      "Iteration=8960, Loss=0.9163131713867188\n",
      "Iteration=8970, Loss=0.9122322797775269\n",
      "Iteration=8980, Loss=0.914831280708313\n",
      "Iteration=8990, Loss=0.9092779159545898\n",
      "Iteration=9000, Loss=0.9127227067947388\n",
      "Iteration=9010, Loss=0.9029791355133057\n",
      "Iteration=9020, Loss=0.9349068403244019\n",
      "Iteration=9030, Loss=0.9242790341377258\n",
      "Iteration=9040, Loss=0.9177360534667969\n",
      "Iteration=9050, Loss=0.9396551847457886\n",
      "Iteration=9060, Loss=0.9228324294090271\n",
      "Iteration=9070, Loss=0.9037516117095947\n",
      "Iteration=9080, Loss=0.9183846712112427\n",
      "Iteration=9090, Loss=0.8987693786621094\n",
      "Iteration=9100, Loss=0.9104713797569275\n",
      "Iteration=9110, Loss=0.9270734786987305\n",
      "Iteration=9120, Loss=0.8984588384628296\n",
      "Iteration=9130, Loss=0.9121905565261841\n",
      "Iteration=9140, Loss=0.913013219833374\n",
      "Iteration=9150, Loss=0.9223508238792419\n",
      "Iteration=9160, Loss=0.9119895696640015\n",
      "Iteration=9170, Loss=0.9235295653343201\n",
      "Iteration=9180, Loss=0.9219454526901245\n",
      "Iteration=9190, Loss=0.9104294776916504\n",
      "Iteration=9200, Loss=0.9171880483627319\n",
      "Iteration=9210, Loss=0.920041024684906\n",
      "Iteration=9220, Loss=0.9292240738868713\n",
      "Iteration=9230, Loss=0.9058602452278137\n",
      "Iteration=9240, Loss=0.9139885306358337\n",
      "Iteration=9250, Loss=0.9157425165176392\n",
      "Iteration=9260, Loss=0.9200369119644165\n",
      "Iteration=9270, Loss=0.9331579208374023\n",
      "Iteration=9280, Loss=0.9206679463386536\n",
      "Iteration=9290, Loss=0.9007357358932495\n",
      "Iteration=9300, Loss=0.9054616093635559\n",
      "Iteration=9310, Loss=0.9185400605201721\n",
      "Iteration=9320, Loss=0.9120402932167053\n",
      "Iteration=9330, Loss=0.9035345315933228\n",
      "Iteration=9340, Loss=0.9391302466392517\n",
      "Iteration=9350, Loss=0.9217212200164795\n",
      "Iteration=9360, Loss=0.9252117276191711\n",
      "Iteration=9370, Loss=0.9075120687484741\n",
      "Iteration=9380, Loss=0.9114145040512085\n",
      "Iteration=9390, Loss=0.9208400249481201\n",
      "Iteration=9400, Loss=0.9091750979423523\n",
      "Iteration=9410, Loss=0.9170902371406555\n",
      "Iteration=9420, Loss=0.9120165109634399\n",
      "Iteration=9430, Loss=0.918728232383728\n",
      "Iteration=9440, Loss=0.9145649671554565\n",
      "Iteration=9450, Loss=0.922005295753479\n",
      "Iteration=9460, Loss=0.9112316966056824\n",
      "Iteration=9470, Loss=0.9077666997909546\n",
      "Iteration=9480, Loss=0.9025713801383972\n",
      "Iteration=9490, Loss=0.9265836477279663\n",
      "Iteration=9500, Loss=0.9213341474533081\n",
      "Iteration=9510, Loss=0.9183276891708374\n",
      "Iteration=9520, Loss=0.9109218120574951\n",
      "Iteration=9530, Loss=0.9234068989753723\n",
      "Iteration=9540, Loss=0.9077519178390503\n",
      "Iteration=9550, Loss=0.9263254404067993\n",
      "Iteration=9560, Loss=0.913510799407959\n",
      "Iteration=9570, Loss=0.8952186107635498\n",
      "Iteration=9580, Loss=0.9062057733535767\n",
      "Iteration=9590, Loss=0.9063880443572998\n",
      "Iteration=9600, Loss=0.9099581837654114\n",
      "Iteration=9610, Loss=0.9067379236221313\n",
      "Iteration=9620, Loss=0.9236095547676086\n",
      "Iteration=9630, Loss=0.9245990514755249\n",
      "Iteration=9640, Loss=0.9055330753326416\n",
      "Iteration=9650, Loss=0.9242041110992432\n",
      "Iteration=9660, Loss=0.9136670827865601\n",
      "Iteration=9670, Loss=0.9056958556175232\n",
      "Iteration=9680, Loss=0.9164470434188843\n",
      "Iteration=9690, Loss=0.9089644551277161\n",
      "Iteration=9700, Loss=0.9135604500770569\n",
      "Iteration=9710, Loss=0.9188646674156189\n",
      "Iteration=9720, Loss=0.9177283644676208\n",
      "Iteration=9730, Loss=0.9287132024765015\n",
      "Iteration=9740, Loss=0.9204164147377014\n",
      "Iteration=9750, Loss=0.9021903872489929\n",
      "Iteration=9760, Loss=0.9173123240470886\n",
      "Iteration=9770, Loss=0.914527177810669\n",
      "Iteration=9780, Loss=0.8999526500701904\n",
      "Iteration=9790, Loss=0.9207923412322998\n",
      "Iteration=9800, Loss=0.9195138216018677\n",
      "Iteration=9810, Loss=0.911827564239502\n",
      "Iteration=9820, Loss=0.9166829586029053\n",
      "Iteration=9830, Loss=0.9248353838920593\n",
      "Iteration=9840, Loss=0.9160710573196411\n",
      "Iteration=9850, Loss=0.9098369479179382\n",
      "Iteration=9860, Loss=0.9074963927268982\n",
      "Iteration=9870, Loss=0.8987624645233154\n",
      "Iteration=9880, Loss=0.9151371717453003\n",
      "Iteration=9890, Loss=0.9206008315086365\n",
      "Iteration=9900, Loss=0.9281999468803406\n",
      "Iteration=9910, Loss=0.9284667372703552\n",
      "Iteration=9920, Loss=0.9556955099105835\n",
      "Iteration=9930, Loss=0.9131178259849548\n",
      "Iteration=9940, Loss=0.9047332406044006\n",
      "Iteration=9950, Loss=0.9085690975189209\n",
      "Iteration=9960, Loss=0.9089011549949646\n",
      "Iteration=9970, Loss=0.90740966796875\n",
      "Iteration=9980, Loss=0.9238240122795105\n",
      "Iteration=9990, Loss=0.9107833504676819\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "dropout_probability = 0.25\n",
    "soft_label_weight = 0.8\n",
    "batch_size = 1000\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "\n",
    "# Fixed parameters, model architecture\n",
    "num_classes = 3\n",
    "embedding_dim = 50\n",
    "leaky_relu_negative_slope = 0.1\n",
    "\n",
    "# Fixed parameters, model training\n",
    "num_iterations = 10000\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "check_every = 10\n",
    "\n",
    "best_model = DistilledDAN(num_classes, embedding_dim, hidden_dim1, hidden_dim2, 0, leaky_relu_negative_slope, dropout_probability, False, False)\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=learning_rate)\n",
    "loss_history, train_accuracy, dev_accuracy = best_model.train_model(X_train, Y_train, X_dev, Y_dev, soft_labels, optimizer, num_iterations, soft_label_weight, loss_fn, batch_size, check_every, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "279cd50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = [i * 10 for i in range(len(loss_history))] # iterations data...\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# Plot loss history on the first subplot\n",
    "ax1.plot(iterations, loss_history, label='Loss', lw=0.75)\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Curve')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot accuracies on the second subplot\n",
    "ax2.plot(iterations, train_accuracy, label='Train Accuracy', lw=0.75)\n",
    "ax2.plot(iterations, dev_accuracy, label='Dev Accuracy', lw=0.75)\n",
    "ax2.set_xlabel('Iterations')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy Curves')\n",
    "ax2.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bba17fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=0, Loss=1.0885285139083862\n",
      "Iteration=10, Loss=1.027242660522461\n",
      "Iteration=20, Loss=1.041053295135498\n",
      "Iteration=30, Loss=1.0247058868408203\n",
      "Iteration=40, Loss=1.0094683170318604\n",
      "Iteration=50, Loss=1.0047203302383423\n",
      "Iteration=60, Loss=0.9902735948562622\n",
      "Iteration=70, Loss=1.0101381540298462\n",
      "Iteration=80, Loss=0.9894310235977173\n",
      "Iteration=90, Loss=0.987460196018219\n",
      "Iteration=100, Loss=0.9784482717514038\n",
      "Iteration=110, Loss=0.9840025901794434\n",
      "Iteration=120, Loss=0.9655537009239197\n",
      "Iteration=130, Loss=1.0646716356277466\n",
      "Iteration=140, Loss=0.9824836254119873\n",
      "Iteration=150, Loss=0.9642987847328186\n",
      "Iteration=160, Loss=0.9603123664855957\n",
      "Iteration=170, Loss=0.9811249375343323\n",
      "Iteration=180, Loss=0.9696670770645142\n",
      "Iteration=190, Loss=0.9585295915603638\n",
      "Iteration=200, Loss=1.0047962665557861\n",
      "Iteration=210, Loss=0.9633969664573669\n",
      "Iteration=220, Loss=0.9684723615646362\n",
      "Iteration=230, Loss=0.9644110798835754\n",
      "Iteration=240, Loss=0.9576123952865601\n",
      "Iteration=250, Loss=0.947786271572113\n",
      "Iteration=260, Loss=0.9692807793617249\n",
      "Iteration=270, Loss=0.9517816305160522\n",
      "Iteration=280, Loss=0.9727447032928467\n",
      "Iteration=290, Loss=0.9537709951400757\n",
      "Iteration=300, Loss=0.9406343698501587\n",
      "Iteration=310, Loss=0.9676622152328491\n",
      "Iteration=320, Loss=0.9695500135421753\n",
      "Iteration=330, Loss=0.9455975294113159\n",
      "Iteration=340, Loss=0.9785451292991638\n",
      "Iteration=350, Loss=0.9588392972946167\n",
      "Iteration=360, Loss=0.9688973426818848\n",
      "Iteration=370, Loss=0.9839350581169128\n",
      "Iteration=380, Loss=0.9709132313728333\n",
      "Iteration=390, Loss=0.9507052898406982\n",
      "Iteration=400, Loss=0.9305487275123596\n",
      "Iteration=410, Loss=0.9579459428787231\n",
      "Iteration=420, Loss=0.9733498692512512\n",
      "Iteration=430, Loss=0.9427533149719238\n",
      "Iteration=440, Loss=0.9443240165710449\n",
      "Iteration=450, Loss=0.959176778793335\n",
      "Iteration=460, Loss=0.9441465735435486\n",
      "Iteration=470, Loss=0.972179114818573\n",
      "Iteration=480, Loss=0.9670416712760925\n",
      "Iteration=490, Loss=0.9629798531532288\n",
      "Iteration=500, Loss=0.9644931554794312\n",
      "Iteration=510, Loss=0.9525031447410583\n",
      "Iteration=520, Loss=0.9579966068267822\n",
      "Iteration=530, Loss=0.9449638724327087\n",
      "Iteration=540, Loss=0.9532947540283203\n",
      "Iteration=550, Loss=0.9458976984024048\n",
      "Iteration=560, Loss=0.9700208902359009\n",
      "Iteration=570, Loss=0.9453685283660889\n",
      "Iteration=580, Loss=0.9387827515602112\n",
      "Iteration=590, Loss=0.9473352432250977\n",
      "Iteration=600, Loss=0.9682771563529968\n",
      "Iteration=610, Loss=0.9472578167915344\n",
      "Iteration=620, Loss=0.9594405889511108\n",
      "Iteration=630, Loss=0.9445109367370605\n",
      "Iteration=640, Loss=0.9382414221763611\n",
      "Iteration=650, Loss=0.9477490782737732\n",
      "Iteration=660, Loss=0.9580677151679993\n",
      "Iteration=670, Loss=0.9665212631225586\n",
      "Iteration=680, Loss=0.950658917427063\n",
      "Iteration=690, Loss=0.9358921647071838\n",
      "Iteration=700, Loss=0.9687539339065552\n",
      "Iteration=710, Loss=0.9572636485099792\n",
      "Iteration=720, Loss=0.9511886239051819\n",
      "Iteration=730, Loss=0.9606570601463318\n",
      "Iteration=740, Loss=0.9667680263519287\n",
      "Iteration=750, Loss=0.9953071475028992\n",
      "Iteration=760, Loss=0.9717366695404053\n",
      "Iteration=770, Loss=0.9510438442230225\n",
      "Iteration=780, Loss=0.9564897418022156\n",
      "Iteration=790, Loss=0.9815667271614075\n",
      "Iteration=800, Loss=0.9499089121818542\n",
      "Iteration=810, Loss=0.9255170822143555\n",
      "Iteration=820, Loss=0.9362720847129822\n",
      "Iteration=830, Loss=0.9553968906402588\n",
      "Iteration=840, Loss=0.970106303691864\n",
      "Iteration=850, Loss=0.9600211977958679\n",
      "Iteration=860, Loss=0.9349923133850098\n",
      "Iteration=870, Loss=0.9566249847412109\n",
      "Iteration=880, Loss=0.9342914819717407\n",
      "Iteration=890, Loss=0.9472260475158691\n",
      "Iteration=900, Loss=0.9369938373565674\n",
      "Iteration=910, Loss=0.94331294298172\n",
      "Iteration=920, Loss=0.9713606834411621\n",
      "Iteration=930, Loss=0.930788516998291\n",
      "Iteration=940, Loss=0.938468337059021\n",
      "Iteration=950, Loss=0.9629257321357727\n",
      "Iteration=960, Loss=0.952202558517456\n",
      "Iteration=970, Loss=0.9617842435836792\n",
      "Iteration=980, Loss=0.9166120290756226\n",
      "Iteration=990, Loss=0.9403278827667236\n",
      "Iteration=1000, Loss=0.9183094501495361\n",
      "Iteration=1010, Loss=0.9858039021492004\n",
      "Iteration=1020, Loss=0.9566103219985962\n",
      "Iteration=1030, Loss=0.9529057145118713\n",
      "Iteration=1040, Loss=0.9592706561088562\n",
      "Iteration=1050, Loss=0.9914935231208801\n",
      "Iteration=1060, Loss=0.949307382106781\n",
      "Iteration=1070, Loss=0.9465398192405701\n",
      "Iteration=1080, Loss=0.9175266027450562\n",
      "Iteration=1090, Loss=0.9774101972579956\n",
      "Iteration=1100, Loss=0.9483361840248108\n",
      "Iteration=1110, Loss=0.9433208703994751\n",
      "Iteration=1120, Loss=0.9298978447914124\n",
      "Iteration=1130, Loss=0.9337061047554016\n",
      "Iteration=1140, Loss=0.9266635775566101\n",
      "Iteration=1150, Loss=0.9452176094055176\n",
      "Iteration=1160, Loss=0.9389541745185852\n",
      "Iteration=1170, Loss=0.9478952884674072\n",
      "Iteration=1180, Loss=0.9887068867683411\n",
      "Iteration=1190, Loss=0.9585793018341064\n",
      "Iteration=1200, Loss=0.9525926113128662\n",
      "Iteration=1210, Loss=0.9213201999664307\n",
      "Iteration=1220, Loss=0.9638199210166931\n",
      "Iteration=1230, Loss=0.9754248857498169\n",
      "Iteration=1240, Loss=0.9504404067993164\n",
      "Iteration=1250, Loss=0.9399796724319458\n",
      "Iteration=1260, Loss=0.9363400936126709\n",
      "Iteration=1270, Loss=0.9231473803520203\n",
      "Iteration=1280, Loss=0.9292980432510376\n",
      "Iteration=1290, Loss=0.9500479102134705\n",
      "Iteration=1300, Loss=0.9589945077896118\n",
      "Iteration=1310, Loss=0.9313049912452698\n",
      "Iteration=1320, Loss=0.9522030353546143\n",
      "Iteration=1330, Loss=0.9635964632034302\n",
      "Iteration=1340, Loss=0.9343040585517883\n",
      "Iteration=1350, Loss=0.9406935572624207\n",
      "Iteration=1360, Loss=0.9452125430107117\n",
      "Iteration=1370, Loss=0.9277513027191162\n",
      "Iteration=1380, Loss=0.9274658560752869\n",
      "Iteration=1390, Loss=0.9386454224586487\n",
      "Iteration=1400, Loss=0.9476646184921265\n",
      "Iteration=1410, Loss=0.9481101632118225\n",
      "Iteration=1420, Loss=0.9462506771087646\n",
      "Iteration=1430, Loss=0.9360701441764832\n",
      "Iteration=1440, Loss=0.9437429904937744\n",
      "Iteration=1450, Loss=0.9416452646255493\n",
      "Iteration=1460, Loss=0.9402344226837158\n",
      "Iteration=1470, Loss=0.9593604803085327\n",
      "Iteration=1480, Loss=0.9366560578346252\n",
      "Iteration=1490, Loss=0.9380184412002563\n",
      "Iteration=1500, Loss=0.9435458183288574\n",
      "Iteration=1510, Loss=0.9473641514778137\n",
      "Iteration=1520, Loss=0.9264315366744995\n",
      "Iteration=1530, Loss=0.9270269274711609\n",
      "Iteration=1540, Loss=0.9553418159484863\n",
      "Iteration=1550, Loss=0.9374951124191284\n",
      "Iteration=1560, Loss=0.9294695258140564\n",
      "Iteration=1570, Loss=0.9445360898971558\n",
      "Iteration=1580, Loss=0.9498348236083984\n",
      "Iteration=1590, Loss=0.955222487449646\n",
      "Iteration=1600, Loss=0.9548137187957764\n",
      "Iteration=1610, Loss=0.9638881683349609\n",
      "Iteration=1620, Loss=0.9181447625160217\n",
      "Iteration=1630, Loss=0.9467114210128784\n",
      "Iteration=1640, Loss=0.9542984962463379\n",
      "Iteration=1650, Loss=0.9418955445289612\n",
      "Iteration=1660, Loss=0.9335135221481323\n",
      "Iteration=1670, Loss=0.9323384761810303\n",
      "Iteration=1680, Loss=0.9684138894081116\n",
      "Iteration=1690, Loss=0.9440127015113831\n",
      "Iteration=1700, Loss=0.9481633901596069\n",
      "Iteration=1710, Loss=0.9316962957382202\n",
      "Iteration=1720, Loss=0.961459219455719\n",
      "Iteration=1730, Loss=0.9468436241149902\n",
      "Iteration=1740, Loss=0.930199146270752\n",
      "Iteration=1750, Loss=0.9701391458511353\n",
      "Iteration=1760, Loss=0.9558908939361572\n",
      "Iteration=1770, Loss=0.9264614582061768\n",
      "Iteration=1780, Loss=0.9405872821807861\n",
      "Iteration=1790, Loss=0.9268642067909241\n",
      "Iteration=1800, Loss=0.9331551194190979\n",
      "Iteration=1810, Loss=0.9442657232284546\n",
      "Iteration=1820, Loss=0.9612933993339539\n",
      "Iteration=1830, Loss=0.9430733323097229\n",
      "Iteration=1840, Loss=0.9276075959205627\n",
      "Iteration=1850, Loss=0.946562647819519\n",
      "Iteration=1860, Loss=0.9308764934539795\n",
      "Iteration=1870, Loss=0.9637476801872253\n",
      "Iteration=1880, Loss=0.9465667009353638\n",
      "Iteration=1890, Loss=0.9616731405258179\n",
      "Iteration=1900, Loss=0.9564235806465149\n",
      "Iteration=1910, Loss=0.9626398086547852\n",
      "Iteration=1920, Loss=0.9296417236328125\n",
      "Iteration=1930, Loss=0.9477282166481018\n",
      "Iteration=1940, Loss=0.941489040851593\n",
      "Iteration=1950, Loss=0.9407414197921753\n",
      "Iteration=1960, Loss=0.9630061984062195\n",
      "Iteration=1970, Loss=0.9100674390792847\n",
      "Iteration=1980, Loss=0.9285539388656616\n",
      "Iteration=1990, Loss=0.92345130443573\n",
      "Iteration=2000, Loss=0.9493383169174194\n",
      "Iteration=2010, Loss=0.9663504958152771\n",
      "Iteration=2020, Loss=0.9712255597114563\n",
      "Iteration=2030, Loss=0.9414350390434265\n",
      "Iteration=2040, Loss=0.9268994927406311\n",
      "Iteration=2050, Loss=0.9136242866516113\n",
      "Iteration=2060, Loss=0.9468888640403748\n",
      "Iteration=2070, Loss=0.9240846037864685\n",
      "Iteration=2080, Loss=0.9175238609313965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2090, Loss=0.9618185758590698\n",
      "Iteration=2100, Loss=0.9550561904907227\n",
      "Iteration=2110, Loss=0.9406064748764038\n",
      "Iteration=2120, Loss=0.9381712079048157\n",
      "Iteration=2130, Loss=0.9363371729850769\n",
      "Iteration=2140, Loss=0.9519748091697693\n",
      "Iteration=2150, Loss=0.9238938093185425\n",
      "Iteration=2160, Loss=0.933324933052063\n",
      "Iteration=2170, Loss=0.921482264995575\n",
      "Iteration=2180, Loss=0.9389544725418091\n",
      "Iteration=2190, Loss=0.93348628282547\n",
      "Iteration=2200, Loss=0.9643319249153137\n",
      "Iteration=2210, Loss=0.9399455785751343\n",
      "Iteration=2220, Loss=0.9379822611808777\n",
      "Iteration=2230, Loss=0.9408054947853088\n",
      "Iteration=2240, Loss=0.9310736060142517\n",
      "Iteration=2250, Loss=0.9545102715492249\n",
      "Iteration=2260, Loss=0.9018595814704895\n",
      "Iteration=2270, Loss=0.9287023544311523\n",
      "Iteration=2280, Loss=0.9277300834655762\n",
      "Iteration=2290, Loss=0.9303678274154663\n",
      "Iteration=2300, Loss=0.9271658658981323\n",
      "Iteration=2310, Loss=0.9444338083267212\n",
      "Iteration=2320, Loss=0.9330013394355774\n",
      "Iteration=2330, Loss=0.9149361848831177\n",
      "Iteration=2340, Loss=0.928482174873352\n",
      "Iteration=2350, Loss=0.9382407665252686\n",
      "Iteration=2360, Loss=0.9426353573799133\n",
      "Iteration=2370, Loss=0.9323611855506897\n",
      "Iteration=2380, Loss=0.9198426604270935\n",
      "Iteration=2390, Loss=0.9276270866394043\n",
      "Iteration=2400, Loss=0.9513572454452515\n",
      "Iteration=2410, Loss=0.9416097402572632\n",
      "Iteration=2420, Loss=0.908289909362793\n",
      "Iteration=2430, Loss=0.9293826818466187\n",
      "Iteration=2440, Loss=0.9241717457771301\n",
      "Iteration=2450, Loss=0.9340466856956482\n",
      "Iteration=2460, Loss=0.9305023550987244\n",
      "Iteration=2470, Loss=0.9238256216049194\n",
      "Iteration=2480, Loss=0.9354375600814819\n",
      "Iteration=2490, Loss=0.9281411170959473\n",
      "Iteration=2500, Loss=0.9367249011993408\n",
      "Iteration=2510, Loss=0.9163667559623718\n",
      "Iteration=2520, Loss=0.9374949932098389\n",
      "Iteration=2530, Loss=0.9266340136528015\n",
      "Iteration=2540, Loss=0.913850724697113\n",
      "Iteration=2550, Loss=0.9338096976280212\n",
      "Iteration=2560, Loss=0.9215646982192993\n",
      "Iteration=2570, Loss=0.933612585067749\n",
      "Iteration=2580, Loss=0.9157775640487671\n",
      "Iteration=2590, Loss=0.9066393971443176\n",
      "Iteration=2600, Loss=0.9318601489067078\n",
      "Iteration=2610, Loss=0.9465411901473999\n",
      "Iteration=2620, Loss=0.9218394160270691\n",
      "Iteration=2630, Loss=0.9102721214294434\n",
      "Iteration=2640, Loss=0.9217272400856018\n",
      "Iteration=2650, Loss=0.9256371259689331\n",
      "Iteration=2660, Loss=0.9482525587081909\n",
      "Iteration=2670, Loss=0.9441503286361694\n",
      "Iteration=2680, Loss=0.9177225232124329\n",
      "Iteration=2690, Loss=0.9134151339530945\n",
      "Iteration=2700, Loss=0.9388210773468018\n",
      "Iteration=2710, Loss=0.9156242609024048\n",
      "Iteration=2720, Loss=0.9257513880729675\n",
      "Iteration=2730, Loss=0.9099437594413757\n",
      "Iteration=2740, Loss=0.9259634613990784\n",
      "Iteration=2750, Loss=0.9066067934036255\n",
      "Iteration=2760, Loss=0.9547169804573059\n",
      "Iteration=2770, Loss=0.9583955407142639\n",
      "Iteration=2780, Loss=0.9382607936859131\n",
      "Iteration=2790, Loss=0.9283554553985596\n",
      "Iteration=2800, Loss=0.9281840324401855\n",
      "Iteration=2810, Loss=0.9284489154815674\n",
      "Iteration=2820, Loss=0.9248447418212891\n",
      "Iteration=2830, Loss=0.9318386912345886\n",
      "Iteration=2840, Loss=0.9412868022918701\n",
      "Iteration=2850, Loss=0.9128121733665466\n",
      "Iteration=2860, Loss=0.9408146739006042\n",
      "Iteration=2870, Loss=0.9244732856750488\n",
      "Iteration=2880, Loss=0.9285522699356079\n",
      "Iteration=2890, Loss=0.9192438721656799\n",
      "Iteration=2900, Loss=0.9330770969390869\n",
      "Iteration=2910, Loss=0.928052544593811\n",
      "Iteration=2920, Loss=0.9403644800186157\n",
      "Iteration=2930, Loss=0.9243614673614502\n",
      "Iteration=2940, Loss=0.9100884795188904\n",
      "Iteration=2950, Loss=0.9425823092460632\n",
      "Iteration=2960, Loss=0.9160821437835693\n",
      "Iteration=2970, Loss=0.9041094779968262\n",
      "Iteration=2980, Loss=0.8978574275970459\n",
      "Iteration=2990, Loss=0.9078392386436462\n",
      "Iteration=3000, Loss=0.9241539835929871\n",
      "Iteration=3010, Loss=0.9325599074363708\n",
      "Iteration=3020, Loss=0.9461121559143066\n",
      "Iteration=3030, Loss=0.9200332760810852\n",
      "Iteration=3040, Loss=0.9259029030799866\n",
      "Iteration=3050, Loss=0.9472320675849915\n",
      "Iteration=3060, Loss=0.9359155893325806\n",
      "Iteration=3070, Loss=0.9622802138328552\n",
      "Iteration=3080, Loss=0.9190868735313416\n",
      "Iteration=3090, Loss=0.9595515727996826\n",
      "Iteration=3100, Loss=0.9223014116287231\n",
      "Iteration=3110, Loss=0.9289790391921997\n",
      "Iteration=3120, Loss=0.9281439185142517\n",
      "Iteration=3130, Loss=0.9345571994781494\n",
      "Iteration=3140, Loss=0.9220899343490601\n",
      "Iteration=3150, Loss=0.9309062361717224\n",
      "Iteration=3160, Loss=0.920850932598114\n",
      "Iteration=3170, Loss=0.9539651870727539\n",
      "Iteration=3180, Loss=0.9136256575584412\n",
      "Iteration=3190, Loss=0.9545075297355652\n",
      "Iteration=3200, Loss=0.9416061043739319\n",
      "Iteration=3210, Loss=0.9255325198173523\n",
      "Iteration=3220, Loss=0.9138842225074768\n",
      "Iteration=3230, Loss=0.9240210056304932\n",
      "Iteration=3240, Loss=0.9295854568481445\n",
      "Iteration=3250, Loss=0.9018807411193848\n",
      "Iteration=3260, Loss=0.9275285601615906\n",
      "Iteration=3270, Loss=0.9561067223548889\n",
      "Iteration=3280, Loss=0.9046407341957092\n",
      "Iteration=3290, Loss=0.9328047633171082\n",
      "Iteration=3300, Loss=0.9159401655197144\n",
      "Iteration=3310, Loss=0.8974841237068176\n",
      "Iteration=3320, Loss=0.9251717925071716\n",
      "Iteration=3330, Loss=0.9103739261627197\n",
      "Iteration=3340, Loss=0.92820805311203\n",
      "Iteration=3350, Loss=0.933811604976654\n",
      "Iteration=3360, Loss=0.9326730370521545\n",
      "Iteration=3370, Loss=0.9400198459625244\n",
      "Iteration=3380, Loss=0.920013427734375\n",
      "Iteration=3390, Loss=0.9284206032752991\n",
      "Iteration=3400, Loss=0.9102076888084412\n",
      "Iteration=3410, Loss=0.9144283533096313\n",
      "Iteration=3420, Loss=0.9214982390403748\n",
      "Iteration=3430, Loss=0.9139719605445862\n",
      "Iteration=3440, Loss=0.9276768565177917\n",
      "Iteration=3450, Loss=0.9421494007110596\n",
      "Iteration=3460, Loss=0.9336480498313904\n",
      "Iteration=3470, Loss=0.9617658853530884\n",
      "Iteration=3480, Loss=0.9120522737503052\n",
      "Iteration=3490, Loss=0.9189926981925964\n",
      "Iteration=3500, Loss=0.9188548922538757\n",
      "Iteration=3510, Loss=0.9378127455711365\n",
      "Iteration=3520, Loss=0.9088975191116333\n",
      "Iteration=3530, Loss=0.915505051612854\n",
      "Iteration=3540, Loss=0.9329206347465515\n",
      "Iteration=3550, Loss=0.9466409087181091\n",
      "Iteration=3560, Loss=0.9132453203201294\n",
      "Iteration=3570, Loss=0.8913832902908325\n",
      "Iteration=3580, Loss=0.9270612001419067\n",
      "Iteration=3590, Loss=0.9237337112426758\n",
      "Iteration=3600, Loss=0.9370215535163879\n",
      "Iteration=3610, Loss=0.9229235649108887\n",
      "Iteration=3620, Loss=0.9428931474685669\n",
      "Iteration=3630, Loss=0.9083573818206787\n",
      "Iteration=3640, Loss=0.9041386246681213\n",
      "Iteration=3650, Loss=0.9335718154907227\n",
      "Iteration=3660, Loss=0.9471745491027832\n",
      "Iteration=3670, Loss=0.9356175661087036\n",
      "Iteration=3680, Loss=0.9069882035255432\n",
      "Iteration=3690, Loss=0.9350732564926147\n",
      "Iteration=3700, Loss=0.8920592069625854\n",
      "Iteration=3710, Loss=0.9318889379501343\n",
      "Iteration=3720, Loss=0.9237187504768372\n",
      "Iteration=3730, Loss=0.9166960716247559\n",
      "Iteration=3740, Loss=0.92673659324646\n",
      "Iteration=3750, Loss=0.9113305807113647\n",
      "Iteration=3760, Loss=0.917967677116394\n",
      "Iteration=3770, Loss=0.9298427700996399\n",
      "Iteration=3780, Loss=0.9155352115631104\n",
      "Iteration=3790, Loss=0.9322522878646851\n",
      "Iteration=3800, Loss=0.9098371863365173\n",
      "Iteration=3810, Loss=0.9233831763267517\n",
      "Iteration=3820, Loss=0.9153589010238647\n",
      "Iteration=3830, Loss=0.9154771566390991\n",
      "Iteration=3840, Loss=0.9037384986877441\n",
      "Iteration=3850, Loss=0.9476086497306824\n",
      "Iteration=3860, Loss=0.9366655945777893\n",
      "Iteration=3870, Loss=0.9277550578117371\n",
      "Iteration=3880, Loss=0.904744565486908\n",
      "Iteration=3890, Loss=0.9130666255950928\n",
      "Iteration=3900, Loss=0.9321706891059875\n",
      "Iteration=3910, Loss=0.915121853351593\n",
      "Iteration=3920, Loss=0.9162781238555908\n",
      "Iteration=3930, Loss=0.9281948208808899\n",
      "Iteration=3940, Loss=0.9216231107711792\n",
      "Iteration=3950, Loss=0.9414318799972534\n",
      "Iteration=3960, Loss=0.9259437322616577\n",
      "Iteration=3970, Loss=0.914850652217865\n",
      "Iteration=3980, Loss=0.9060519337654114\n",
      "Iteration=3990, Loss=0.9212125539779663\n",
      "Iteration=4000, Loss=0.9356631636619568\n",
      "Iteration=4010, Loss=0.9296343922615051\n",
      "Iteration=4020, Loss=0.9121509194374084\n",
      "Iteration=4030, Loss=0.9569122195243835\n",
      "Iteration=4040, Loss=0.9206974506378174\n",
      "Iteration=4050, Loss=0.9539008140563965\n",
      "Iteration=4060, Loss=0.9696645736694336\n",
      "Iteration=4070, Loss=0.9462867975234985\n",
      "Iteration=4080, Loss=0.9200184941291809\n",
      "Iteration=4090, Loss=0.9094531536102295\n",
      "Iteration=4100, Loss=0.9458231925964355\n",
      "Iteration=4110, Loss=0.9410730004310608\n",
      "Iteration=4120, Loss=0.9610202312469482\n",
      "Iteration=4130, Loss=0.9114671945571899\n",
      "Iteration=4140, Loss=0.9181042909622192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=4150, Loss=0.9318855404853821\n",
      "Iteration=4160, Loss=0.9241802096366882\n",
      "Iteration=4170, Loss=0.9069603085517883\n",
      "Iteration=4180, Loss=0.9310295581817627\n",
      "Iteration=4190, Loss=0.9221225380897522\n",
      "Iteration=4200, Loss=0.9146918058395386\n",
      "Iteration=4210, Loss=0.906134843826294\n",
      "Iteration=4220, Loss=0.9279516339302063\n",
      "Iteration=4230, Loss=0.9181097745895386\n",
      "Iteration=4240, Loss=0.8909484148025513\n",
      "Iteration=4250, Loss=0.9169103503227234\n",
      "Iteration=4260, Loss=0.8976951837539673\n",
      "Iteration=4270, Loss=0.9297513365745544\n",
      "Iteration=4280, Loss=0.9030617475509644\n",
      "Iteration=4290, Loss=0.9120279550552368\n",
      "Iteration=4300, Loss=0.9117124080657959\n",
      "Iteration=4310, Loss=0.9369221329689026\n",
      "Iteration=4320, Loss=0.9147611856460571\n",
      "Iteration=4330, Loss=0.9112275838851929\n",
      "Iteration=4340, Loss=0.9281116127967834\n",
      "Iteration=4350, Loss=0.9263076782226562\n",
      "Iteration=4360, Loss=0.9048717617988586\n",
      "Iteration=4370, Loss=0.92313152551651\n",
      "Iteration=4380, Loss=0.9113330245018005\n",
      "Iteration=4390, Loss=0.920246422290802\n",
      "Iteration=4400, Loss=0.8943092226982117\n",
      "Iteration=4410, Loss=0.9225926995277405\n",
      "Iteration=4420, Loss=0.8963409066200256\n",
      "Iteration=4430, Loss=0.9359102249145508\n",
      "Iteration=4440, Loss=0.9141592383384705\n",
      "Iteration=4450, Loss=0.9314203858375549\n",
      "Iteration=4460, Loss=0.8975527286529541\n",
      "Iteration=4470, Loss=0.9205020666122437\n",
      "Iteration=4480, Loss=0.9154062271118164\n",
      "Iteration=4490, Loss=0.9080259203910828\n",
      "Iteration=4500, Loss=0.9355842471122742\n",
      "Iteration=4510, Loss=0.9364561438560486\n",
      "Iteration=4520, Loss=0.9114729166030884\n",
      "Iteration=4530, Loss=0.9127033948898315\n",
      "Iteration=4540, Loss=0.9032034277915955\n",
      "Iteration=4550, Loss=0.9151046276092529\n",
      "Iteration=4560, Loss=0.9034786820411682\n",
      "Iteration=4570, Loss=0.9222621917724609\n",
      "Iteration=4580, Loss=0.9324158430099487\n",
      "Iteration=4590, Loss=0.9203125238418579\n",
      "Iteration=4600, Loss=0.9147648811340332\n",
      "Iteration=4610, Loss=0.9382011294364929\n",
      "Iteration=4620, Loss=0.9283475279808044\n",
      "Iteration=4630, Loss=0.9310806393623352\n",
      "Iteration=4640, Loss=0.9162063598632812\n",
      "Iteration=4650, Loss=0.9421380162239075\n",
      "Iteration=4660, Loss=0.9238234162330627\n",
      "Iteration=4670, Loss=0.8934352993965149\n",
      "Iteration=4680, Loss=0.9173423051834106\n",
      "Iteration=4690, Loss=0.9116478562355042\n",
      "Iteration=4700, Loss=0.9478051066398621\n",
      "Iteration=4710, Loss=0.9158792495727539\n",
      "Iteration=4720, Loss=0.9053868055343628\n",
      "Iteration=4730, Loss=0.9060934782028198\n",
      "Iteration=4740, Loss=0.913569986820221\n",
      "Iteration=4750, Loss=0.9313490986824036\n",
      "Iteration=4760, Loss=0.9131643176078796\n",
      "Iteration=4770, Loss=0.907174825668335\n",
      "Iteration=4780, Loss=0.9201174378395081\n",
      "Iteration=4790, Loss=0.9063467383384705\n",
      "Iteration=4800, Loss=0.9404367208480835\n",
      "Iteration=4810, Loss=0.8920301198959351\n",
      "Iteration=4820, Loss=0.9150266051292419\n",
      "Iteration=4830, Loss=0.9362934827804565\n",
      "Iteration=4840, Loss=0.9113938212394714\n",
      "Iteration=4850, Loss=0.9401641488075256\n",
      "Iteration=4860, Loss=0.9372612833976746\n",
      "Iteration=4870, Loss=0.930777907371521\n",
      "Iteration=4880, Loss=0.9173958897590637\n",
      "Iteration=4890, Loss=0.9268637895584106\n",
      "Iteration=4900, Loss=0.9346209764480591\n",
      "Iteration=4910, Loss=0.9296956658363342\n",
      "Iteration=4920, Loss=0.9142114520072937\n",
      "Iteration=4930, Loss=0.9198489189147949\n",
      "Iteration=4940, Loss=0.9497901797294617\n",
      "Iteration=4950, Loss=0.9189837574958801\n",
      "Iteration=4960, Loss=0.9297921657562256\n",
      "Iteration=4970, Loss=0.9360734224319458\n",
      "Iteration=4980, Loss=0.9187976121902466\n",
      "Iteration=4990, Loss=0.9258231520652771\n",
      "Iteration=5000, Loss=0.9047440886497498\n",
      "Iteration=5010, Loss=0.9229951500892639\n",
      "Iteration=5020, Loss=0.9022511839866638\n",
      "Iteration=5030, Loss=0.9062305092811584\n",
      "Iteration=5040, Loss=0.8800610899925232\n",
      "Iteration=5050, Loss=0.921255886554718\n",
      "Iteration=5060, Loss=0.9181525707244873\n",
      "Iteration=5070, Loss=0.9075146317481995\n",
      "Iteration=5080, Loss=0.9070351719856262\n",
      "Iteration=5090, Loss=0.9360311031341553\n",
      "Iteration=5100, Loss=0.9225062131881714\n",
      "Iteration=5110, Loss=0.9149932265281677\n",
      "Iteration=5120, Loss=0.9026902318000793\n",
      "Iteration=5130, Loss=0.9232290387153625\n",
      "Iteration=5140, Loss=0.9141549468040466\n",
      "Iteration=5150, Loss=0.9349194765090942\n",
      "Iteration=5160, Loss=0.8948376178741455\n",
      "Iteration=5170, Loss=0.9133664965629578\n",
      "Iteration=5180, Loss=0.9227831959724426\n",
      "Iteration=5190, Loss=0.9317518472671509\n",
      "Iteration=5200, Loss=0.9281558990478516\n",
      "Iteration=5210, Loss=0.9082269072532654\n",
      "Iteration=5220, Loss=0.9339268803596497\n",
      "Iteration=5230, Loss=0.9080447554588318\n",
      "Iteration=5240, Loss=0.9101539850234985\n",
      "Iteration=5250, Loss=0.9173318147659302\n",
      "Iteration=5260, Loss=0.9203370213508606\n",
      "Iteration=5270, Loss=0.9230177402496338\n",
      "Iteration=5280, Loss=0.8889418840408325\n",
      "Iteration=5290, Loss=0.9078935980796814\n",
      "Iteration=5300, Loss=0.9123856425285339\n",
      "Iteration=5310, Loss=0.9317278861999512\n",
      "Iteration=5320, Loss=0.9212490916252136\n",
      "Iteration=5330, Loss=0.9274614453315735\n",
      "Iteration=5340, Loss=0.9079551100730896\n",
      "Iteration=5350, Loss=0.9178694486618042\n",
      "Iteration=5360, Loss=0.9077380299568176\n",
      "Iteration=5370, Loss=0.9242512583732605\n",
      "Iteration=5380, Loss=0.9215088486671448\n",
      "Iteration=5390, Loss=0.9165703058242798\n",
      "Iteration=5400, Loss=0.9156142473220825\n",
      "Iteration=5410, Loss=0.9390289783477783\n",
      "Iteration=5420, Loss=0.9578953981399536\n",
      "Iteration=5430, Loss=0.9130493402481079\n",
      "Iteration=5440, Loss=0.8985817432403564\n",
      "Iteration=5450, Loss=0.9082524180412292\n",
      "Iteration=5460, Loss=0.9069703817367554\n",
      "Iteration=5470, Loss=0.913421630859375\n",
      "Iteration=5480, Loss=0.9073169827461243\n",
      "Iteration=5490, Loss=0.9266238808631897\n",
      "Iteration=5500, Loss=0.8987581133842468\n",
      "Iteration=5510, Loss=0.9110146760940552\n",
      "Iteration=5520, Loss=0.930156946182251\n",
      "Iteration=5530, Loss=0.9165660738945007\n",
      "Iteration=5540, Loss=0.9089168906211853\n",
      "Iteration=5550, Loss=0.9083291292190552\n",
      "Iteration=5560, Loss=0.9204663634300232\n",
      "Iteration=5570, Loss=0.9261587858200073\n",
      "Iteration=5580, Loss=0.8974093198776245\n",
      "Iteration=5590, Loss=0.9138906598091125\n",
      "Iteration=5600, Loss=0.9268739223480225\n",
      "Iteration=5610, Loss=0.9420342445373535\n",
      "Iteration=5620, Loss=0.9402357339859009\n",
      "Iteration=5630, Loss=0.9198808670043945\n",
      "Iteration=5640, Loss=0.9208962321281433\n",
      "Iteration=5650, Loss=0.9378258585929871\n",
      "Iteration=5660, Loss=0.9197331070899963\n",
      "Iteration=5670, Loss=0.9390382170677185\n",
      "Iteration=5680, Loss=0.9029162526130676\n",
      "Iteration=5690, Loss=0.9221988320350647\n",
      "Iteration=5700, Loss=0.929760217666626\n",
      "Iteration=5710, Loss=0.9039371609687805\n",
      "Iteration=5720, Loss=0.9393478631973267\n",
      "Iteration=5730, Loss=0.921882688999176\n",
      "Iteration=5740, Loss=0.9152624011039734\n",
      "Iteration=5750, Loss=0.9275732636451721\n",
      "Iteration=5760, Loss=0.9043557643890381\n",
      "Iteration=5770, Loss=0.9317978024482727\n",
      "Iteration=5780, Loss=0.9216039180755615\n",
      "Iteration=5790, Loss=0.9113865494728088\n",
      "Iteration=5800, Loss=0.9147869944572449\n",
      "Iteration=5810, Loss=0.9288199543952942\n",
      "Iteration=5820, Loss=0.9053239226341248\n",
      "Iteration=5830, Loss=0.9141728281974792\n",
      "Iteration=5840, Loss=0.9207417368888855\n",
      "Iteration=5850, Loss=0.9154521822929382\n",
      "Iteration=5860, Loss=0.9231301546096802\n",
      "Iteration=5870, Loss=0.9246306419372559\n",
      "Iteration=5880, Loss=0.9426169395446777\n",
      "Iteration=5890, Loss=0.9269417524337769\n",
      "Iteration=5900, Loss=0.9206843376159668\n",
      "Iteration=5910, Loss=0.9065728783607483\n",
      "Iteration=5920, Loss=0.9181362986564636\n",
      "Iteration=5930, Loss=0.9017365574836731\n",
      "Iteration=5940, Loss=0.913526177406311\n",
      "Iteration=5950, Loss=0.8865150213241577\n",
      "Iteration=5960, Loss=0.9040818810462952\n",
      "Iteration=5970, Loss=0.9297836422920227\n",
      "Iteration=5980, Loss=0.9187654256820679\n",
      "Iteration=5990, Loss=0.9288190603256226\n",
      "Iteration=6000, Loss=0.913538932800293\n",
      "Iteration=6010, Loss=0.917314887046814\n",
      "Iteration=6020, Loss=0.918716549873352\n",
      "Iteration=6030, Loss=0.907743513584137\n",
      "Iteration=6040, Loss=0.939223051071167\n",
      "Iteration=6050, Loss=0.9071580767631531\n",
      "Iteration=6060, Loss=0.8910884857177734\n",
      "Iteration=6070, Loss=0.8964396715164185\n",
      "Iteration=6080, Loss=0.8968071341514587\n",
      "Iteration=6090, Loss=0.9156124591827393\n",
      "Iteration=6100, Loss=0.9312899112701416\n",
      "Iteration=6110, Loss=0.9028944969177246\n",
      "Iteration=6120, Loss=0.8985048532485962\n",
      "Iteration=6130, Loss=0.9282670021057129\n",
      "Iteration=6140, Loss=0.9034601449966431\n",
      "Iteration=6150, Loss=0.9285654425621033\n",
      "Iteration=6160, Loss=0.9045392870903015\n",
      "Iteration=6170, Loss=0.9322748184204102\n",
      "Iteration=6180, Loss=0.9159601330757141\n",
      "Iteration=6190, Loss=0.8986068367958069\n",
      "Iteration=6200, Loss=0.8999622464179993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=6210, Loss=0.9156532883644104\n",
      "Iteration=6220, Loss=0.913910448551178\n",
      "Iteration=6230, Loss=0.9199516177177429\n",
      "Iteration=6240, Loss=0.9246274828910828\n",
      "Iteration=6250, Loss=0.9278907179832458\n",
      "Iteration=6260, Loss=0.906621515750885\n",
      "Iteration=6270, Loss=0.8954688310623169\n",
      "Iteration=6280, Loss=0.9097052216529846\n",
      "Iteration=6290, Loss=0.9047282338142395\n",
      "Iteration=6300, Loss=0.9204365611076355\n",
      "Iteration=6310, Loss=0.9131746292114258\n",
      "Iteration=6320, Loss=0.9276635646820068\n",
      "Iteration=6330, Loss=0.9092298746109009\n",
      "Iteration=6340, Loss=0.9166369438171387\n",
      "Iteration=6350, Loss=0.9094070792198181\n",
      "Iteration=6360, Loss=0.9043735861778259\n",
      "Iteration=6370, Loss=0.9278938174247742\n",
      "Iteration=6380, Loss=0.9091252088546753\n",
      "Iteration=6390, Loss=0.901544451713562\n",
      "Iteration=6400, Loss=0.9021129608154297\n",
      "Iteration=6410, Loss=0.9241980910301208\n",
      "Iteration=6420, Loss=0.9109318256378174\n",
      "Iteration=6430, Loss=0.9086185693740845\n",
      "Iteration=6440, Loss=0.9104467034339905\n",
      "Iteration=6450, Loss=0.9264398813247681\n",
      "Iteration=6460, Loss=0.9156043529510498\n",
      "Iteration=6470, Loss=0.9089428782463074\n",
      "Iteration=6480, Loss=0.9319911599159241\n",
      "Iteration=6490, Loss=0.9387880563735962\n",
      "Iteration=6500, Loss=0.9110350608825684\n",
      "Iteration=6510, Loss=0.9047060608863831\n",
      "Iteration=6520, Loss=0.907074511051178\n",
      "Iteration=6530, Loss=0.8975458741188049\n",
      "Iteration=6540, Loss=0.9127410650253296\n",
      "Iteration=6550, Loss=0.9140393733978271\n",
      "Iteration=6560, Loss=0.9084776639938354\n",
      "Iteration=6570, Loss=0.8946964740753174\n",
      "Iteration=6580, Loss=0.9204469919204712\n",
      "Iteration=6590, Loss=0.9028860926628113\n",
      "Iteration=6600, Loss=0.9065434336662292\n",
      "Iteration=6610, Loss=0.9169270396232605\n",
      "Iteration=6620, Loss=0.9215455651283264\n",
      "Iteration=6630, Loss=0.9447391033172607\n",
      "Iteration=6640, Loss=0.9175218343734741\n",
      "Iteration=6650, Loss=0.9259793162345886\n",
      "Iteration=6660, Loss=0.8911834359169006\n",
      "Iteration=6670, Loss=0.9095652103424072\n",
      "Iteration=6680, Loss=0.9209030270576477\n",
      "Iteration=6690, Loss=0.9036973118782043\n",
      "Iteration=6700, Loss=0.9177356958389282\n",
      "Iteration=6710, Loss=0.9402042627334595\n",
      "Iteration=6720, Loss=0.9110747575759888\n",
      "Iteration=6730, Loss=0.9116807579994202\n",
      "Iteration=6740, Loss=0.9054537415504456\n",
      "Iteration=6750, Loss=0.8946715593338013\n",
      "Iteration=6760, Loss=0.9181012511253357\n",
      "Iteration=6770, Loss=0.9085108637809753\n",
      "Iteration=6780, Loss=0.9024946689605713\n",
      "Iteration=6790, Loss=0.9280110597610474\n",
      "Iteration=6800, Loss=0.9011121988296509\n",
      "Iteration=6810, Loss=0.9223334193229675\n",
      "Iteration=6820, Loss=0.9206798076629639\n",
      "Iteration=6830, Loss=0.9387232065200806\n",
      "Iteration=6840, Loss=0.9109699130058289\n",
      "Iteration=6850, Loss=0.9135181903839111\n",
      "Iteration=6860, Loss=0.9082005620002747\n",
      "Iteration=6870, Loss=0.9335470795631409\n",
      "Iteration=6880, Loss=0.9208477139472961\n",
      "Iteration=6890, Loss=0.9209782481193542\n",
      "Iteration=6900, Loss=0.8966823220252991\n",
      "Iteration=6910, Loss=0.912346601486206\n",
      "Iteration=6920, Loss=0.9187207818031311\n",
      "Iteration=6930, Loss=0.8916344046592712\n",
      "Iteration=6940, Loss=0.9254275560379028\n",
      "Iteration=6950, Loss=0.9173106551170349\n",
      "Iteration=6960, Loss=0.9232832193374634\n",
      "Iteration=6970, Loss=0.9287547469139099\n",
      "Iteration=6980, Loss=0.917697012424469\n",
      "Iteration=6990, Loss=0.9032706618309021\n",
      "Iteration=7000, Loss=0.9130563735961914\n",
      "Iteration=7010, Loss=0.9074125289916992\n",
      "Iteration=7020, Loss=0.9136830568313599\n",
      "Iteration=7030, Loss=0.9276835918426514\n",
      "Iteration=7040, Loss=0.9046623706817627\n",
      "Iteration=7050, Loss=0.897989809513092\n",
      "Iteration=7060, Loss=0.9102967977523804\n",
      "Iteration=7070, Loss=0.9034202694892883\n",
      "Iteration=7080, Loss=0.9030854105949402\n",
      "Iteration=7090, Loss=0.9171832799911499\n",
      "Iteration=7100, Loss=0.9278709292411804\n",
      "Iteration=7110, Loss=0.948591411113739\n",
      "Iteration=7120, Loss=0.9238158464431763\n",
      "Iteration=7130, Loss=0.9213323593139648\n",
      "Iteration=7140, Loss=0.8977653384208679\n",
      "Iteration=7150, Loss=0.9316801428794861\n",
      "Iteration=7160, Loss=0.8739411234855652\n",
      "Iteration=7170, Loss=0.9126629829406738\n",
      "Iteration=7180, Loss=0.9146217703819275\n",
      "Iteration=7190, Loss=0.9100335836410522\n",
      "Iteration=7200, Loss=0.9180660247802734\n",
      "Iteration=7210, Loss=0.9145538210868835\n",
      "Iteration=7220, Loss=0.9171282052993774\n",
      "Iteration=7230, Loss=0.9079154133796692\n",
      "Iteration=7240, Loss=0.9162712693214417\n",
      "Iteration=7250, Loss=0.9040039777755737\n",
      "Iteration=7260, Loss=0.916130542755127\n",
      "Iteration=7270, Loss=0.9012607932090759\n",
      "Iteration=7280, Loss=0.9262324571609497\n",
      "Iteration=7290, Loss=0.920246422290802\n",
      "Iteration=7300, Loss=0.924339234828949\n",
      "Iteration=7310, Loss=0.9238434433937073\n",
      "Iteration=7320, Loss=0.9319983124732971\n",
      "Iteration=7330, Loss=0.9212439656257629\n",
      "Iteration=7340, Loss=0.9072315096855164\n",
      "Iteration=7350, Loss=0.9131258726119995\n",
      "Iteration=7360, Loss=0.9302449822425842\n",
      "Iteration=7370, Loss=0.9160155057907104\n",
      "Iteration=7380, Loss=0.9146044254302979\n",
      "Iteration=7390, Loss=0.8942424058914185\n",
      "Iteration=7400, Loss=0.9254328012466431\n",
      "Iteration=7410, Loss=0.9182205200195312\n",
      "Iteration=7420, Loss=0.9208139777183533\n",
      "Iteration=7430, Loss=0.9171989560127258\n",
      "Iteration=7440, Loss=0.8957910537719727\n",
      "Iteration=7450, Loss=0.9254591464996338\n",
      "Iteration=7460, Loss=0.9333077073097229\n",
      "Iteration=7470, Loss=0.9106940627098083\n",
      "Iteration=7480, Loss=0.9077476859092712\n",
      "Iteration=7490, Loss=0.8987178802490234\n",
      "Iteration=7500, Loss=0.920610249042511\n",
      "Iteration=7510, Loss=0.8895715475082397\n",
      "Iteration=7520, Loss=0.9317842125892639\n",
      "Iteration=7530, Loss=0.9144097566604614\n",
      "Iteration=7540, Loss=0.8894338607788086\n",
      "Iteration=7550, Loss=0.9101512432098389\n",
      "Iteration=7560, Loss=0.9264200329780579\n",
      "Iteration=7570, Loss=0.9015594124794006\n",
      "Iteration=7580, Loss=0.926223635673523\n",
      "Iteration=7590, Loss=0.9173632860183716\n",
      "Iteration=7600, Loss=0.9123742580413818\n",
      "Iteration=7610, Loss=0.9133653044700623\n",
      "Iteration=7620, Loss=0.8931904435157776\n",
      "Iteration=7630, Loss=0.9040308594703674\n",
      "Iteration=7640, Loss=0.9132015109062195\n",
      "Iteration=7650, Loss=0.9138453006744385\n",
      "Iteration=7660, Loss=0.9092702865600586\n",
      "Iteration=7670, Loss=0.9110307097434998\n",
      "Iteration=7680, Loss=0.9190446138381958\n",
      "Iteration=7690, Loss=0.8970077037811279\n",
      "Iteration=7700, Loss=0.8884124159812927\n",
      "Iteration=7710, Loss=0.9291645288467407\n",
      "Iteration=7720, Loss=0.9092629551887512\n",
      "Iteration=7730, Loss=0.9169955849647522\n",
      "Iteration=7740, Loss=0.9099246263504028\n",
      "Iteration=7750, Loss=0.9335119724273682\n",
      "Iteration=7760, Loss=0.9261265993118286\n",
      "Iteration=7770, Loss=0.8936766386032104\n",
      "Iteration=7780, Loss=0.906010091304779\n",
      "Iteration=7790, Loss=0.9321728944778442\n",
      "Iteration=7800, Loss=0.9320993423461914\n",
      "Iteration=7810, Loss=0.9040805697441101\n",
      "Iteration=7820, Loss=0.9000951051712036\n",
      "Iteration=7830, Loss=0.8845037221908569\n",
      "Iteration=7840, Loss=0.8921507000923157\n",
      "Iteration=7850, Loss=0.8938736319541931\n",
      "Iteration=7860, Loss=0.9094971418380737\n",
      "Iteration=7870, Loss=0.9318932890892029\n",
      "Iteration=7880, Loss=0.9243625402450562\n",
      "Iteration=7890, Loss=0.9133968949317932\n",
      "Iteration=7900, Loss=0.915671169757843\n",
      "Iteration=7910, Loss=0.9296618103981018\n",
      "Iteration=7920, Loss=0.9234278798103333\n",
      "Iteration=7930, Loss=0.9280146956443787\n",
      "Iteration=7940, Loss=0.9240766763687134\n",
      "Iteration=7950, Loss=0.9456203579902649\n",
      "Iteration=7960, Loss=0.9083394408226013\n",
      "Iteration=7970, Loss=0.9150674343109131\n",
      "Iteration=7980, Loss=0.9103894233703613\n",
      "Iteration=7990, Loss=0.9046399593353271\n",
      "Iteration=8000, Loss=0.9041739702224731\n",
      "Iteration=8010, Loss=0.9078429937362671\n",
      "Iteration=8020, Loss=0.8999642133712769\n",
      "Iteration=8030, Loss=0.9171137809753418\n",
      "Iteration=8040, Loss=0.9292637705802917\n",
      "Iteration=8050, Loss=0.9113261699676514\n",
      "Iteration=8060, Loss=0.902283787727356\n",
      "Iteration=8070, Loss=0.9385260343551636\n",
      "Iteration=8080, Loss=0.8967512845993042\n",
      "Iteration=8090, Loss=0.9102505445480347\n",
      "Iteration=8100, Loss=0.9124329090118408\n",
      "Iteration=8110, Loss=0.8890848755836487\n",
      "Iteration=8120, Loss=0.893124520778656\n",
      "Iteration=8130, Loss=0.9056158065795898\n",
      "Iteration=8140, Loss=0.9058690667152405\n",
      "Iteration=8150, Loss=0.9023287892341614\n",
      "Iteration=8160, Loss=0.8943549990653992\n",
      "Iteration=8170, Loss=0.9284734129905701\n",
      "Iteration=8180, Loss=0.902259111404419\n",
      "Iteration=8190, Loss=0.9142075777053833\n",
      "Iteration=8200, Loss=0.9242256283760071\n",
      "Iteration=8210, Loss=0.9046323299407959\n",
      "Iteration=8220, Loss=0.9271213412284851\n",
      "Iteration=8230, Loss=0.9049121737480164\n",
      "Iteration=8240, Loss=0.9105831980705261\n",
      "Iteration=8250, Loss=0.9250867962837219\n",
      "Iteration=8260, Loss=0.9097384810447693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=8270, Loss=0.9193779826164246\n",
      "Iteration=8280, Loss=0.8974387645721436\n",
      "Iteration=8290, Loss=0.931049108505249\n",
      "Iteration=8300, Loss=0.9147986173629761\n",
      "Iteration=8310, Loss=0.9016770720481873\n",
      "Iteration=8320, Loss=0.9324605464935303\n",
      "Iteration=8330, Loss=0.9262558817863464\n",
      "Iteration=8340, Loss=0.907590389251709\n",
      "Iteration=8350, Loss=0.9092491865158081\n",
      "Iteration=8360, Loss=0.9088373780250549\n",
      "Iteration=8370, Loss=0.9015715718269348\n",
      "Iteration=8380, Loss=0.9123635292053223\n",
      "Iteration=8390, Loss=0.9544125199317932\n",
      "Iteration=8400, Loss=0.9306545853614807\n",
      "Iteration=8410, Loss=0.9151895642280579\n",
      "Iteration=8420, Loss=0.9161475896835327\n",
      "Iteration=8430, Loss=0.9023685455322266\n",
      "Iteration=8440, Loss=0.9001863598823547\n",
      "Iteration=8450, Loss=0.9149475693702698\n",
      "Iteration=8460, Loss=0.9098836779594421\n",
      "Iteration=8470, Loss=0.9196987748146057\n",
      "Iteration=8480, Loss=0.9066348671913147\n",
      "Iteration=8490, Loss=0.9217165112495422\n",
      "Iteration=8500, Loss=0.9137462973594666\n",
      "Iteration=8510, Loss=0.905043363571167\n",
      "Iteration=8520, Loss=0.9238941073417664\n",
      "Iteration=8530, Loss=0.8974086046218872\n",
      "Iteration=8540, Loss=0.9066294431686401\n",
      "Iteration=8550, Loss=0.9068686962127686\n",
      "Iteration=8560, Loss=0.9243453741073608\n",
      "Iteration=8570, Loss=0.9130863547325134\n",
      "Iteration=8580, Loss=0.9297818541526794\n",
      "Iteration=8590, Loss=0.9067469239234924\n",
      "Iteration=8600, Loss=0.9105821847915649\n",
      "Iteration=8610, Loss=0.8946219682693481\n",
      "Iteration=8620, Loss=0.8885228633880615\n",
      "Iteration=8630, Loss=0.9341106414794922\n",
      "Iteration=8640, Loss=0.9121537804603577\n",
      "Iteration=8650, Loss=0.902024507522583\n",
      "Iteration=8660, Loss=0.9081390500068665\n",
      "Iteration=8670, Loss=0.9241268038749695\n",
      "Iteration=8680, Loss=0.9235237836837769\n",
      "Iteration=8690, Loss=0.8917461037635803\n",
      "Iteration=8700, Loss=0.9214863181114197\n",
      "Iteration=8710, Loss=0.9088792204856873\n",
      "Iteration=8720, Loss=0.9109627604484558\n",
      "Iteration=8730, Loss=0.9106635451316833\n",
      "Iteration=8740, Loss=0.9225070476531982\n",
      "Iteration=8750, Loss=0.902328610420227\n",
      "Iteration=8760, Loss=0.9195022583007812\n",
      "Iteration=8770, Loss=0.8853309750556946\n",
      "Iteration=8780, Loss=0.9243746399879456\n",
      "Iteration=8790, Loss=0.8885851502418518\n",
      "Iteration=8800, Loss=0.8865833878517151\n",
      "Iteration=8810, Loss=0.9013884663581848\n",
      "Iteration=8820, Loss=0.9249646663665771\n",
      "Iteration=8830, Loss=0.9052287340164185\n",
      "Iteration=8840, Loss=0.9312447905540466\n",
      "Iteration=8850, Loss=0.9005892872810364\n",
      "Iteration=8860, Loss=0.9057114720344543\n",
      "Iteration=8870, Loss=0.9246974587440491\n",
      "Iteration=8880, Loss=0.9160802364349365\n",
      "Iteration=8890, Loss=0.9111404418945312\n",
      "Iteration=8900, Loss=0.9027053117752075\n",
      "Iteration=8910, Loss=0.9124698638916016\n",
      "Iteration=8920, Loss=0.9160116314888\n",
      "Iteration=8930, Loss=0.9190593361854553\n",
      "Iteration=8940, Loss=0.916302502155304\n",
      "Iteration=8950, Loss=0.9038670063018799\n",
      "Iteration=8960, Loss=0.8953988552093506\n",
      "Iteration=8970, Loss=0.9048135280609131\n",
      "Iteration=8980, Loss=0.9135246872901917\n",
      "Iteration=8990, Loss=0.9029882550239563\n",
      "Iteration=9000, Loss=0.9173498749732971\n",
      "Iteration=9010, Loss=0.917543888092041\n",
      "Iteration=9020, Loss=0.9084089994430542\n",
      "Iteration=9030, Loss=0.9053840041160583\n",
      "Iteration=9040, Loss=0.9353742599487305\n",
      "Iteration=9050, Loss=0.9086499214172363\n",
      "Iteration=9060, Loss=0.9033845663070679\n",
      "Iteration=9070, Loss=0.91902095079422\n",
      "Iteration=9080, Loss=0.9066286683082581\n",
      "Iteration=9090, Loss=0.9148077368736267\n",
      "Iteration=9100, Loss=0.9143617153167725\n",
      "Iteration=9110, Loss=0.9282116293907166\n",
      "Iteration=9120, Loss=0.9092509746551514\n",
      "Iteration=9130, Loss=0.940605878829956\n",
      "Iteration=9140, Loss=0.9136434197425842\n",
      "Iteration=9150, Loss=0.9087077379226685\n",
      "Iteration=9160, Loss=0.9196925163269043\n",
      "Iteration=9170, Loss=0.9205878376960754\n",
      "Iteration=9180, Loss=0.92631995677948\n",
      "Iteration=9190, Loss=0.938378095626831\n",
      "Iteration=9200, Loss=0.9055784940719604\n",
      "Iteration=9210, Loss=0.9122841954231262\n",
      "Iteration=9220, Loss=0.9012717604637146\n",
      "Iteration=9230, Loss=0.9237623810768127\n",
      "Iteration=9240, Loss=0.9272502660751343\n",
      "Iteration=9250, Loss=0.9092423319816589\n",
      "Iteration=9260, Loss=0.9211629629135132\n",
      "Iteration=9270, Loss=0.9143098592758179\n",
      "Iteration=9280, Loss=0.906934916973114\n",
      "Iteration=9290, Loss=0.945585310459137\n",
      "Iteration=9300, Loss=0.9141154289245605\n",
      "Iteration=9310, Loss=0.8984903693199158\n",
      "Iteration=9320, Loss=0.912152886390686\n",
      "Iteration=9330, Loss=0.8859656453132629\n",
      "Iteration=9340, Loss=0.8962624073028564\n",
      "Iteration=9350, Loss=0.9152499437332153\n",
      "Iteration=9360, Loss=0.9160184264183044\n",
      "Iteration=9370, Loss=0.9032418727874756\n",
      "Iteration=9380, Loss=0.8749914169311523\n",
      "Iteration=9390, Loss=0.9292677044868469\n",
      "Iteration=9400, Loss=0.8968750834465027\n",
      "Iteration=9410, Loss=0.8985421657562256\n",
      "Iteration=9420, Loss=0.911494791507721\n",
      "Iteration=9430, Loss=0.9295501708984375\n",
      "Iteration=9440, Loss=0.9346979260444641\n",
      "Iteration=9450, Loss=0.8930538296699524\n",
      "Iteration=9460, Loss=0.9145749807357788\n",
      "Iteration=9470, Loss=0.8925708532333374\n",
      "Iteration=9480, Loss=0.9057163596153259\n",
      "Iteration=9490, Loss=0.9069083333015442\n",
      "Iteration=9500, Loss=0.898924708366394\n",
      "Iteration=9510, Loss=0.9172166585922241\n",
      "Iteration=9520, Loss=0.8914910554885864\n",
      "Iteration=9530, Loss=0.8943433165550232\n",
      "Iteration=9540, Loss=0.9208699464797974\n",
      "Iteration=9550, Loss=0.9067075252532959\n",
      "Iteration=9560, Loss=0.9220702648162842\n",
      "Iteration=9570, Loss=0.9071189761161804\n",
      "Iteration=9580, Loss=0.9230214357376099\n",
      "Iteration=9590, Loss=0.9238212704658508\n",
      "Iteration=9600, Loss=0.9048753380775452\n",
      "Iteration=9610, Loss=0.9131994247436523\n",
      "Iteration=9620, Loss=0.9123514890670776\n",
      "Iteration=9630, Loss=0.9164752960205078\n",
      "Iteration=9640, Loss=0.9150354266166687\n",
      "Iteration=9650, Loss=0.926547110080719\n",
      "Iteration=9660, Loss=0.928531289100647\n",
      "Iteration=9670, Loss=0.9093852639198303\n",
      "Iteration=9680, Loss=0.9104628562927246\n",
      "Iteration=9690, Loss=0.8902515172958374\n",
      "Iteration=9700, Loss=0.9127122163772583\n",
      "Iteration=9710, Loss=0.9033163785934448\n",
      "Iteration=9720, Loss=0.9067475199699402\n",
      "Iteration=9730, Loss=0.8964802026748657\n",
      "Iteration=9740, Loss=0.9161776304244995\n",
      "Iteration=9750, Loss=0.9173728823661804\n",
      "Iteration=9760, Loss=0.9249678254127502\n",
      "Iteration=9770, Loss=0.9194453358650208\n",
      "Iteration=9780, Loss=0.9069997668266296\n",
      "Iteration=9790, Loss=0.9104103446006775\n",
      "Iteration=9800, Loss=0.9340026378631592\n",
      "Iteration=9810, Loss=0.9285800457000732\n",
      "Iteration=9820, Loss=0.9137704372406006\n",
      "Iteration=9830, Loss=0.9281841516494751\n",
      "Iteration=9840, Loss=0.9150311946868896\n",
      "Iteration=9850, Loss=0.9273048043251038\n",
      "Iteration=9860, Loss=0.9122304320335388\n",
      "Iteration=9870, Loss=0.9071434140205383\n",
      "Iteration=9880, Loss=0.9222359657287598\n",
      "Iteration=9890, Loss=0.9134398698806763\n",
      "Iteration=9900, Loss=0.8843900561332703\n",
      "Iteration=9910, Loss=0.9088042974472046\n",
      "Iteration=9920, Loss=0.9373608231544495\n",
      "Iteration=9930, Loss=0.9243477582931519\n",
      "Iteration=9940, Loss=0.9069916009902954\n",
      "Iteration=9950, Loss=0.9023510813713074\n",
      "Iteration=9960, Loss=0.9259278178215027\n",
      "Iteration=9970, Loss=0.9260559678077698\n",
      "Iteration=9980, Loss=0.8844252824783325\n",
      "Iteration=9990, Loss=0.9180198907852173\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "dropout_probability = 0.25\n",
    "soft_label_weight = 0\n",
    "batch_size = 1000\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "\n",
    "# Fixed parameters, model architecture\n",
    "num_classes = 3\n",
    "embedding_dim = 50\n",
    "leaky_relu_negative_slope = 0.1\n",
    "\n",
    "# Fixed parameters, model training\n",
    "num_iterations = 10000\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "check_every = 10\n",
    "\n",
    "baseline_DAN = DistilledDAN(num_classes, embedding_dim, hidden_dim1, hidden_dim2, 0, leaky_relu_negative_slope, dropout_probability, False, False)\n",
    "optimizer = torch.optim.Adam(baseline_DAN.parameters(), lr=learning_rate)\n",
    "loss_history, train_accuracy, dev_accuracy = baseline_DAN.train_model(X_train, Y_train, X_dev, Y_dev, soft_labels, optimizer, num_iterations, soft_label_weight, loss_fn, batch_size, check_every, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f7a8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dev acc for baseline DAN 0.619\n",
      "best train acc for baseline DAN 0.624224487558917\n"
     ]
    }
   ],
   "source": [
    "print(\"best dev acc for baseline DAN\", dev_accuracy[np.argmax(dev_accuracy)])\n",
    "print(\"best train acc for baseline DAN\", train_accuracy[np.argmax(dev_accuracy)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34501ec2",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf36abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Y_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>Sentinel Editorial: FBI’s Comey ‘had no one of...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12280</th>\n",
       "      <td>perfect pussy clips #vanessa hudgens zac efron...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>#latestnews 4 #newmexico #politics + #nativeam...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12282</th>\n",
       "      <td>Trying to have a conversation with my dad abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12283</th>\n",
       "      <td>@user You are a stand up guy and a Gentleman V...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12284 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label sentiment   \n",
       "0      @user @user what do these '1/2 naked pics' hav...      1   neutral  \\\n",
       "1      OH: “I had a blue penis while I was this” [pla...      1   neutral   \n",
       "2      @user @user That's coming, but I think the vic...      1   neutral   \n",
       "3      I think I may be finally in with the in crowd ...      2  positive   \n",
       "4      @user Wow,first Hugo Chavez and now Fidel Cast...      0  negative   \n",
       "...                                                  ...    ...       ...   \n",
       "12279  Sentinel Editorial: FBI’s Comey ‘had no one of...      1   neutral   \n",
       "12280  perfect pussy clips #vanessa hudgens zac efron...      1   neutral   \n",
       "12281  #latestnews 4 #newmexico #politics + #nativeam...      1   neutral   \n",
       "12282  Trying to have a conversation with my dad abou...      0  negative   \n",
       "12283  @user You are a stand up guy and a Gentleman V...      2  positive   \n",
       "\n",
       "                Y_hard  \n",
       "0      [0.0, 1.0, 0.0]  \n",
       "1      [0.0, 1.0, 0.0]  \n",
       "2      [0.0, 1.0, 0.0]  \n",
       "3      [0.0, 0.0, 1.0]  \n",
       "4      [1.0, 0.0, 0.0]  \n",
       "...                ...  \n",
       "12279  [0.0, 1.0, 0.0]  \n",
       "12280  [0.0, 1.0, 0.0]  \n",
       "12281  [0.0, 1.0, 0.0]  \n",
       "12282  [1.0, 0.0, 0.0]  \n",
       "12283  [0.0, 0.0, 1.0]  \n",
       "\n",
       "[12284 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "150a974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df513c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best student model test acc 0.6291924454575057\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = best_model.predict(Xmat_test)\n",
    "print(\"best student model test acc\", best_model.accuracy(Y_pred_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb9d9d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline DAN model test acc 0.6020026050146532\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test_baseline_DAN = baseline_DAN.predict(Xmat_test)\n",
    "print(\"baseline DAN model test acc\", baseline_DAN.accuracy(Y_pred_test_baseline_DAN, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f88a8",
   "metadata": {},
   "source": [
    "### Results - Test Accuracy\n",
    "\n",
    "```\n",
    "best student model test acc 0.6291924454575057\n",
    "baseline DAN model test acc 0.6020026050146532\n",
    "Baseline Embedding test accuracy: 0.6101432758059264\n",
    "Baseline BOW Test accuracy: 0.5902800390752198\n",
    "\n",
    "dev acc for baseline DAN 0.619\n",
    "Baseline BOW dev accuracy: 0.6775\n",
    "Baseline Embedding dev accuracy: 0.612\n",
    "best student model dev acc 62.7%\n",
    "\n",
    "train acc for baseline DAN 0.624224487558917\n",
    "Baseline Embedding train accuracy: 0.6146443056012276\n",
    "Baseline BOW train accuracy: Train accuracy: 0.9095472980379261\n",
    "best student model train acc 62.6%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "76864ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_baseline_DAN = [0, 0, 0]\n",
    "wrong_baseline_DAN = [0, 0, 0]\n",
    "for y, y_pred in zip(Y_test, Y_pred_test_baseline_DAN):\n",
    "    total_baseline_DAN[y] += 1\n",
    "    if y != y_pred:\n",
    "        # if the prediction is wrong\n",
    "        wrong_baseline_DAN[y] += 1\n",
    "\n",
    "percent_error_baseline_DAN = []\n",
    "\n",
    "for i in range(len(total_baseline_DAN)):\n",
    "    percent_error_baseline_DAN.append(wrong_baseline_DAN[i]/total_baseline_DAN[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad710d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6754783484390735, 0.12329459322890349, 0.6206315789473684]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_error_baseline_DAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb5d4c",
   "metadata": {},
   "source": [
    "# Plot the evaluation bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9407bbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "models = ['B. BOW', 'B. Embed.', 'B. DAN', 'Best Student Model']\n",
    "label_0 = [0.5599194360523666, 0.6226082578046325, 0.6754783484390735, 0.47129909365558914]\n",
    "label_1 = [0.3084049183089102, 0.20683847060805122, 0.12329459322890349, 0.25080006737409466]\n",
    "label_2 = [0.41178947368421054, 0.45810526315789474, 0.6206315789473684, 0.5027368421052631]\n",
    "\n",
    "# Number of models\n",
    "N = len(models)\n",
    "\n",
    "# The x locations for the models\n",
    "ind = np.arange(0, 2*N, 2)  # increase spaces between groups\n",
    "\n",
    "# The width of the bars\n",
    "width = 0.44\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Bars for label 0\n",
    "rects1 = ax.bar(ind, label_0, width, color='#1f77b4')\n",
    "\n",
    "# Bars for label 1\n",
    "rects2 = ax.bar(ind+width, label_1, width, color='#ff7f0e')\n",
    "\n",
    "# Bars for label 2\n",
    "rects3 = ax.bar(ind+width*2, label_2, width, color='#2ca02c')\n",
    "\n",
    "# Add labels, title, and axes ticks\n",
    "ax.set_ylabel('Error Rate')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Negative (0)', 'Neutral (1)', 'Positive (2)'))\n",
    "\n",
    "# Plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d61c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
