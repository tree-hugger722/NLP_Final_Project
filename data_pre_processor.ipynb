{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625df7d0",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "Pytorch\n",
    "\n",
    "- input layer\n",
    "- some kind of deep averaging net\n",
    "- last_shared_layer = torch.xxx()\n",
    "\n",
    "classification specific net:\n",
    "first_layer_class_output = torch.xxx(last_shared_layer)\n",
    "...\n",
    "last layer = softmax that outputs 5 labels\n",
    "\n",
    "\n",
    "sentiment specific net:\n",
    "first_layer_sent_output = torch.xxx(last_shared_layer)\n",
    "...\n",
    "last layer = softmax that outputs 3 labels\n",
    "\n",
    "forward() returns 2 elements?                                                                                                                                                                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc2d2a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Forward pass \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: MAKE THIS WORK-- we have a skeleton of how we want it to work here, fill in the rest\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pred_class, pred_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mforward(X_batch)\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn1(pred_class, Y_batch[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39mloss_fn2(pred_sent, Y_batch[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# Forward pass \n",
    "# TODO: MAKE THIS WORK-- we have a skeleton of how we want it to work here, fill in the rest\n",
    "pred_class, pred_sent = self.forward(X_batch)\n",
    "loss = loss_fn1(pred_class, Y_batch[0]) +loss_fn2(pred_sent, Y_batch[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b9222",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "287de37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "04a5b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    train = pd.read_csv(\"./dataset_bbc/train_w_sentiment.csv\")\n",
    "    test = pd.read_csv(\"./dataset_bbc/test_w_sentiment.csv\")\n",
    "    test_category = pd.read_csv(\"./dataset_bbc/sample_solution.csv\")\n",
    "\n",
    "    test[\"Category\"] = test_category[\"Category\"]\n",
    "\n",
    "    Xmat = train[\"Text\"]\n",
    "    Y = train[[\"sentiment\",\"Category\"]]\n",
    "\n",
    "    Xmat_test = test[\"Text\"]\n",
    "    Y_test = test[[\"sentiment\",\"Category\"]]\n",
    "    \n",
    "    return Xmat, Y, Xmat_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c2d27405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xmat, Y, Xmat_test, Y_test = load_dataset()\n",
    "Xmat_train, Xmat_dev, Y_train, Y_dev = train_test_split(Xmat, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9a6599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def tokenizer(text: str):\n",
    "    '''\n",
    "    Citation: This tokenizer function & regex rule is borrowed from Katie's tokenizer regex demo at:\n",
    "    https://www.cs.williams.edu/~kkeith/teaching/s23/cs375/attach/tokenization_regex_demo.html\n",
    "    This helper function takes a string and returns a list of tokenized strings.\n",
    "    '''\n",
    "    regex = r\"[A-Za-z]+|\\$[\\d\\.]+|\\S+\" \n",
    "    res = nltk.regexp_tokenize(text, regex)\n",
    "    return [i for i in res if i != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cb0b4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Loads embeddings from embedding file and creates \n",
    "    1) dictionary of embedding words to indices\n",
    "    2) list of embedding indices to words\n",
    "    3) dense word embedding matrix\n",
    "    \"\"\"\n",
    "    embeddings = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "    vocab2indx = dict(embeddings.key_to_index)\n",
    "    idx2vocab = list(embeddings.index_to_key)\n",
    "    embed_array = embeddings.vectors # matrix of dense word embeddings \n",
    "                                     # rows: a word \n",
    "                                     # columns: dimensions (50) of the dense embeddings\n",
    "    return vocab2indx, idx2vocab, embed_array\n",
    "\n",
    "\n",
    "def add_the_embedding(embed_array, vocab2indx): \n",
    "    \"\"\"\n",
    "    Adds \"the\" embedding to the embed_array matrix\n",
    "    \"\"\"\n",
    "    the_embedding = embed_array[vocab2indx[\"the\"]]\n",
    "    out = np.vstack((embed_array, the_embedding))\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_oov(idx2vocab, vocab2indx, embed_array):\n",
    "    \"\"\"\n",
    "    Adds <OOV> token to embedded vocabulary\n",
    "    \"\"\"\n",
    "    print(\"len embed array: \", len(embed_array))\n",
    "    new_oov_entry = len(embed_array)\n",
    "    idx2vocab += [\"<OOV>\"]\n",
    "    vocab2indx[\"<OOV>\"] = new_oov_entry\n",
    "    embed_array_w_oov = add_the_embedding(embed_array, vocab2indx)\n",
    "\n",
    "    return idx2vocab, vocab2indx, embed_array_w_oov\n",
    "\n",
    "\n",
    "def add_pad(idx2vocab, vocab2indx, embed_array):\n",
    "    \"\"\"\n",
    "    Adds <PAD> token to embedded vocabulary\n",
    "    \"\"\"\n",
    "    print(\"len embed array: \", len(embed_array))\n",
    "    new_pad_entry = len(embed_array)\n",
    "    idx2vocab += [\"<PAD>\"]\n",
    "    vocab2indx[\"<PAD>\"] = new_pad_entry\n",
    "    embed_array_w_pad = add_the_embedding(embed_array, vocab2indx)\n",
    "    \n",
    "    return idx2vocab, vocab2indx, embed_array_w_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "70fc1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate and pad\n",
    "\n",
    "def truncate(original_indices_list: list, maximum_length=100) -> list: \n",
    "    \"\"\"\n",
    "    Truncates the original_indices_list to the maximum_length\n",
    "    \"\"\"\n",
    "    return original_indices_list[0:maximum_length]\n",
    "\n",
    "\n",
    "def pad(original_indices_list: list, pad_index: int, maximum_length=100) -> list: \n",
    "    \"\"\"\n",
    "    Given original_indices_list, concatenates the pad_index enough times \n",
    "    to make the list to maximum_length. \n",
    "    \"\"\"\n",
    "    while len(original_indices_list) < maximum_length:\n",
    "        original_indices_list.append(pad_index)\n",
    "        \n",
    "    return original_indices_list\n",
    "\n",
    "\n",
    "def get_padded_oov_embeddings():\n",
    "    \"\"\"\n",
    "    Get embedding array which includes the <PAD> and <OOV> tokens\n",
    "    \"\"\"\n",
    "    vocab2indx, idx2vocab, embed_array = load_embeddings(\"glove50_4k.txt\")\n",
    "    idx2vocab, vocab2indx, embed_array_w_oov = add_oov(idx2vocab, vocab2indx, embed_array)\n",
    "    idx2vocab, vocab2indx, embed_array_w_oov_pad = add_pad(idx2vocab, vocab2indx, embed_array_w_oov)\n",
    "    \n",
    "    return embed_array_w_oov_pad, vocab2indx, idx2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1de35e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_indices(tokens, vocab2indx): \n",
    "    \"\"\"\n",
    "    For each example, translate each token into its corresponding index from vocab2indx\n",
    "    \n",
    "    Replace words not in the vocabulary with the symbol \"<OOV>\" \n",
    "        which stands for 'out of vocabulary'\n",
    "        \n",
    "    Arguments: \n",
    "       - tokens (List[str]): list of strings of tokens \n",
    "       - vocab2indx (dict): each vocabulary word as strings and its corresponding int index \n",
    "                           for the embeddings \n",
    "                           \n",
    "    Returns: \n",
    "        - (List[int]): list of integers\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in vocab2indx:\n",
    "            token = \"<OOV>\"\n",
    "        indices.append(vocab2indx[token])\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5a788491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example 1 tokens =  worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.\n"
     ]
    }
   ],
   "source": [
    "#Unit test 1\n",
    "toks1 = \"this is great\".split()\n",
    "out1 = create_word_indices(toks1, vocab2indx)\n",
    "out1\n",
    "train1_toks = Xmat[0]\n",
    "print(\"Training example 1 tokens = \", train1_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "37a31ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_X(Xmat):\n",
    "    MAXIMUM_LENGTH = 512\n",
    "    embeddings, vocab2indx, idx2vocab = get_padded_oov_embeddings()\n",
    "    \n",
    "    X_list = []\n",
    "    for one_train_example in Xmat: \n",
    "        one_train_example = tokenizer(one_train_example)\n",
    "        one_train_indices = create_word_indices(one_train_example, vocab2indx)\n",
    "        one_train_indices = truncate(one_train_indices, maximum_length=MAXIMUM_LENGTH)\n",
    "        one_train_indices = pad(one_train_indices, len(vocab2indx)-1, maximum_length=MAXIMUM_LENGTH)\n",
    "        \n",
    "        one_train_example_embeddings = [] # A list of token embeddings\n",
    "        \n",
    "        for index in one_train_indices:\n",
    "            one_train_example_embeddings.append(embeddings[index])\n",
    "        \n",
    "        X_list.append(one_train_example_embeddings)\n",
    "        \n",
    "    X = torch.FloatTensor(X_list)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c30dc17d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len embed array:  4196\n",
      "len embed array:  4197\n"
     ]
    }
   ],
   "source": [
    "X = convert_X(Xmat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f0088046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1043, 512, 50])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "52f726a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worldcom',\n",
       " 'ex',\n",
       " '-boss',\n",
       " 'launches',\n",
       " 'defence',\n",
       " 'lawyers',\n",
       " 'defending',\n",
       " 'former',\n",
       " 'worldcom',\n",
       " 'chief',\n",
       " 'bernie',\n",
       " 'ebbers',\n",
       " 'against',\n",
       " 'a',\n",
       " 'battery',\n",
       " 'of',\n",
       " 'fraud',\n",
       " 'charges',\n",
       " 'have',\n",
       " 'called',\n",
       " 'a',\n",
       " 'company',\n",
       " 'whistleblower',\n",
       " 'as',\n",
       " 'their',\n",
       " 'first',\n",
       " 'witness',\n",
       " 'cynthia',\n",
       " 'cooper',\n",
       " 'worldcom',\n",
       " 's',\n",
       " 'ex',\n",
       " '-head',\n",
       " 'of',\n",
       " 'internal',\n",
       " 'accounting',\n",
       " 'alerted',\n",
       " 'directors',\n",
       " 'to',\n",
       " 'irregular',\n",
       " 'accounting',\n",
       " 'practices',\n",
       " 'at',\n",
       " 'the',\n",
       " 'us',\n",
       " 'telecoms',\n",
       " 'giant',\n",
       " 'in',\n",
       " '2002.',\n",
       " 'her',\n",
       " 'warnings',\n",
       " 'led',\n",
       " 'to',\n",
       " 'the',\n",
       " 'collapse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'firm',\n",
       " 'following',\n",
       " 'the',\n",
       " 'discovery',\n",
       " 'of',\n",
       " 'an',\n",
       " '$11',\n",
       " 'bn',\n",
       " '(£5.7bn)',\n",
       " 'accounting',\n",
       " 'fraud',\n",
       " 'mr',\n",
       " 'ebbers',\n",
       " 'has',\n",
       " 'pleaded',\n",
       " 'not',\n",
       " 'guilty',\n",
       " 'to',\n",
       " 'charges',\n",
       " 'of',\n",
       " 'fraud',\n",
       " 'and',\n",
       " 'conspiracy',\n",
       " 'prosecution',\n",
       " 'lawyers',\n",
       " 'have',\n",
       " 'argued',\n",
       " 'that',\n",
       " 'mr',\n",
       " 'ebbers',\n",
       " 'orchestrated',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'accounting',\n",
       " 'tricks',\n",
       " 'at',\n",
       " 'worldcom',\n",
       " 'ordering',\n",
       " 'employees',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'expenses',\n",
       " 'and',\n",
       " 'inflate',\n",
       " 'revenues',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'earnings',\n",
       " 'estimates',\n",
       " 'but',\n",
       " 'ms',\n",
       " 'cooper',\n",
       " 'who',\n",
       " 'now',\n",
       " 'runs',\n",
       " 'her',\n",
       " 'own',\n",
       " 'consulting',\n",
       " 'business',\n",
       " 'told',\n",
       " 'a',\n",
       " 'jury',\n",
       " 'in',\n",
       " 'new',\n",
       " 'york',\n",
       " 'on',\n",
       " 'wednesday',\n",
       " 'that',\n",
       " 'external',\n",
       " 'auditors',\n",
       " 'arthur',\n",
       " 'andersen',\n",
       " 'had',\n",
       " 'approved',\n",
       " 'worldcom',\n",
       " 's',\n",
       " 'accounting',\n",
       " 'in',\n",
       " 'early',\n",
       " '2001',\n",
       " 'and',\n",
       " '2002.',\n",
       " 'she',\n",
       " 'said',\n",
       " 'andersen',\n",
       " 'had',\n",
       " 'given',\n",
       " 'a',\n",
       " 'green',\n",
       " 'light',\n",
       " 'to',\n",
       " 'the',\n",
       " 'procedures',\n",
       " 'and',\n",
       " 'practices',\n",
       " 'used',\n",
       " 'by',\n",
       " 'worldcom',\n",
       " 'mr',\n",
       " 'ebber',\n",
       " 's',\n",
       " 'lawyers',\n",
       " 'have',\n",
       " 'said',\n",
       " 'he',\n",
       " 'was',\n",
       " 'unaware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fraud',\n",
       " 'arguing',\n",
       " 'that',\n",
       " 'auditors',\n",
       " 'did',\n",
       " 'not',\n",
       " 'alert',\n",
       " 'him',\n",
       " 'to',\n",
       " 'any',\n",
       " 'problems',\n",
       " 'ms',\n",
       " 'cooper',\n",
       " 'also',\n",
       " 'said',\n",
       " 'that',\n",
       " 'during',\n",
       " 'shareholder',\n",
       " 'meetings',\n",
       " 'mr',\n",
       " 'ebbers',\n",
       " 'often',\n",
       " 'passed',\n",
       " 'over',\n",
       " 'technical',\n",
       " 'questions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'company',\n",
       " 's',\n",
       " 'finance',\n",
       " 'chief',\n",
       " 'giving',\n",
       " 'only',\n",
       " 'brief',\n",
       " 'answers',\n",
       " 'himself',\n",
       " 'the',\n",
       " 'prosecution',\n",
       " 's',\n",
       " 'star',\n",
       " 'witness',\n",
       " 'former',\n",
       " 'worldcom',\n",
       " 'financial',\n",
       " 'chief',\n",
       " 'scott',\n",
       " 'sullivan',\n",
       " 'has',\n",
       " 'said',\n",
       " 'that',\n",
       " 'mr',\n",
       " 'ebbers',\n",
       " 'ordered',\n",
       " 'accounting',\n",
       " 'adjustments',\n",
       " 'at',\n",
       " 'the',\n",
       " 'firm',\n",
       " 'telling',\n",
       " 'him',\n",
       " 'to',\n",
       " 'hit',\n",
       " 'our',\n",
       " 'books',\n",
       " 'however',\n",
       " 'ms',\n",
       " 'cooper',\n",
       " 'said',\n",
       " 'mr',\n",
       " 'sullivan',\n",
       " 'had',\n",
       " 'not',\n",
       " 'mentioned',\n",
       " 'anything',\n",
       " 'uncomfortable',\n",
       " 'about',\n",
       " 'worldcom',\n",
       " 's',\n",
       " 'accounting',\n",
       " 'during',\n",
       " 'a',\n",
       " '2001',\n",
       " 'audit',\n",
       " 'committee',\n",
       " 'meeting',\n",
       " 'mr',\n",
       " 'ebbers',\n",
       " 'could',\n",
       " 'face',\n",
       " 'a',\n",
       " 'jail',\n",
       " 'sentence',\n",
       " 'of',\n",
       " '85',\n",
       " 'years',\n",
       " 'if',\n",
       " 'convicted',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'charges',\n",
       " 'he',\n",
       " 'is',\n",
       " 'facing',\n",
       " 'worldcom',\n",
       " 'emerged',\n",
       " 'from',\n",
       " 'bankruptcy',\n",
       " 'protection',\n",
       " 'in',\n",
       " '2004',\n",
       " 'and',\n",
       " 'is',\n",
       " 'now',\n",
       " 'known',\n",
       " 'as',\n",
       " 'mci',\n",
       " 'last',\n",
       " 'week',\n",
       " 'mci',\n",
       " 'agreed',\n",
       " 'to',\n",
       " 'a',\n",
       " 'buyout',\n",
       " 'by',\n",
       " 'verizon',\n",
       " 'communications',\n",
       " 'in',\n",
       " 'a',\n",
       " 'deal',\n",
       " 'valued',\n",
       " 'at',\n",
       " '$6.75',\n",
       " 'bn']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(Xmat_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8f71a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_to_label(proba_batch):\n",
    "\n",
    "    # Find the index of the largest value in each sub-array\n",
    "    max_indices = np.argmax(proba_batch, axis=1)\n",
    "\n",
    "    # Create a new array of the same shape filled with 0s\n",
    "    binary_array = np.zeros_like(proba_batch)\n",
    "\n",
    "    # Set the largest value positions to 1\n",
    "    for i, max_index in enumerate(max_indices):\n",
    "        binary_array[i, max_index] = 1\n",
    "    \n",
    "    return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b069d410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = [[0.1, 0.7, 0.3],[0.9, 0.05, 0.05]]\n",
    "proba_to_label(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build architecture\n",
    "\n",
    "# Distilled Dual-task Deep Averaging Net\n",
    "class DistilledDualDan(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation for Deep Averaging Network for classification \n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes_sentiment, \n",
    "                       num_classes_classification,\n",
    "                       embedding_dim: int, #architecture/pre-processing decision \n",
    "                       hidden_dim1: int, #architecture decision\n",
    "                       hidden_dim2: int, #architecture decision \n",
    "                       leaky_relu_negative_slope: float, #hyperparameter\n",
    "                       dropout_probability: float #hyperparameter\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Create the network architecture. \n",
    "        \n",
    "        Hints: \n",
    "        - Make sure all your dimensions of various layers work out correctly \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes_sentiment = num_classes_sentiment\n",
    "        self.num_classes_classification = num_classes_classification\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.leaky_relu_negative_slope = leaky_relu_negative_slope\n",
    "        self.dropout_probability = dropout_probability\n",
    "        \n",
    "        # Shared layers between the 2 tasks\n",
    "        self.hidden1 = nn.Linear(self.embedding_dim, self.hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(self.hidden_dim1,self.hidden_dim2)\n",
    "        \n",
    "        # Sentiment-specific layers\n",
    "        self.theta_sentiment = nn.Linear(self.hidden_dim2, self.num_classes_sentiment)\n",
    "        \n",
    "        # Classification-specific layers\n",
    "        self.theta_classification = nn.Linear(self.hidden_dim2, self.num_classes_classification)\n",
    "        \n",
    "        # Common \"tools\"\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1) # A dimension along which LogSoftmax will be computed.\n",
    "        self.apply_dropout = nn.Dropout(self.dropout_probability)\n",
    "        \n",
    "        \n",
    "    def forward(self, X_batch: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given X_batch, make the forward pass through the network. \n",
    "        \n",
    "        The output should be the predicted *log probabilities*. \n",
    "        \n",
    "        Returns: \n",
    "            - (torch.Tensor): the log probabilites after the forward pass \n",
    "                The shape of this tensor should be (X_batch.shape[0], 2)\n",
    "                \n",
    "        Hints: \n",
    "            - Look at Pytorch's implemenation of .mean()\n",
    "            - There should be NO for-loops in this method\n",
    "        \"\"\"\n",
    "        # activation function: leaky_relu\n",
    "        # probability function used on the forward pass = softmax w log applied\n",
    "        # leaky_relu_forward_backward(u:float, negative_slope: float=0.1)\n",
    "        \n",
    "        # for each example, get mean of word embeddings on the row (dim=1)\n",
    "            # expected dimensionality: [m x d], where m is the num of examples \n",
    "            # (2, in the toy example) and d is the number of dimensions (50, \n",
    "            # in the toy example)\n",
    "        \n",
    "        # convert from inputted word indices to corresponding vector embeddings\n",
    "        \n",
    "        # embedded_with_dropout = self.apply_dropout(X_bat)\n",
    "        \n",
    "        # pool input by average so embedding shape goes from (# examples, # words, embedding dimension)\n",
    "        # to (# examples, embedding dimension)\n",
    "        \n",
    "        # TODO - Dropout!\n",
    "        \n",
    "        # Common layers\n",
    "        pooled_input_batch = torch.mean(X_batch, dim=1)\n",
    "        hid1_output_batch = self.hidden1(pooled_input_batch)\n",
    "        hid1_output_batch = torch.nn.functional.leaky_relu(hid1_output_batch, self.leaky_relu_negative_slope)\n",
    "        \n",
    "        hid2_output_batch = self.hidden2(hid1_output_batch)\n",
    "        hid2_output_batch = torch.nn.functional.leaky_relu(hid2_output_batch, self.leaky_relu_negative_slope)\n",
    "        \n",
    "        # Sentiment-specific layers\n",
    "        out_sentiment_batch = torch.FloatTensor(self.theta_sentiment(hid2_output_batch))\n",
    "        log_probs_sentiment_batch = self.log_softmax(out_sentiment_batch)\n",
    "        \n",
    "        # Classification-specific layers\n",
    "        \n",
    "        out_classification_batch = torch.FloatTensor(self.theta_classification(hid2_output_batch))\n",
    "        log_probs_classification_batch = self.log_softmax(out_classification_batch)\n",
    "        \n",
    "        return log_probs_sentiment_batch, log_probs_classification_batch\n",
    "        \n",
    "    def train_model(self, \n",
    "                    X_train, \n",
    "                    Y_train, # need to be one-hot encoding\n",
    "                    X_dev, \n",
    "                    Y_dev, # need to be one-hot encoding\n",
    "                    sentiment_soft_labels,\n",
    "                    classification_soft_labels,\n",
    "                    soft_label_weight=0.5,\n",
    "                    loss_fn=nn.CrossEntropyLoss(),\n",
    "                    optimizer, \n",
    "                    num_iterations, \n",
    "                    batch_size = 500, \n",
    "                    check_every=10, \n",
    "                    verbose=False): \n",
    "        \"\"\"\n",
    "        Method to train the model. \n",
    "        \n",
    "        No need to modify this method. \n",
    "        \"\"\"\n",
    "        self.train() # tells nn.Module its in training mode \n",
    "                      # (important when we get to things like dropout)\n",
    "            \n",
    "        loss_history = [] # We'll record the loss for inspection\n",
    "        train_accuracy = []\n",
    "        dev_accuracy = []\n",
    "        \n",
    "        for t in range(num_iterations):\n",
    "            \n",
    "            # Randomly selecting a batch\n",
    "            if batch_size >= X_train.shape[0]: \n",
    "                X_batch = X_train\n",
    "                Y_batch = Y_train\n",
    "                sentiment_soft_labels_batch = sentiment_soft_labels\n",
    "                classification_soft_labels_batch = classification_soft_labels\n",
    "            else: #randomly choose batch_size number of examples \n",
    "                batch_indices = np.random.randint(X_train.shape[0], size=batch_size)\n",
    "                X_batch = X_train[batch_indices]\n",
    "                Y_batch = Y_train[batch_indices]\n",
    "                sentiment_soft_labels_batch = sentiment_soft_labels[batch_indices]\n",
    "                classification_soft_labels_batch = classification_soft_labels[batch_indices]\n",
    "          \n",
    "            # TODO!!! CHECK THIS!!!\n",
    "            Y_sentiment_batch = Y_batch[1]\n",
    "            Y_classification_batch = Y_batch[0]\n",
    "\n",
    "            # Forward pass \n",
    "            log_probs_sentiment_batch, log_probs_classification_batch = self.forward(X_batch)\n",
    "\n",
    "            # distillation loss (cross entropy loss with hard labels + cross entropy loss with soft labels)\n",
    "            # weighted with soft and hard label\n",
    "            sentiment_loss = (1-soft_label_weight)*loss_fn(log_probs_sentiment_batch, Y_sentiment_batch) + \n",
    "                             soft_label_weight*loss_fn(log_probs_sentiment_batch, sentiment_soft_labels_batch)\n",
    "                \n",
    "            classification_loss = (1-soft_label_weight)*loss_fn(log_probs_classification_batch, Y_classification_batch) + \n",
    "                             soft_label_weight*loss_fn(log_probs_classification_batch, classification_soft_labels_batch)\n",
    "            \n",
    "            # Question: divided by batch size?\n",
    "            total_loss = sentiment_loss + classification_loss\n",
    "\n",
    "            #Backprop\n",
    "            optimizer.zero_grad() # clears the gradients from the previous iteration\n",
    "                                  # this step is important because otherwise Pytorch will \n",
    "                                  # *accumulate* gradients for all itereations (all backwards passes)\n",
    "            loss.backward() # calculate gradients from forward step \n",
    "            optimizer.step() # gradient descent update equation \n",
    "\n",
    "            #Check the loss and train and dev accuracies every \n",
    "            if t % check_every == 0:\n",
    "                loss_value = loss.item() # call .item() to detach from the tensor \n",
    "                loss_history.append(loss_value)\n",
    "\n",
    "                #Check train accuracy (entire set, not just batch) \n",
    "                train_y_pred, _ = self.predict(X_train)\n",
    "                train_acc = self.accuracy(train_y_pred, Y_train.detach().numpy()) \n",
    "                train_accuracy.append(train_acc)\n",
    "\n",
    "                #Check dev accuracy (entire set, not just batch) \n",
    "                dev_y_pred, _ = self.predict(X_dev)\n",
    "                dev_acc = self.accuracy(dev_y_pred, Y_dev.detach().numpy())\n",
    "                dev_accuracy.append(dev_acc)\n",
    "\n",
    "                if verbose: print(f\"Iteration={t}, Loss={loss_value}\")\n",
    "                \n",
    "        return loss_history, train_accuracy, dev_accuracy\n",
    "    \n",
    "    def predict(self, X, proba_mode=False):\n",
    "        \"\"\"\n",
    "        Method to make predictions given a trained model. \n",
    "        \n",
    "        No need to modify this method. \n",
    "        \"\"\"\n",
    "        self.eval() # tells nn.Module its NOT in training mode \n",
    "                 # (important when we get to things like dropout)\n",
    "    \n",
    "        log_probs_sentiment_batch, log_probs_classification_batch = self.forward(X)\n",
    "        \n",
    "        if proba_mode:\n",
    "            return log_probs_sentiment_batch, log_probs_classification_batch\n",
    "        else:\n",
    "            # convert proba to label\n",
    "            label_sentiment_batch = proba_to_label(log_probs_sentiment_batch)\n",
    "            label_classification_batch = proba_to_label(log_probs_classification_batch)\n",
    "            \n",
    "        \n",
    "        if self.num_classes == 2: \n",
    "            log_pred_pos_class = pred_log_probs[:,1].detach().numpy() #get only the positive class \n",
    "            pred_pos_class = np.exp(log_pred_pos_class) #exp to undo the log \n",
    "            # decision threshold\n",
    "            y_pred = np.zeros(X.shape[0])\n",
    "            y_pred[pred_pos_class>= 0.5] = 1\n",
    "            return y_pred, pred_pos_class\n",
    "        \n",
    "        else: \n",
    "            return pred_log_probs\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_pred: np.ndarray, y_true: np.ndarray) -> float: \n",
    "        \"\"\"\n",
    "        Calculates accuracy. No need to modify this method. \n",
    "        \"\"\"\n",
    "        return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data train-dev-test split\n",
    "# a pipeline for hyperparameter tuning and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
