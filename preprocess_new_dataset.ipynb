{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828f4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ed5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load training and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    train = pd.read_csv(\"./new_dataset/train.csv\")\n",
    "    val = pd.read_csv(\"./new_dataset/val.csv\")\n",
    "    test = pd.read_csv(\"./new_dataset/test.csv\")\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297f908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85d427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping from label to sentiment text\n",
    "label_to_sentiment = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "train['sentiment'] = train['label'].map(label_to_sentiment)\n",
    "val['sentiment'] = val['label'].map(label_to_sentiment)\n",
    "test['sentiment'] = test['label'].map(label_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98cd34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neutral     20673\n",
      "positive    17849\n",
      "negative     7093\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of positive, neutral, and negative sentiments\n",
    "sentiment_counts = train['sentiment'].value_counts()\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a1d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_one_hot(Y):\n",
    "    \"\"\"\n",
    "    For each row in input Y, converts labels 0, 1, and 2 to arrays\n",
    "    that are one-hot encoded\n",
    "    \"\"\"\n",
    "    encoded_Y = np.zeros((Y.shape[0],3))\n",
    "    \n",
    "    for index, row in enumerate(Y):\n",
    "        one_hot_array = np.zeros(3)\n",
    "        one_hot_array[row] = 1\n",
    "        encoded_Y[index] = one_hot_array\n",
    "    \n",
    "    return encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5c9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Y_hard\"] = encode_labels_one_hot(train[\"label\"]).tolist()\n",
    "val[\"Y_hard\"] = encode_labels_one_hot(val[\"label\"]).tolist()\n",
    "test[\"Y_hard\"] = encode_labels_one_hot(test[\"label\"]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f3dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save val and test\n",
    "val.to_csv(\"./new_dataset/val_preprocessed.csv\", index=False)\n",
    "test.to_csv(\"./new_dataset/test_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98472999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softlabels(X):\n",
    "    \"\"\"\n",
    "    Citation: Full Classification Example on twitter-roberta-base-sentiment-latest Model card. \n",
    "    Link: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latesthttps://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "    \n",
    "    Runs Twitter-Roberta-Based-Sentiment Model on the Twitter Sentiment Extraction dataset\n",
    "    Returns an array of soft labels (log probabilities)\n",
    "    \"\"\"\n",
    "    # Preprocess text (username and link placeholders)\n",
    "    def preprocess(text):\n",
    "        text = str(text)\n",
    "        new_text = []\n",
    "        for t in text.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            new_text.append(t)\n",
    "        return \" \".join(new_text)\n",
    "    \n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "    \n",
    "    # Pytorch\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "    # dimensions: [# examples, # classes (3)]\n",
    "    soft_labels = np.zeros((X.shape[0],3))\n",
    "    \n",
    "    for index, row in enumerate(X):\n",
    "        if index % 1000 == 0:\n",
    "            print(\"Current index: \", index)\n",
    "        text = preprocess(row)\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        soft_labels[index] = scores.tolist()\n",
    "        index += 1\n",
    "\n",
    "    return soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "981c72c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae884d99e2ee41a589e08c617d457a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index:  0\n",
      "Current index:  1000\n",
      "Current index:  2000\n",
      "Current index:  3000\n",
      "Current index:  4000\n",
      "Current index:  5000\n",
      "Current index:  6000\n",
      "Current index:  7000\n",
      "Current index:  8000\n",
      "Current index:  9000\n",
      "Current index:  10000\n",
      "Current index:  11000\n",
      "Current index:  12000\n",
      "Current index:  13000\n",
      "Current index:  14000\n",
      "Current index:  15000\n",
      "Current index:  16000\n",
      "Current index:  17000\n",
      "Current index:  18000\n",
      "Current index:  19000\n",
      "Current index:  20000\n",
      "Current index:  21000\n",
      "Current index:  22000\n",
      "Current index:  23000\n",
      "Current index:  24000\n",
      "Current index:  25000\n",
      "Current index:  26000\n",
      "Current index:  27000\n",
      "Current index:  28000\n",
      "Current index:  29000\n",
      "Current index:  30000\n",
      "Current index:  31000\n",
      "Current index:  32000\n",
      "Current index:  33000\n",
      "Current index:  34000\n",
      "Current index:  35000\n",
      "Current index:  36000\n",
      "Current index:  37000\n",
      "Current index:  38000\n",
      "Current index:  39000\n",
      "Current index:  40000\n",
      "Current index:  41000\n",
      "Current index:  42000\n",
      "Current index:  43000\n",
      "Current index:  44000\n",
      "Current index:  45000\n"
     ]
    }
   ],
   "source": [
    "train[\"Y_soft\"] = get_softlabels(train[\"text\"]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb89521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"./new_dataset/train_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5471022",
   "metadata": {},
   "source": [
    "# Accuracy of the teacher on new dataset (the one teacher is trained on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0ea9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pred = train[[\"label\", \"Y_soft\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1258299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_max_index(df):\n",
    "    correct_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        Y_soft = np.array(row['Y_soft'])\n",
    "        label = row['label']\n",
    "        if np.argmax(Y_soft) == label:\n",
    "            correct_count += 1\n",
    "    return correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d10944",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = compare_max_index(teacher_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6bf3672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772662501370163"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_count / teacher_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacd9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
